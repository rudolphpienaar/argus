/**
 * @file System Knowledge Base
 * Auto-generated by scripts/bundle-docs.cjs
 * Contains the full content of the docs/ directory for AI context.
 */

export const SYSTEM_KNOWLEDGE: Record<string, string> = {
    "agentic-safety.adoc": "= Why Agents Will Always Lie: Theoretical Foundations for Deterministic Orchestration in ARGUS\n:author: ATLAS Project Team\n:revdate: 2026-02-14\n:toc: macro\n:toclevels: 3\n:sectnums:\n\ntoc::[]\n\n== Motivation\n\nThis document grounds the ARGUS architecture in a formal theoretical argument about the structural limits of agentic AI in safety-critical domains. The argument is developed fully in the paper _Reasoning, LLMs, and Agentic Programs: Agents Will Always Lie, So Clinical Truth Must Live Outside the Model_ (Pienaar, 2026). This document summarizes the key results and maps them concretely to ARGUS's design decisions.\n\nThe central claim is that hallucination in agentic systems is not a bug to be fixed but a mathematical property of probabilistic policies navigating large action spaces. The architectural consequence is that LLMs must be confined to intent interpretation, with workflow execution delegated to deterministic, prevalidated systems. ARGUS and CALYPSO are a concrete implementation of this principle.\n\n== The Mathematical Argument\n\n=== Why Generation Is Inherently Probabilistic\n\nNeural networks with fixed parameters implement deterministic forward maps `f_θ : ℝ^d → ℝ^k`. Typically `k ≪ d`, so many distinct inputs collapse to the same or nearby representations. The preimage of any representation `z` is large:\n\n[source]\n----\nP(z) = { x ∈ ℝ^d | f_θ(x) = z }\n----\n\nGeneration asks the model to go backward — from representation to output — but this reverse direction cannot be a true inverse because the forward map is many-to-one. The only meaningful way back is probabilistic: the model learns a conditional distribution `p_θ(x | c)` over the equivalence class of outputs compatible with a context `c`, and sampling draws one member:\n\n[source]\n----\nx ~ p_θ(x | c)\n----\n\nProbability is therefore not an optional detail on top of otherwise deterministic networks. It is intrinsic to the generative step. Forcing determinism (collapsing `p_θ` to a single mode) would destroy the coverage and fidelity that make generative models useful.\n\n=== The Action Graph and Orchestration Hallucination\n\nModel the tools available to an agent as a directed graph `G = (V, E)`, where vertices are primitive operations and edges are allowed transitions. A workflow is a path `s = (v₁, v₂, …, v_L)` in this graph.\n\nAmong all reachable paths `S(G)`, only a subset `S_valid` corresponds to clinically valid workflows. The complement `S_invalid = S(G) \\ S_valid` is combinatorially enormous.\n\nAn agentic policy defines a probability distribution over workflows:\n\n[source]\n----\nπ_MCP(s | i),    s ∈ S(G)\n----\n\nThe orchestration hallucination probability — the chance of selecting an invalid workflow — is:\n\n[source]\n----\nH_MCP(i) = 1 − Σ_{s ∈ S_valid} π_MCP(s | i)\n----\n\n=== The Inevitability Theorem\n\n**Theorem (non-zero orchestration risk):** If there exists any reachable state `x` and action `a` such that the resulting workflow is clinically invalid and `π_MCP(a | x) > 0`, then:\n\n[source]\n----\nH_MCP(i) > 0\n----\n\nFor a workflow of length `L` with per-step error probability `ε > 0`:\n\n[source]\n----\nH_MCP(i; L) = 1 − (1 − ε)^L\n----\n\nThis quantity increases with `L`. More tools and more steps expand the dangerous space rather than shrinking it. Requiring more detailed reasoning (longer chains of thought, explicit tool calls, \"showing the work\") only increases the number of opportunities for deviation.\n\nSafety interlocks change what happens _after_ an invalid path is attempted, but they do not change the probability that the policy _attempts_ it. The ever-error probability remains strictly positive:\n\n[source]\n----\nH^ever_MCP(i) ≥ P[reach x] · π_MCP(a | x) · P[x → v_fail | a] > 0\n----\n\n=== Heterogeneous Graph Structure\n\nReal tool graphs are not uniform. Some regions are narrow and tightly constrained (low local error `ε_t`), others are wide and loosely constrained (high `ε_t`). The heterogeneous formulation uses prefix histories:\n\n[source]\n----\nP_valid(i; L) = E[ ∏_{t=1}^{L−1} (1 − ε_t(h_t)) ]\n----\n\nThe conclusion holds regardless of graph shape: as long as any reachable decision point has `ε_t > 0`, the overall hallucination probability cannot be eliminated. If the expected cumulative hazard `Σ_t ε_t` grows with `L`, the probability of at least one error tends toward one.\n\n=== The IAS Remedy: Collapsing the Action Space\n\nThe Intent-Action Service (IAS) changes the problem fundamentally. Instead of allowing the agent to select paths in `S(G)`, IAS provides a deterministic compilation from intents to workflows:\n\n[source]\n----\nF : I → S_valid,    F(i) = s_i\n----\n\nThe agent's effective policy becomes:\n\n[source]\n----\nπ_IAS(s | i) = 1  if s = s_i\n               0  otherwise\n----\n\nAnd therefore:\n\n[source]\n----\nH_IAS(i) = 0\n----\n\nThe combinatorially explosive space of invalid workflows is never touched at runtime. Residual hallucination is confined to two interpretable boundaries:\n\n1. **Intent interpretation** — the mapping from natural language `u` to formal intent `i`. This is a semantic error, not an orchestration error.\n2. **IAS specification** — if `F` is incorrectly defined. This is a software verification problem, not a probabilistic one.\n\n== How ARGUS Implements IAS\n\nARGUS does not merely advocate for deterministic orchestration — it implements it. Every architectural layer in CALYPSO exists to keep the LLM out of the orchestration loop.\n\n=== The Routing Chain as F\n\nCALYPSO's five-level routing chain is a concrete realization of the IAS mapping `F : I → S_valid`:\n\n[cols=\"1,2,2\"]\n|===\n| Level | Mechanism | Role in IAS\n\n| 1. Shell parsing\n| Exact string match against builtins\n| Deterministic: `ls`, `cd`, `tree` → single canonical action\n\n| 2. Workflow dispatch\n| `workflow_dispatch()` matches known commands\n| Deterministic: `search`, `gather`, `harmonize`, `federate` → `F(i) = s_i`\n\n| 3. Pattern matching\n| `workflowPatterns[]` intercepts interrogatives\n| Deterministic: \"what stage am I on?\" → VFS query, not LLM inference\n\n| 4. NL intent resolution\n| `actionIntent_resolve()` strips prefixes, maps to commands\n| Deterministic: \"ok do the harmonization\" → `harmonize` → `F(i)`\n\n| 5. LLM fallback\n| `engine.llm_generate()` with injected context\n| Probabilistic, but **confined to explanation and guidance**, not action selection\n|===\n\nLevels 1–4 are the IAS. They collapse the action space to a single canonical workflow per intent. The LLM at level 5 is used for interpretation and interaction — precisely the role the paper assigns to it.\n\n=== Data-State Grounding as S_valid Enforcement\n\nThe paper defines `S_valid` as the set of clinically valid workflows. In ARGUS, this validity is enforced through materialized artifacts:\n\n- A cohort is gathered when `.cohort` exists\n- Data is harmonized when `.harmonized` exists\n- Training is complete when `.local_pass` exists\n- Federation is complete when `.federated` exists\n\nThe `WorkflowEngine` evaluates these conditions fresh on every query using VFS inspection. It never caches or asserts completion from memory. This is the data-state analog of checking `s ∈ S_valid`: the system reads ground truth rather than trusting the agent's assertion.\n\nAn LLM consuming data-state context (VFS queries) reads ground truth. An LLM consuming counter-derived context reads assertions that may be stale. The old in-memory counter approach caused context drift, confabulation, and whack-a-mole regressions — precisely the `H_MCP(i) > 0` behavior the paper predicts. The data-state approach eliminated this class of bug.\n\n=== Three Layers as Defense in Depth\n\nThe paper notes that safety interlocks reduce the _impact_ of invalid orchestration attempts but do not reduce their _probability_. ARGUS acknowledges this by layering defenses:\n\n[cols=\"1,2,2\"]\n|===\n| Layer | What It Does | What It Cannot Do\n\n| Deterministic routing (L1–L4)\n| Prevents workflow queries from reaching the LLM\n| Cannot handle genuinely novel requests\n\n| Context injection (L2)\n| Ensures the LLM has accurate state when consulted\n| Cannot prevent the LLM from ignoring or misinterpreting context\n\n| Stage directives (L3)\n| Hard-coded rules prevent the LLM from advising skips\n| Cannot catch every possible confabulation\n|===\n\nNo single layer eliminates hallucination. Together, they confine it to the narrowest possible boundary: the LLM's interpretation of requests that survive four levels of deterministic routing. This is the architectural consequence of `H_MCP(i) > 0` — you cannot make it zero within the model, so you minimize the surface area where the model operates.\n\n== The Sequencing Problem and Manifests\n\n=== Where Grounding Falls Short\n\nInteractive testing of CALYPSO (v7.2.0) revealed a specific failure mode predicted by the paper's heterogeneous graph analysis. Data-state grounding answers **\"where am I?\"** reliably — the LLM reads artifact state and correctly identifies which stages are complete. But **\"what comes next?\"** is delegated to LLM inference, which drifts:\n\n- After `search`, the LLM skips `gather` and jumps to harmonization\n- After `gather`, the LLM forgets to offer `rename`\n- After `python train.py`, the LLM jumps to \"Federation Dispatch\" without acknowledging sub-steps\n\nIn graph-theoretic terms: the current architecture makes the graph skinny (low `ε_t`) for state queries but wide (high `ε_t`) for sequencing queries. The LLM faces a broad choice space when inferring the next step, and the per-step error probability at these junctures is non-trivial.\n\n=== Manifests as Further IAS Collapse\n\nThe solution is to extend the IAS principle from individual actions to entire workflow sequences. A **persona manifest** (`fedml.manifest.yaml`) defines the complete conversational DAG:\n\n[source,yaml]\n----\nstages:\n  - id: gather\n    previous: search\n    produces:\n      - \"${project}/input/.cohort\"\n    instruction: >\n      Add datasets to your cohort...\n    commands:\n      - add <dataset>\n      - gather\n\n  - id: harmonize\n    previous: [gather, rename]\n    produces:\n      - \"${project}/input/.harmonized\"\n    instruction: >\n      Harmonize your cohort to ensure consistent data formats...\n    commands:\n      - harmonize\n----\n\nEach stage declares `previous` (DAG topology), `produces` (data-state outputs), `instruction` (what to tell the user), and `commands` (exact available actions). The LLM reads the manifest rather than inferring the next step.\n\nIn the paper's terms, this collapses the sequencing action space the same way `F` collapses the orchestration space. The mapping from \"current state\" to \"next guidance\" becomes deterministic: look up the current stage in the manifest, read its `instruction` and `commands`, present them to the user. The LLM no longer navigates a distribution over possible next steps; it reads a single canonical answer.\n\n=== The MCP–IAS Spectrum in Practice\n\nThe paper describes a spectrum from fully agentic (LLM controls all tool selection) to fully deterministic (LLM only selects intents). ARGUS sits near the deterministic end, and each architectural improvement has moved it further:\n\n[cols=\"1,2,1\"]\n|===\n| Version | Architectural Move | Spectrum Position\n\n| v5.0.0\n| Headless core, shell builtins\n| LLM handles routing + state + sequencing\n\n| v6.0.0\n| Workflow patterns, data-state grounding\n| LLM handles sequencing only\n\n| v6.1.0\n| NL intent resolution, stage directives\n| LLM handles guidance text only\n\n| v7.2.0 (planned)\n| Persona manifests\n| LLM interprets NL, reads manifest for everything else\n|===\n\nEach step narrows the `ε_t` at another class of decision point. The trajectory is toward a system where the LLM's only probabilistic contribution is translating natural language into formal intents — the irreducible residual that the paper identifies as the one place where hallucination cannot be architecturally eliminated.\n\n== The Fingerprint Extension\n\nThe manifest design includes a further data-state innovation: **Merkle fingerprinting** over the DAG. Each stage's artifact carries a fingerprint that is a function of its own content and all ancestor fingerprints:\n\n[source]\n----\nfp(s) = hash(content(s), fp(parent_1), …, fp(parent_n))\n----\n\nThis enables staleness detection without a controller. If a user revisits an earlier stage and changes it, the fingerprint chain breaks at every downstream stage whose recorded parent fingerprints no longer match. The runtime detects invalidation by reading artifacts — pure data-state, no event bus, no dirty bit.\n\nThis is the data-state analog of the paper's observation that safety interlocks are reactive (they respond to errors after the fact) while structural constraints are preventive (they make errors impossible by construction). Fingerprinting makes stale state _visible_ rather than relying on a controller to track it.\n\n== Summary\n\nThe paper proves that orchestration hallucination probability is non-zero for any probabilistic policy over a non-trivial action graph, and increases with workflow length. The architectural remedy is to remove the LLM from the orchestration loop entirely, confining it to intent interpretation.\n\nARGUS implements this remedy through:\n\n1. **Deterministic routing** — four levels of pattern matching before LLM fallback (the IAS mapping `F`)\n2. **Data-state grounding** — materialized artifacts as ground truth, not model assertions (enforcing `S_valid`)\n3. **Context injection** — live VFS queries fed to the LLM, not cached memory (preventing context drift)\n4. **Stage directives** — hard-coded rules constraining LLM output (defense in depth)\n5. **Persona manifests** (in progress) — collapsing sequencing to deterministic DAG lookup (extending `F` to full workflow paths)\n6. **Merkle fingerprinting** (in progress) — data-state staleness detection without controllers\n\nEach layer exists because the mathematics demands it. Hallucination is not a quality issue to be solved with better prompts; it is a structural property of probabilistic systems. The only sound response is to minimize the surface area where probability governs decisions.\n\n== References\n\n* Pienaar, R. \"Reasoning, LLMs, and Agentic Programs: Agents Will Always Lie, So Clinical Truth Must Live Outside the Model.\" 2026.\n* See also: `docs/agentic.adoc` — ARGUS positioning vs agentic design patterns\n* See also: `docs/CURRENT.md` — Active manifest and DAG fingerprinting design\n* See also: `docs/persona-workflows.adoc` — Data-state grounding and workflow definitions\n\n---\n_Last updated: {revdate}_",
    "agentic.adoc": "= ARGUS and Agentic Design Patterns\n:author: ATLAS Project Team\n:revdate: 2026-02-11\n:toc:\n:sectnums:\n\n== Introduction\n\nThe word \"agentic\" has become overloaded. In its broadest sense it describes any system where an AI model takes actions in the world rather than merely generating text. In practice, the term covers architectures as different as autonomous coding agents, chatbot sidebars, and tool-calling orchestration frameworks. ARGUS sits in this landscape but does not fit neatly into any existing category.\n\nThis document compares and contrasts the ARGUS design with established agentic patterns. The goal is not to claim superiority over other approaches — many solve different problems well — but to make explicit where ARGUS diverges, why it diverges, and what trade-offs result.\n\n== The Agentic Landscape\n\n=== Reasoning-Action Loops (ReAct)\n\nThe ReAct pattern (Yao et al., 2022) interleaves reasoning traces with environment actions. The model thinks about what to do, takes an action, observes the result, and reasons again. This produces interpretable chains of thought tied to concrete steps.\n\nARGUS borrows the structure of this loop — CALYPSO interprets intent, dispatches an action, and reports the result — but differs in a critical way: the reasoning step does not determine what action to take in an open-ended sense. CALYPSO's routing chain uses deterministic pattern matching and intent resolution before the LLM is consulted. The LLM provides natural language interpretation, not action selection.\n\n=== Tool-Using Agents (Toolformer, Function Calling)\n\nToolformer (Schick et al., 2023) and structured function calling (OpenAI, Anthropic) give models the ability to invoke typed tools during generation. The model decides when and which tool to call, and the tool's output is folded back into the generation context.\n\nARGUS uses a similar dispatch mechanism — CALYPSO maps user intent to deterministic functions like `project_gather()`, `project_harmonize()`, and `workflow_dispatch()` — but the routing is inverted. In tool-using agents, the model selects the tool. In ARGUS, deterministic code resolves the intent first (`workflowPatterns`, `actionIntent_resolve`, `workflow_dispatch`), and the LLM is the fallback path, not the primary dispatcher. This inversion is deliberate: in a medical imaging workflow, the cost of the model selecting the wrong tool is higher than the cost of slightly less flexible intent handling.\n\n=== Autonomous Agents (Auto-GPT, SWE-agent, OpenHands)\n\nAutonomous agent systems give the AI full control of a task loop. The human provides a goal, and the agent plans, executes, and iterates until the goal is met or the budget is exhausted. SWE-agent (2024) and OpenHands apply this pattern to software engineering with terminal and file access.\n\nARGUS explicitly rejects this model. The human remains in the interaction loop at every stage. CALYPSO guides, warns, and dispatches, but the user decides when to proceed, when to skip a stage, and when to override a recommendation. The soft enforcement model (warn → warn-with-reason → allow) encodes this philosophy: the system educates rather than blocks, and never takes irreversible action without the user's participation.\n\n=== Orchestration Frameworks (LangGraph, CrewAI)\n\nOrchestration frameworks provide infrastructure for building multi-step, multi-agent workflows. LangGraph models workflows as state machines with conditional edges. CrewAI assigns roles to multiple agents that collaborate on a shared task.\n\nARGUS shares the state machine structure — the `WorkflowEngine` manages a DAG of stages with dependencies, validation conditions, and transition rules — but does not use multiple collaborating agents. There is one AI layer (CALYPSO) and one user. The complexity is in the workflow, not in agent coordination. This keeps the trust model simple: the user trusts one system, and that system's claims are verifiable against materialized artifacts.\n\n=== Model Context Protocol (MCP)\n\nMCP standardizes how models access external tools and context sources through a uniform protocol. It addresses the integration problem: how to connect models to arbitrary services without bespoke plumbing for each.\n\nARGUS does not currently use MCP, but its architecture is compatible with it. The VFS layer and store already provide structured context that `workflowContext_forLLM()` assembles for the model. Exposing these as MCP resources would be a natural extension, making CALYPSO's grounding context available to external models and tools.\n\n=== Intent-Action Services (ChRIS Intent-Server)\n\nThe Intent-Action Service (IAS) proposal (https://github.com/FNNDSC/intent-server[FNNDSC/intent-server]) addresses a structural problem in the ChRIS ecosystem: CUBE exposes a declarative, HATEOAS-compliant hypermedia API, but clients need procedural workflows that orchestrate multiple resource operations into coherent sequences. Rather than polluting CUBE with procedural logic, the IAS sits as an external service that accepts high-level intents, resolves them into concrete action sequences, dispatches those actions against CUBE, and manages credentials through authCore.\n\nThis is the closest formal ancestor to what CALYPSO does inside ARGUS. The IAS proposal articulates the separation clearly: the declarative API stays pure, the procedural orchestration lives in a distinct layer, and clients speak in intent rather than in raw API calls. ARGUS inherits this separation in spirit — CALYPSO is an intent-action layer that sits between the user and the deterministic execution substrate (VFS, workflow engine, store) — but instantiates it differently. Where the IAS is proposed as a network service mediating between HTTP clients and CUBE's REST API, CALYPSO is embedded in the application itself, mediating between natural language and local deterministic functions. The architectural principle is identical: intents in, actions out, with the orchestration logic isolated from both the user-facing surface and the state substrate.\n\nThe IAS proposal also identifies a key insight that ARGUS validates empirically: intent-level APIs are naturally agentic-ready. When the interface contract is \"describe what you want\" rather than \"compose the exact API calls,\" an LLM can participate in the resolution chain without requiring bespoke integration for every operation. CALYPSO's routing chain — from NL input through deterministic pattern matching to LLM fallback — is a concrete implementation of that principle.\n\n=== AI-as-Sidebar (Copilot Chat, Notion AI, Slack AI)\n\nThe most common production pattern places the AI in a chat panel alongside the real interface. The AI can answer questions, summarize content, and sometimes trigger actions, but it does not own the interaction flow. The user's primary surface is the traditional UI.\n\nThis is the pattern ARGUS most directly challenges. In ARGUS, the terminal and conversational layer _is_ the primary surface. The AI does not hover at the edge of a traditional interface; it mediates all workflow interaction. This is possible because the AI layer routes to deterministic execution rather than generating open-ended actions — the risk profile that makes sidebar placement attractive (constraining the AI's blast radius) is addressed through architectural grounding instead.\n\n== Where ARGUS Diverges\n\nThe patterns above each solve parts of the agentic interaction problem. ARGUS's contribution is a specific combination that, as far as we can determine, no existing system enforces together:\n\n=== AI as Primary Interaction Surface\n\nThe conversational layer is not supplementary. Users interact with ARGUS primarily through CALYPSO, whether in the browser terminal or the headless CLI. The graphical elements (LCARS panels, workflow tracker, file browser) are visualization and state display; the terminal is where work happens.\n\nThis is different from both the sidebar model (where AI is secondary) and the autonomous model (where humans are secondary). ARGUS treats the AI-mediated terminal as the primary control surface while keeping the human firmly in the decision loop.\n\n=== Intent Interpretation, Not Action Selection\n\nCALYPSO interprets what the user wants and maps it to a known operation. It does not select from an open-ended action space. The routing chain is:\n\n1. Shell command parsing (exact match)\n2. Workflow dispatch (known workflow commands)\n3. Workflow pattern matching (interrogative forms)\n4. NL action intent resolution (imperative forms stripped to keywords)\n5. LLM fallback (open-ended queries, explanations, guidance)\n\nSteps 1–4 are deterministic. The LLM in step 5 provides guidance and explanation but does not execute state-changing operations directly. When the LLM detects an action intent (e.g., `[ACTION: HARMONIZE]`), it signals back to deterministic code that performs the actual execution.\n\nThis routing chain is a concrete instantiation of the Intent-Action Service pattern proposed for ChRIS (see <<Intent-Action Services (ChRIS Intent-Server)>>). The IAS formalizes the principle that clients should speak in intent and a distinct orchestration layer should resolve those intents into action sequences. CALYPSO applies that principle at the UI layer: the user speaks in natural language, the routing chain resolves intent deterministically where possible, and the LLM participates only when deterministic resolution is insufficient. The separation between intent acceptance and action execution is the same architectural move, whether the intent arrives as a structured API call or a conversational utterance.\n\n=== Data-State Grounded Truth\n\nThis is the deepest divergence. In most agentic systems, the model asserts what has happened: \"I've completed the task,\" \"the file has been created,\" \"training is done.\" The user trusts (or doesn't trust) these assertions.\n\nIn ARGUS, progress is proven by materialized artifacts. A cohort is gathered when `.cohort` exists in VFS. Data is harmonized when `.harmonized` exists. Training is complete when `train.py` is present and `.local_pass` confirms validation. Federation is done when `.federated` appears. The `WorkflowEngine` evaluates these conditions fresh on every query — it never caches or asserts completion from memory.\n\nThis model is inherited from ChRIS, where filesystem state _is_ computation state. It eliminates the class of bug where the AI's context drifts from reality in long-running workflows.\n\n=== Shared Core Across Surfaces\n\nThe same `CalypsoCore` instance runs in the browser and in the headless CLI server. There is no \"web version\" and \"CLI version\" with separate logic. This means:\n\n- Behavior is identical regardless of surface\n- Tests written against one surface validate both\n- ORACLE integration tests exercise the same code path that users interact with\n\nThis architectural decision makes the agentic layer testable in a way that surface-specific implementations are not.\n\n=== Soft Enforcement Over Hard Gates\n\nARGUS uses educational warnings rather than hard blocks when users try to skip workflow stages. The first attempt produces a short warning. The second adds a detailed reason. The third allows the skip. This encodes a specific philosophy: the system should teach the workflow rather than enforce it rigidly, and expert users who understand the consequences should not be blocked.\n\nThis contrasts with both permissive systems (where the AI will do whatever the user asks) and restrictive systems (where unauthorized actions are refused outright).\n\n== The Three-Layer Grounding Model\n\nPure agentic systems suffer from context drift: the model's internal state diverges from reality over long interactions, leading to confabulation, stale recommendations, and whack-a-mole bug regressions. ARGUS addresses this with three layers of grounding:\n\n=== Layer 1: Deterministic Routing\n\n`workflowPatterns[]` and `actionIntent_resolve()` intercept workflow-relevant queries before they reach the LLM. Pattern-matched requests execute deterministically. The LLM never sees them and cannot misinterpret them.\n\n=== Layer 2: Context Injection\n\n`workflowContext_forLLM()` builds the LLM's context from live VFS queries at call time. The model receives ground truth about current workflow state — which stages are complete, what the next stage is, what artifacts exist — rather than relying on its memory of previous turns.\n\n=== Layer 3: Stage Directives\n\nHard-coded rules in the system prompt prevent the LLM from advising users to skip required steps or from asserting that steps are complete when the corresponding artifacts do not exist. These directives act as guardrails even when the LLM's own reasoning might lead to incorrect guidance.\n\nThe three layers are defense-in-depth. Layer 1 prevents most workflow queries from reaching the LLM. Layer 2 ensures the LLM has accurate context when it is consulted. Layer 3 constrains the LLM's output even if its reasoning is flawed.\n\n== What ARGUS Is Not\n\nExplicit anti-patterns help clarify boundaries:\n\n**Not autonomous.** ARGUS does not take actions without user participation. CALYPSO guides and dispatches, but the user decides. There is no background agent loop running unsupervised.\n\n**Not a chatbot wrapper.** The AI is not bolted onto an existing interface as an afterthought. The terminal and conversational layer is the primary interaction surface, architecturally integrated with the workflow engine, VFS, and state management.\n\n**Not framework-agnostic.** ARGUS is purpose-built for federated medical imaging workflows on the ATLAS platform. The SeaGaP-MP stage model, the specific VFS artifacts, and the workflow definitions are domain-specific. The _patterns_ may generalize, but the implementation does not pretend to be a general-purpose agentic framework.\n\n**Not a finished product.** ARGUS is a thought experiment made concrete — a live design and architectural blueprint. It is meant to be used and studied, not deployed as production infrastructure in its current form.\n\n== Open Questions\n\nHonest architecture documentation acknowledges what remains unresolved:\n\n**Multi-user concurrency.** The current model assumes a single user interacting with a single CALYPSO instance. How the data-state grounding model extends to concurrent users modifying shared workflow state is an open design problem.\n\n**Generalization beyond medical imaging.** The data-state approach works well for workflows with clear artifact boundaries (files, markers, trained models). Whether it generalizes to domains with less tangible state transitions — collaborative document editing, interactive data exploration, creative workflows — is untested.\n\n**Deterministic dispatch vs. flexible intent.** The routing chain prioritizes determinism over flexibility. As the set of supported operations grows, maintaining the pattern-matching layers becomes increasingly complex. At some point, the balance between deterministic safety and model-driven flexibility will need to be revisited.\n\n**LLM model dependency.** CALYPSO's guidance quality depends on the underlying model's capabilities. The grounding layers mitigate hallucination risk, but they do not eliminate the dependency on model quality for explanation, context synthesis, and conversational flow.\n\n**Offline and degraded-mode operation.** If the LLM backend is unavailable, CALYPSO's deterministic layers (shell commands, workflow dispatch, intent resolution) continue to work, but guidance and explanation degrade. The current architecture does not have a formal degraded-mode specification.\n\n== Further Reading\n\nFor the mathematical proof that agentic orchestration carries irreducible hallucination risk and why ARGUS's architecture is the necessary consequence, see `docs/agentic-safety.adoc`.",
    "architecture.adoc": "= ARGUS Architecture\n:toc:\n:toclevels: 3\n:sectnums:\n\n== Core Philosophy: Robust Vanilla\nARGUS avoids heavy frontend frameworks (React, Vue) to maintain maximum performance and \"snap.\" However, to avoid state desynchronization issues common in imperative Vanilla JS, we employ a **Pub/Sub (Observer) Pattern**.\n\n== State Management (Pub/Sub)\n\nThe application state is centralized in a `Store` that acts as the single source of truth. Components do not mutate state directly; they dispatch **Actions**. The Store mutates the state and broadcasts **Events**. Components subscribe to these events to update the UI.\n\n== Application Logic Layers\n\nThe application logic is decoupled into specialized providers and orchestrators.\n\n=== Calypso AI Core (Orchestrator)\n**`src/lcarslm/CalypsoCore.ts`**\n*   **Role**: Primary command execution pipeline.\n*   **Architecture**: Modular orchestrator that delegates to logic providers.\n*   **Pipeline**: 11-stage waterfall (Script -> Special -> Control Plane -> Confirmation -> Harmonize -> Shell -> Workflow -> Guidance -> Action -> LLM).\n\n=== Logic Providers (Capability Layer)\nAs of v9.0.0, heavy logic is isolated into specialized providers:\n*   **`SearchProvider`**: Dataset discovery and anaphora resolution.\n*   **`StatusProvider`**: System status and context generation.\n*   **`LLMProvider`**: LLM orchestration and intent parsing.\n*   **`CalypsoPresenter`**: Visual formatting and LCARS dialect markers.\n\n=== The Intent Layer (Local IAS)\n**`src/core/logic/ProjectManager.ts`**\n*   **Role**: Bridges high-level intents (\"Gather this dataset\") to low-level system operations (VFS mounting, Store mutation).\n*   **Architecture**: Implements the **Intent-Action Service (IAS)** pattern locally.\n\n== Virtual Computer System (VCS)\n\nThe VCS (`src/vfs/`) is ARGUS's stateful runtime environment. It provides a POSIX-like in-memory filesystem with content-aware files, a Shell interpreter, and a Provider architecture.\n\n=== Components\n\n[cols=\"1,2\"]\n|===\n| Component | Location\n\n| VirtualFileSystem\n| `src/vfs/VirtualFileSystem.ts` — Tree storage, content storage, path resolution, CWD, events.\n\n| Shell\n| `src/vfs/Shell.ts` — Command interpreter and environment manager.\n\n| ShellBuiltins\n| `src/vfs/ShellBuiltins.ts` — Implementation of 20+ POSIX builtins (ls, cd, python, upload, analyze, etc.).\n\n| ContentRegistry\n| `src/vfs/content/ContentRegistry.ts` — Maps file paths to content generators.\n\n| DatasetProvider\n| `src/vfs/providers/DatasetProvider.ts` — Builds `~/data/cohort/` from selected datasets.\n\n| ProjectProvider\n| `src/vfs/providers/ProjectProvider.ts` — Scaffolds `$HOME` + populates `~/src/project/`.\n|===\n\n=== Data Flow\n\n1.  **User types `cat train.py`** in the terminal.\n2.  **Terminal** sends raw input to the **Shell**.\n3.  **Shell** expands variables and delegates to **ShellBuiltins**.\n4.  **ShellBuiltins** calls `vfs.node_read()`.\n5.  **VFS** resolves content via the **ContentRegistry**.\n6.  **Shell** returns a `ShellResult` to the Terminal.\n\n== Data-State Workflow Semantics\n\nARGUS's workflow tracking follows the same data-state DAG model used by ChRIS at the compute layer. Progress is proven by the existence of materialized artifacts in the session tree (`~/sessions/`), not by controller assertions.\n\n=== Grounding the LLM\n\nThe data-state model prevents the LLM from drifting on workflow state via:\n*   **Deterministic routing**: Pattern matchers intercept status/progress queries.\n*   **Context injection**: `StatusProvider` builds stage summaries from live VFS.\n*   **Artifact validation**: `WorkflowAdapter` resolves position from materialized envelopes.\n\nSee `docs/vcs.adoc` and `docs/calypso.adoc` for full specifications.",
    "calypso.adoc": "= CALYPSO: The AI Core\n:revnumber: 9.0.0\n:revdate: 2026-02-16\n:toc: macro\n:toclevels: 3\n:sectnums:\n\ntoc::[]\n\n== Identity\n\n**Name:** CALYPSO\n**Acronym:** **C**ognitive **A**lgorithms & **L**ogic **Y**ielding **P**redictive **S**cientific **O**utcomes\n**Role:** The Intelligence Layer of the ARGUS System.\n\n=== Namesake\n\nCALYPSO carries a layered homage spanning Greek mythology and _Star Trek: Discovery_:\n\n**The Myth (Homer's Odyssey):** Calypso was a nymph who lived on the island of Ogygia. When the shipwrecked Odysseus washed ashore, she rescued him and kept him on her island for seven years, offering immortality if he would stay. Her name derives from the Greek _kalyptō_ — \"to conceal\" or \"to hide.\" Where the mythological Calypso concealed Odysseus _from_ the world, our CALYPSO conceals complexity _for_ the user.\n\n**Daughter of ATLAS:** In the ARGUS system hierarchy, CALYPSO is the _daughter_ of ATLAS — born from the infrastructure. ATLAS (the titan, the platform) bears the weight of the federated learning ecosystem. CALYPSO, his daughter, is the intelligence that emerges from that foundation, guiding users through the complexity her father supports.\n\n**Star Trek: Discovery — \"Calypso\" (Short Treks, 2018):** The name is a direct reference to the _Star Trek: Short Treks_ episode **\"Calypso\"**, which is part of the _Discovery_ storyline. In this episode, set a thousand years after _Discovery_'s final mission, a wounded soldier named Craft is rescued by **Zora** — the USS _Discovery_'s evolved artificial intelligence. Like the mythological nymph, Zora nurses Craft back to health, forms a bond with him, and ultimately helps him return home to his family. The _Discovery_ series finale (2024) revealed that Zora waited alone for a millennium, maintaining the ship in a nebula, to ensure this encounter would happen.\n\n**The Double Homage:** ARGUS pays tribute to Star Trek twice over:\n\n1. The entire visual language is **LCARS** — the Library Computer Access/Retrieval System designed by Michael Okuda for _The Next Generation_. This is the same interface paradigm that Zora would have used aboard _Discovery_.\n\n2. The name \"Calypso\" directly invokes Zora's episode — an AI manifesting through LCARS, patiently guiding users through unfamiliar territory, concealing complexity so they can focus on their mission and eventually reach their destination. Like Zora, our CALYPSO is the daughter of her ship — born from the infrastructure, waiting to help.\n\n== Lore & Function\n\nCALYPSO is the \"Ghost in the Machine\" — the daughter of ATLAS, the artificial intelligence that bridges the gap between the human user and the massive, federated complexity of her father's network.\n\nWhile ARGUS provides the guided framework (the body), CALYPSO provides the logic and natural language understanding (the mind). Born from the infrastructure, she is responsible for:\n\n*   **Cohort Discovery:** Translating vague human intent (\"Show me brain scans\") into precise database queries.\n*   **Context Management:** Remembering user session state, selected datasets, and project context.\n*   **Workflow Guidance:** Suggesting the next logical steps in the SeaGaP (Search, Gather, Process) pipeline.\n*   **Knowledge Retrieval:** She has read-access to the full system documentation (`docs/*.adoc`) and can explain architecture, file structures, and workflows on demand.\n\n== Architecture: The Modular Core\n\nAs of v9.0.0, Calypso is architected as a **modular orchestrator** that delegates logic to specialized providers. This separation of concerns ensures that the core remains a thin, maintainable pipeline while presentation and heavy logic are isolated.\n\n=== The Layer Model\n\n[source]\n----\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                           PRESENTATION LAYER                                │\n│   (Environment-specific adapters)                                           │\n├─────────────────────────────────────────────────────────────────────────────┤\n│                                                                             │\n│   BrowserAdapter          CLIAdapter            NodeAdapter                 │\n│   ┌─────────────┐        ┌─────────────┐       ┌─────────────┐             │\n│   │ Terminal UI │        │   stdout    │       │ Test Harness│             │\n│   │ DOM updates │        │   readline  │       │ Assertions  │             │\n│   └──────┬──────┘        └──────┬──────┘       └──────┬──────┘             │\n│          │                      │                     │                     │\n└──────────┼──────────────────────┼─────────────────────┼─────────────────────┘\n           │                      │                     │\n           └──────────────────────┼─────────────────────┘\n                                  │\n                    CalypsoResponse (actions + message)\n                                  │\n┌─────────────────────────────────┼───────────────────────────────────────────┐\n│                                 ▼                                           │\n│                         CALYPSO CORE (Orchestrator)                         │\n│   (Thin pipeline, logic-free)                                               │\n├─────────────────────────────────────────────────────────────────────────────┤\n│                                                                             │\n│   CalypsoCore.ts (Pipeline Stages)                                          │\n│   1. Script Capture  4. Control Plane  7. Shell (Builtins)  10. Action Match│\n│   2. Special Cmds    5. Confirmations  8. Workflow Dispatch 11. LLM Query  │\n│   3. Script UX       6. Harmonize      9. Guidance                          │\n│                                                                             │\n├──────────┬──────────────────────┬─────────────────────┬─────────────────────┤\n│          ▼                      ▼                     ▼                     │\n│   LOGIC PROVIDERS        PRESENTATION          ROUTERS               UTILS  │\n│   ┌──────────────┐      ┌──────────────┐      ┌──────────────┐      ┌─────┐ │\n│   │ SearchProv   │      │ CalypsoPres  │      │ ControlPlane │      │ VFS │ │\n│   │ StatusProv   │      │ (ANSI/Trek)  │      │ ActionRouter │      │ Snap│ │\n│   │ LLMProv      │      └──────────────┘      └──────────────┘      └─────┘ │\n│   └──────────────┘                                                          │\n└─────────────────────────────────────────────────────────────────────────────┘\n----\n\n=== CalypsoCore\n\nThe `CalypsoCore` class is the central pipeline orchestrator. It manages the flow of user input through a series of deterministic handlers before falling back to the LLM.\n\n**Integration with Providers:**\nCalypso delegates all complex logic to specialized providers:\n1.  **SearchProvider**: Handles dataset discovery, anaphora resolution (`that`, `them`), and search snapshots.\n2.  **StatusProvider**: Generates system status blocks, version info, and LLM context summaries.\n3.  **LLMProvider**: Orchestrates LLM queries and processes responses via the `IntentParser`.\n4.  **CalypsoPresenter**: Centralizes all visual formatting (ANSI decorators, LCARS markers `●/○`).\n\n[source,typescript]\n----\n// src/lcarslm/CalypsoCore.ts\n\nexport class CalypsoCore {\n    /** Primary command execution pipeline (11 stages). */\n    public async command_execute(input: string): Promise<CalypsoResponse> {\n        // 1. Check script capture\n        // 2. Check special commands (/, snapshots, reset)\n        // 3. Check script discovery\n        // 4. Check control plane intents\n        // 5. Check confirmation gates\n        // 6. Check first-class harmonize\n        // 7. Check shell builtins (delegated to ShellBuiltins)\n        // 8. Check workflow dispatch (manifest-driven)\n        // 9. Check guidance interrogatives\n        // 10. Check imperative action matches\n        // 11. Fall back to LLMProvider\n    }\n}\n----\n\n=== CalypsoResponse\n\nInstead of directly manipulating the DOM, CalypsoCore returns a structured response. Adapters interpret the response according to their environment.\n\n[source,typescript]\n----\nexport interface CalypsoResponse {\n    /** Text message to display */\n    message: string;\n\n    /** Actions for the adapter to execute */\n    actions: CalypsoAction[];\n\n    /** Whether the operation was successful */\n    success: boolean;\n\n    /** Optional state snapshot for verification */\n    state?: {\n        vfs?: VfsSnapshotNode;\n        store?: Partial<AppState>;\n    };\n}\n----\n\n=== Logic Providers Reference\n\n[cols=\"1,2,2\"]\n|===\n| Provider | Responsibilities | Location\n\n| `SearchProvider`\n| Discovery, Anaphora, Snapshots\n| `src/lcarslm/SearchProvider.ts`\n\n| `StatusProvider`\n| Status blocks, Version, Context\n| `src/lcarslm/StatusProvider.ts`\n\n| `LLMProvider`\n| Query orchestration, Intent parsing\n| `src/lcarslm/LLMProvider.ts`\n\n| `CalypsoPresenter`\n| ANSI formatting, Tables, Markers\n| `src/lcarslm/CalypsoPresenter.ts`\n|===\n\n== Operating Modes\n\nCalypso can run in three modes:\n\n=== Browser Mode (Full ARGUS)\n\nThe traditional mode where Calypso runs inside the ARGUS web application.\n\n[source,bash]\n----\n$ make serve\n# Open http://localhost:8080\n# Calypso is available in the Intelligence Console\n----\n\n=== Headless Mode (Standalone Server)\n\nCalypso runs as a Node.js server without a browser. Useful for testing, scripting, and CLI interaction.\n\n[source,bash]\n----\n$ make calypso\nStarting Calypso Server on :8081...\nCalypsoCore initialized (VFS: 47 nodes, Store: clean)\nReady for connections.\n----\n\n=== CLI Mode (Interactive REPL)\n\nA command-line client connects to the headless server. The CLI provides an SSH-style login experience, dynamic prompt with username and working directory, a spinner during async operations, and markdown-to-ANSI rendering of LLM responses.\n\n[source,bash]\n----\n$ make calypso-cli\n╔══════════════════════════════════════════════════════════════╗\n║  CALYPSO CORE V9.0.0                                         ║\n║  Cognitive Algorithms & Logic Yielding Predictive Scientific ║\n║  Outcomes                                                    ║\n╚══════════════════════════════════════════════════════════════╝\nConnected to localhost:8081\n----\n\n== Source Structure\n\nAs of v9.0.0, the Calypso service is organized into logic providers and routing modules:\n\n[source]\n----\nsrc/lcarslm/                        # CalypsoCore — the AI brain\n├── CalypsoCore.ts                  #   The Thin Orchestrator\n├── CalypsoPresenter.ts             #   The Visual Language Layer\n├── SearchProvider.ts               #   Discovery & Anaphora\n├── StatusProvider.ts               #   System & Context Summaries\n├── LLMProvider.ts                  #   LLM Query Orchestrator\n├── engine.ts                       #   LCARSEngine: LLM client wrapper\n├── types.ts                        #   CalypsoResponse, CalypsoAction, Intent\n├── federation/\n│   ├── FederationOrchestrator.ts   #   Workflow Handshake\n│   └── FederationContentProvider.ts#   Artifact Generation\n├── routing/\n│   ├── ActionRouter.ts             #   Imperative Intent Routing\n│   ├── ControlPlaneRouter.ts       #   Automation Intents\n│   └── IntentParser.ts             #   LLM Result Parsing\n├── utils/\n│   └── VfsUtils.ts                 #   VFS Snapshotting & Serialization\n└── scripts/\n    └── ScriptRuntime.ts            #   .clpso script execution\n----\n\nNOTE: For the full service architecture specification, see `docs/calypso-architecture.adoc`.\n\n== Integration with ORACLE\n\nThe modular architecture enables precise ORACLE testing. Tests can now assert on specific provider state (e.g., SearchProvider's anaphora buffer) or verify that the orchestrator routes to the correct deterministic handler before hitting the LLM.\n\n---\n_Last updated: 2026-02-16 (v9.0.0)_",
    "dag-engine.adoc": "= DAG Engine Specification\n:author: ATLAS Project Team\n:revdate: 2026-02-16\n:revnumber: 9.0.0\n:toc: macro\n:toclevels: 3\n:sectnums:\n\ntoc::[]\n\n== Overview\n\nThe DAG engine (`src/dag/`) is the foundational layer of ARGUS responsible for defining, materializing, and verifying workflow execution as a directed acyclic graph.\n\n=== What It Is\n\nA directed acyclic graph (DAG) is a graph where each node is a workflow stage (search, gather, harmonize, etc.) and each edge represents a dependency. The DAG captures the full topology of a workflow — which stages exist, how they relate, and where they branch or join.\n\n=== Why It Exists (Data-State Grounding)\n\nARGUS follows **ChRIS data-state DAG semantics**: progress is proven by materialized artifacts, not asserted by controllers or counters. Before the DAG engine, sequencing was delegated to LLM inference, which drifted. The DAG engine makes sequencing deterministic by reading from YAML manifests.\n\n== Design Principles\n\n1. **Every Stage Produces an Artifact.** Every stage materializes an `ArtifactEnvelope` into its `data/` directory in the session tree. The presence of this JSON file is the *only* proof of completion.\n2. **Backward Pointers.** Each stage declares its `previous` stage(s). This naturally supports linear sequences, branching, and joining (topological joins).\n3. **Logic-Presentation Separation.** Manifests define the *what* (topology, instructions), while the `HANDLER_REGISTRY` in `CalypsoCore` defines the *how* (deterministic logic).\n\n== Manifest Format (v9.0.0)\n\nA manifest is a YAML document living in `src/dag/manifests/` that defines a complete persona workflow.\n\n=== Stage Definition\n\nEach stage in the `stages` list has the following fields:\n\n[cols=\"1,1,3\"]\n|===\n| Field | Required | Description\n\n| `id`\n| yes\n| Unique identifier (snake_case, e.g., `federate-brief`). Used as the directory name in the session tree.\n\n| `handler`\n| yes\n| **The Logic Link.** The ID of the capability registered in `CalypsoCore`'s `HANDLER_REGISTRY`. This ties the YAML stage to an entry point in the code.\n\n| `commands`\n| yes\n| List of exact strings the user can type to trigger this stage (e.g., `harmonize`, `add <dataset>`).\n\n| `completes_with`\n| no\n| **Completion Alias.** If set to another stage ID, this stage is considered complete if the *target* stage has an artifact. Used when multiple stages share a single result (e.g., `search` and `rename` both alias to `gather`).\n\n| `previous`\n| yes\n| Parent stage(s). `~` for root. Single string for linear. Array `[a, b]` for join nodes.\n\n| `produces`\n| yes\n| Filename(s) to materialize (usually `[stageId].json`).\n\n| `instruction`\n| yes\n| The guidance text presented to the user. The LLM reads this field to provide deterministic guidance.\n\n| `optional`\n| yes\n| If `true`, the stage can be bypassed without warning (materializes a skip sentinel).\n\n| `parameters`\n| no\n| Default configuration map for the stage logic.\n|===\n\n== Linking YAML to Code: The Handler Registry\n\nThe `handler` field in the manifest is the key that unlocks deterministic execution. When a user types a command that matches a stage, `CalypsoCore` looks up the corresponding handler in its registry.\n\n=== `HANDLER_REGISTRY` (`src/lcarslm/CalypsoCore.ts`)\n\nThe registry maps `handler` strings from YAML to TypeScript methods or closures:\n\n[source,typescript]\n----\nprivate readonly HANDLER_REGISTRY: Record<string, WorkflowHandler> = {\n    'search':    (_, args) => this.workflow_search(args.join(' ')),\n    'gather':    async (cmd, args) => { ... },\n    'harmonize': () => this.workflow_harmonize(),\n    'scaffold':  (_, args) => this.workflow_proceed(args[0]),\n    'federation': (cmd, args) => this.workflow_federationCommand(cmd, args),\n};\n----\n\n**How it works:**\n1. User types `harmonize`.\n2. `WorkflowAdapter` identifies that `harmonize` belongs to stage `id: harmonize`.\n3. The stage definition specifies `handler: harmonize`.\n4. `CalypsoCore` invokes `HANDLER_REGISTRY['harmonize']`.\n5. The handler executes logic (VFS mutation, store update).\n6. **Automatic Orchestration:** On success, `CalypsoCore` automatically marks the stage complete and materializes the `ArtifactEnvelope`.\n\n== Completion Aliasing (`completes_with`)\n\nSome stages do not produce their own unique artifact but are \"subsumed\" by a later stage.\n\n*   **Example**: `search` and `rename` are part of the gathering phase. They are only \"complete\" once the user has actually run `gather` and created a project.\n*   **YAML Config**:\n[source,yaml]\n----\n- id: search\n  handler: search\n  completes_with: gather  # Checks ~/sessions/.../gather/data/gather.json\n----\n\nThis allows the UI to show `search` as complete as soon as the project is created, providing a better user experience without requiring every micro-action to have a unique artifact.\n\n== Session Tree Structure\n\nThe session tree materializes the DAG as a physical directory structure under `~/sessions/<persona>/session-<id>/`. Every stage, including the root, is explicitly nested to preserve clear provenance.\n\n[source]\n----\n~/sessions/fedml/session-123/\n  search/                  # Stage: search (Root)\n    data/\n      search.json          # Artifact name from manifest\n    gather/                # Stage: gather (Child of search)\n      data/\n        gather.json\n      rename/              # Stage: rename (Child of gather)\n        data/\n          rename.json\n        harmonize/         # Stage: harmonize (Child of rename)\n          data/\n            harmonize.json\n----\n\nThe nesting strictly encodes the DAG path. A stage is considered \"Complete\" if the artifact filename defined in its manifest `produces` field exists at its topological path.\n\n== Verification and Fingerprinting\n\nEvery artifact carries a **Merkle Fingerprint**:\n- `_fingerprint`: SHA-256(content + parent fingerprints).\n- `_parent_fingerprints`: Map of parent IDs to their fingerprints at execution time.\n\nIf a user goes back to an earlier stage (e.g., `gather`) and re-executes it with different data, the fingerprint changes. The `Chain` validator detects that downstream stages (e.g., `harmonize`) now have mismatched parent fingerprints and flags them as **Stale**.\n\n---\n_Last updated: 2026-02-16 (v9.0.0)_",
    "framework.adoc": "= ARGUS Framework Patterns\n:author: ATLAS Project Team\n:revdate: 2026-01-30\n:toc:\n:sectnums:\n\n== Purpose\n\nARGUS is built without a frontend framework (React, Vue, Svelte). Reactivity, component lifecycle, and DOM ownership are handled through project-specific patterns that have emerged organically during development. This document codifies those patterns as they exist today -- not as aspirational design, but as working conventions extracted from the codebase.\n\nThe goal is threefold:\n\n1. **Onboarding**: A new developer (human or AI) can read this document and understand how to add features without reverse-engineering implicit conventions.\n2. **Consistency**: Named patterns are referenceable. \"Use the slot pattern\" is an actionable instruction.\n3. **Guard rails**: Documented anti-patterns prevent re-invention of known mistakes.\n\n== Naming Convention: RPN\n\nAll functions follow **Reverse Polish Notation**: `<subject>_<verb>`.\n\n[source,typescript]\n----\n// Good\nfunction workspace_expand(): void { ... }\nfunction cohortTree_build(datasets: DatasetInput[]): FileNode { ... }\nfunction detailHeader_populate(asset, id, overlay, lcarsFrame): void { ... }\n\n// Bad\nfunction expandWorkspace(): void { ... }\nfunction buildCohortTree(datasets: DatasetInput[]): FileNode { ... }\n----\n\nThe subject is the thing being acted on. The verb is the action. This applies to:\n\n- Module-level functions: `catalog_search()`, `projectStrip_render()`\n- Class methods: `browser.trees_set()`, `browser.tab_switch()`, `shell.env_set()`\n- Store actions: `store.project_load()`, `store.marketplace_toggle()`\n- Event handlers: `selectionToggle_handle()`, `terminalCommand_handle()`\n\nPrivate helpers follow the same convention: `descendantPaths_collect()`, `imageWebUrl_resolve()`.\n\n== State Management: Store + EventBus\n\n=== Architecture\n\nApplication state is centralized in a single `Store` class (`src/core/state/store.ts`). The store holds:\n\n- **Reactive state** (`ExtendedState`): current stage, selected datasets, active project, training job, installed assets.\n- **Global singletons** (`globals`): terminal, VCS, shell, frame slot, AI engine.\n\nAll mutations go through Store actions, which emit typed events via the `EventBus` (`src/core/state/events.ts`).\n\n[source,typescript]\n----\n// Store action\npublic stage_set(stage: AppState['currentStage']): void {\n    this._state.currentStage = stage;\n    events.emit(Events.STAGE_CHANGED, stage);\n    events.emit(Events.STATE_CHANGED, this._state);\n}\n\n// Consumer subscribes\nevents.on(Events.STAGE_CHANGED, (newStage): void => {\n    stageContent_update(newStage);\n});\n----\n\n=== The `globals` Object\n\nThe `globals` bag on the Store holds runtime singletons that don't belong in serializable state:\n\n[cols=\"1,2\"]\n|===\n| Key | Type\n\n| `terminal` | `LCARSTerminal \\| null`\n| `vcs` | `VirtualFileSystem`\n| `shell` | `Shell \\| null`\n| `frameSlot` | `FrameSlot \\| null`\n| `lcarsEngine` | `LCARSEngine \\| null`\n| `lossChart` | `{ ctx, data } \\| null`\n| `trainingInterval` | `number \\| null`\n|===\n\nAccess via `import { globals } from '../state/store.js'`.\n\nIMPORTANT: The VCS instance is `globals.vcs`, not `globals.vfs`. This has caused bugs.\n\n=== Event Types\n\nAll events are typed via the `EventPayloads` interface. The compiler enforces payload types at both emit and subscribe sites:\n\n[source,typescript]\n----\nexport enum Events {\n    STATE_CHANGED       // payload: AppState\n    STAGE_CHANGED       // payload: AppState['currentStage']\n    DATASET_SELECTION_CHANGED  // payload: Dataset[]\n    PROJECT_LOADED      // payload: Project | null\n    VFS_UPDATED         // payload: void\n    VFS_CHANGED         // payload: VfsChangeEvent\n    CWD_CHANGED         // payload: CwdChangeEvent\n}\n----\n\n=== Rules\n\n1. **Never mutate `state` directly from outside the Store.** Use Store actions.\n2. **Emit `STATE_CHANGED` after every mutation.** Consumers may depend on any field.\n3. **`globals` is mutable by design** -- singletons are initialized at boot and nulled on teardown. Guard access with null checks.\n\n== The Command Router Pattern\n\n=== Problem\nThe main application entry point (`argus.ts`) should be an orchestrator, not a logic handler. Routing string commands (e.g., \"search\", \"mount\", \"federate\") in a massive switch statement inside `argus.ts` couples it tightly to every feature.\n\n=== Solution\nDelegate all command logic to a dedicated router (`src/core/logic/commands.ts`).\n\n[source,typescript]\n----\n// argus.ts (Entry Point)\nimport { command_dispatch } from './core/logic/commands.js';\nterminal.fallback_set(command_dispatch);\n\n// commands.ts (Router)\nexport async function command_dispatch(cmd: string, args: string[]): Promise<void> {\n    const core = core_get();\n    if (!core) return;\n\n    const input = [cmd, ...args].join(' ').trim();\n    const response = await core.command_execute(input);\n    browserAdapter.response_apply(response);\n}\n----\n\n== The Stage Lifecycle Pattern\n\n=== Problem\nStage transitions (Search -> Process) require setup and teardown logic (e.g., opening the terminal, populating the IDE). Hardcoding this in `argus.ts` makes it a \"God Object.\"\n\n=== Solution\nInvert control. Each stage module exports `stage_enter()` and `stage_exit()` hooks. The orchestrator simply calls them.\n\n[source,typescript]\n----\n// src/core/stages/process.ts\nexport function stage_enter(): void {\n    projectDir_populate(...);\n    globals.frameSlot.frame_open();\n}\nexport function stage_exit(): void {\n    // Cleanup\n}\n\n// argus.ts\nconst newHandler = STAGE_HANDLERS[stageName];\nif (newHandler) newHandler.stage_enter();\n----\n\n== The Window Binding Registry Pattern\n\n=== Problem\nHTML `onclick=\"myFunc()\"` requires `myFunc` to be on `window`. Scattering `window.foo = foo` assignments throughout the codebase is untidy and bypasses type safety.\n\n=== Solution\nCentralize all bindings in `src/core/logic/WindowBindings.ts`. This provides a single manifest of the application's public DOM API.\n\n[source,typescript]\n----\n// WindowBindings.ts\ndeclare global {\n    interface Window {\n        myFunction: typeof myFunction;\n    }\n}\n\nexport function windowBindings_initialize(): void {\n    window.myFunction = myFunction;\n}\n----\n\n== The Slot Pattern\n\n=== Problem\n\nMultiple consumers need to display different content inside a shared DOM container (e.g., the asset detail overlay is used by marketplace, project detail, and dataset detail). The naive approach -- rewriting `innerHTML` on open and restoring it on close -- is fragile. If any consumer forgets to restore, the next consumer inherits corrupted DOM.\n\n=== Solution\n\nThe shared container holds the **default consumer's** content as static HTML. Additional consumers get empty **slot containers** -- `<div>` elements that are hidden by default and shown on demand via a CSS `data-mode` attribute.\n\n==== DOM Structure\n\n[source,html]\n----\n<div id=\"asset-detail-overlay\" data-mode=\"marketplace\">\n    <!-- Original marketplace content (never mutated) -->\n    <div class=\"lcars-sidebar\">...</div>\n    <div id=\"overlay-sidebar-slot\" class=\"lcars-sidebar overlay-slot\"></div>\n\n    <div class=\"lcars-content\">...</div>\n    <div id=\"overlay-content-slot\" class=\"lcars-content overlay-slot\"></div>\n\n    <div class=\"detail-command-column\">...</div>\n    <div id=\"overlay-command-slot\" class=\"detail-command-column overlay-slot\"></div>\n</div>\n----\n\n==== CSS Visibility Rules\n\n[source,css]\n----\n/* Default mode: hide slots */\n#asset-detail-overlay[data-mode=\"marketplace\"] .overlay-slot {\n    display: none !important;\n}\n\n/* Project/dataset modes: hide originals, show slots */\n#asset-detail-overlay[data-mode=\"project\"] .lcars-sidebar:not(.overlay-slot),\n#asset-detail-overlay[data-mode=\"project\"] .lcars-content:not(.overlay-slot),\n#asset-detail-overlay[data-mode=\"project\"] .detail-command-column:not(.overlay-slot) {\n    display: none !important;\n}\n----\n\n==== Consumer Contract\n\nOpening a non-default consumer:\n\n[source,typescript]\n----\n// 1. Set mode\noverlay.dataset.mode = 'project';\n\n// 2. Write into slots (never touch originals)\nconst sidebarSlot = document.getElementById('overlay-sidebar-slot');\nsidebarSlot.innerHTML = '...';\n\nconst contentSlot = document.getElementById('overlay-content-slot');\ncontentSlot.innerHTML = '...';\n\nconst commandSlot = document.getElementById('overlay-command-slot');\ncommandSlot.innerHTML = '...';\n----\n\nClosing a non-default consumer:\n\n[source,typescript]\n----\n// 1. Clear slots\noverlaySlots_clear();\n\n// 2. Reset mode -- CSS shows originals, hides (now-empty) slots\noverlay.dataset.mode = 'marketplace';\n----\n\nThe `overlaySlots_clear()` helper is defined in `search.ts`:\n\n[source,typescript]\n----\nfunction overlaySlots_clear(): void {\n    const sidebarSlot = document.getElementById('overlay-sidebar-slot');\n    const contentSlot = document.getElementById('overlay-content-slot');\n    const commandSlot = document.getElementById('overlay-command-slot');\n    if (sidebarSlot) sidebarSlot.innerHTML = '';\n    if (contentSlot) contentSlot.innerHTML = '';\n    if (commandSlot) commandSlot.innerHTML = '';\n}\n----\n\n=== When to Use\n\nUse the slot pattern whenever multiple consumers share a DOM container. The default consumer's content stays as static HTML. Each additional consumer gets a slot.\n\n=== Anti-Pattern: innerHTML Restore\n\n[WARNING]\n====\n*Do not* cache `innerHTML` on open and restore it on close. This was the original approach in ARGUS (`detailContent_restore()`). It failed when `datasetDetail_populate()` replaced the command column's `innerHTML` with DONE/ADD/CANCEL pills, but `datasetDetail_close()` only restored `.lcars-content` -- not the command column. When a marketplace asset was opened next, it showed gather pills instead of INSTALL/CLOSE.\n\nThe slot pattern eliminates this entire class of bug. The marketplace's original DOM is never read, cached, or written. Mode switching is pure CSS visibility.\n====\n\n== The Populate / Teardown Lifecycle\n\n=== The Pattern\n\nEvery overlay consumer follows the same implicit lifecycle:\n\n----\npopulate → show → [expand] → [collapse] → close → clear\n----\n\n[cols=\"1,3\"]\n|===\n| Phase | Responsibility\n\n| **populate** | Write content into the appropriate containers (slots or originals). Set LCARS hue, header fields, event listeners.\n| **show** | Remove `hidden` / `closing` classes from the overlay. Trigger slide-in animation.\n| **expand** _(optional)_ | Transform the overlay into a workspace layout (split-pane, resize handles).\n| **collapse** _(optional)_ | Reverse workspace expansion. Remove resize handles, restore layout.\n| **close** | Trigger slide-out animation. On `animationend`, add `hidden` class.\n| **clear** | Clear slot innerHTML, reset `data-mode`, destroy component instances (FileBrowser).\n|===\n\n=== Critical Rule: Teardown Before Stage Transition\n\n[IMPORTANT]\n====\nAny code that transitions away from an active workspace **MUST** call `workspace_teardown()` first. The workspace sets `display: none` on the search stage content, adds `workspace-active` to the right-frame, and keeps the asset-detail overlay visible. If these aren't reversed, the destination stage's content renders behind the overlay and is invisible.\n\nThis rule was learned when `federationHandshake_run()` in `process.ts` called `stage_advanceTo('monitor')` without collapsing the workspace. The monitor stage content was correctly activated but invisible behind the expanded overlay.\n====\n\n`workspace_teardown()` is the canonical cleanup function:\n\n[source,typescript]\n----\nexport function workspace_teardown(): void {\n    if (isWorkspaceExpanded) {\n        workspace_collapse();    // resize handles, layout, stage content\n    }\n    overlay.classList.add('hidden');\n    overlay.dataset.mode = 'marketplace';\n    overlaySlots_clear();\n    if (globals.frameSlot?.state_isOpen()) {\n        globals.frameSlot.frame_close();\n    }\n}\n----\n\n== The Component Pattern\n\nARGUS uses two styles of reusable UI element: **class components** and **render functions**.\n\n=== Class Components\n\nUsed when the component has internal state, event listeners, or a destroy lifecycle.\n\n==== FileBrowser\n\n`src/ui/components/FileBrowser.ts`\n\nThe most complex component. Renders a VFS file tree with preview pane, supports multiple named tabs, and an optional selectable mode for gathering.\n\n**Constructor options:**\n[source,typescript]\n----\ninterface FileBrowserOptions {\n    treeContainer: HTMLElement;\n    previewContainer: HTMLElement;\n    vfs: VirtualFileSystem;\n    projectBase: string;\n    selectable?: boolean;\n    onSelectionChange?: (selectedPaths: string[]) => void;\n}\n----\n\n**Public API (RPN convention):**\n[cols=\"2,3\"]\n|===\n| Method | Purpose\n\n| `trees_set(trees)` | Set named tree roots (e.g. `{ source: srcNode, data: dataNode }`)\n| `tab_switch(tabId)` | Switch active tree and re-render\n| `tree_render()` | Render active tree into DOM\n| `preview_show(path, display)` | Read VFS content, syntax-highlight, display in preview pane\n| `activeTab_get()` | Return current tab ID\n| `selection_get()` | Return selected file paths (selectable mode)\n| `selection_clear()` | Clear all selections\n| `selectionSubtree_extract(root)` | Return pruned tree containing only selected files + skeleton dirs\n| `destroy()` | Clear DOM references, timers, callbacks\n|===\n\n**Selectable mode**: Activated via `selectable: true`. Short click = preview. Long press (500ms) = toggle selection. Long press on folder cascades to all descendants.\n\n**Lifecycle rule**: Always call `destroy()` before discarding a FileBrowser instance. The component holds event listeners that will leak otherwise.\n\n==== FrameSlot\n\n`src/ui/components/FrameSlot.ts`\n\nOrchestrates the two-phase \"double whammy\" animation (frame separation + content slide-in). See `docs/visual_language.adoc` for the animation spec.\n\n==== LCARSTerminal\n\n`src/ui/components/Terminal.ts`\n\nGlobal singleton terminal with command registration, AI mode, and status bar.\n\n=== Render Functions\n\nUsed for stateless, declarative HTML generation. No lifecycle, no event listeners (those are attached by the caller via `onclick` strings).\n\n==== AssetCard\n\n`src/ui/components/AssetCard.ts`\n\nReturns an HTML string for a grid tile. Used by both Marketplace and Search stages.\n\n[source,typescript]\n----\ninterface AssetCardOptions {\n    id: string;\n    type: string;\n    title: string;\n    description: string;\n    metaLeft: string;\n    metaRight: string;\n    badgeText: string;\n    badgeRightText?: string;\n    isInstalled?: boolean;\n    onClick: string;          // onclick handler as string\n    actionButton?: { label, activeLabel?, onClick, isActive? };\n}\n\nconst html: string = render_assetCard(opts);\ncontainer.innerHTML = cards.map(render_assetCard).join('');\n----\n\n**Note**: `onClick` is a string (e.g. `\"assetDetail_open('abc')\"`), not a function reference. This is because the HTML is inserted via `innerHTML`. The target function must be exposed on `window` via typed declarations:\n\n[source,typescript]\n----\n// Use WindowBindings.ts registry\ndeclare global {\n    interface Window {\n        assetDetail_open: typeof assetDetail_open;\n    }\n}\n----\n\n=== Choosing Between Styles\n\n[cols=\"1,1,3\"]\n|===\n| Style | Example | When to Use\n\n| Class component | FileBrowser | Has internal state, event listeners, needs explicit destroy\n| Render function | AssetCard | Stateless HTML generation, no lifecycle\n|===\n\n== The Provider Pattern\n\nProviders translate domain data into VCS filesystem trees. They are pure functions that take domain objects and return `FileNode` trees suitable for mounting.\n\n=== Existing Providers\n\n[cols=\"2,3,2\"]\n|===\n| Provider | Purpose | Location\n\n| `DatasetProvider` | Builds cohort tree from datasets (`/data/training/`, `/data/validation/`) | `src/vfs/providers/DatasetProvider.ts`\n| `ProjectProvider` | Scaffolds project directory (`~/projects/{name}/src/`, config files) | `src/vfs/providers/ProjectProvider.ts`\n| `MarketplaceProvider` | Installs assets to VCS (`/bin/`, `/data/sets/`, `~/models/`) | `src/vfs/providers/MarketplaceProvider.ts`\n|===\n\n=== Contract\n\nA provider:\n\n1. Accepts domain data (datasets, project config, marketplace asset) as input.\n2. Returns a `FileNode` tree (or mutates the VCS directly for `MarketplaceProvider`).\n3. Uses `contentGenerator` strings for lazy file content (evaluated by `ContentRegistry` on read).\n4. Sets `metadata` on nodes for consumer-specific data (e.g., `imageWebBase` for web-servable image URLs).\n\n=== Usage Pattern\n\n[source,typescript]\n----\nimport { cohortTree_build } from '../../vfs/providers/DatasetProvider.js';\n\n// Build tree\nconst dataRoot: VcsFileNode = cohortTree_build(project.datasets);\n\n// Mount into VCS\nglobals.vcs.tree_unmount(`${projectBase}/data`);\nglobals.vcs.tree_mount(`${projectBase}/data`, dataRoot);\n----\n\nAlways `tree_unmount` before `tree_mount` to avoid stale data from a previous mount.\n\n== The Strip Pattern\n\nA horizontal bar of compact chips that persists across context changes. Used for the project strip at the top of the Search stage.\n\n=== Structure\n\n[source,html]\n----\n<div class=\"project-strip\" id=\"project-strip\">\n    <!-- Populated by projectStrip_render() -->\n</div>\n----\n\nThe strip is re-rendered on every state change by calling `projectStrip_render()`. Chips have click handlers attached after render via `addEventListener` (not inline `onclick`).\n\n=== Visual States\n\n[cols=\"1,3\"]\n|===\n| State | Appearance\n\n| Default | Honey border, dark background, `border-radius: 100vmax` (LCARS pill)\n| Active (gather target) | Solid honey background, black text, glow\n| New project | Dashed harvestgold border\n|===\n\n=== Interaction\n\n- First click: set as gather target.\n- Second click (already active): open detail overlay.\n- \"+ NEW\" chip: clear gather target, enter new-project mode.\n\n== The Selectable Mode Pattern\n\nAny tree-based component can support granular selection via long-press interaction.\n\n=== Activation\n\nPass `selectable: true` to the component constructor. The component manages its own `selectedPaths: Set<string>` and reports changes via the `onSelectionChange` callback.\n\n=== Interaction Model\n\n[cols=\"1,3\"]\n|===\n| Gesture | Effect\n\n| Short click (< 500ms) on file | Preview file content (standard behavior)\n| Short click on folder | Toggle folder open/closed\n| Long press (>= 500ms) on file | Toggle selection of individual file\n| Long press on folder | Toggle all descendant files (select all / deselect all)\n|===\n\n=== Subtree Extraction\n\nAfter selection, call `selectionSubtree_extract(root)` to get a pruned copy of the tree containing only selected files and the directory skeleton needed to reach them. This is used by the gather flow to mount partial datasets into a project's VCS tree.\n\n=== Visual Feedback\n\nSelected items receive the `.selected-for-gather` CSS class: canary left-border, subtle background tint, checkmark prefix.\n\n== CSS Architecture\n\n=== File Organization\n\n[cols=\"2,3\"]\n|===\n| File | Scope\n\n| `dist/css/lcars.css` | Global layout, frame, bars, project strip, workspace handles, selection visuals\n| `dist/css/lcars-components.css` | LCARS frame component system (hue-based shading, panels, elbows)\n| `dist/css/marketplace.css` | Marketplace overlay, asset detail overlay, command pills, slot visibility rules, gather pills\n| `dist/css/federation.css` | Federation animation overlay\n|===\n\n=== The Hue System\n\nAll LCARS component colors derive from `--lcars-hue` (0-360). Set the hue on a `.lcars-frame` and all child panels, elbows, and bars inherit computed HSL shades. See `docs/lcars.adoc` for the full spec.\n\n=== Naming\n\nCSS classes follow BEM-like conventions but without strict BEM syntax:\n\n- `.market-card` (block)\n- `.card-header`, `.card-title`, `.card-desc` (elements)\n- `.market-card.installed`, `.market-card.fda` (modifiers)\n- `.workspace-expanded`, `.command-col-hiding` (state classes)\n\n== TypeScript Conventions\n\n=== Explicit Typing\n\nEvery `const`, parameter, return type, and lambda parameter has an explicit type annotation:\n\n[source,typescript]\n----\n// Good\nconst overlay: HTMLElement | null = document.getElementById('asset-detail-overlay');\nconst filtered: Dataset[] = DATASETS.filter((ds: Dataset): boolean => { ... });\n\n// Bad\nconst overlay = document.getElementById('asset-detail-overlay');\nconst filtered = DATASETS.filter(ds => { ... });\n----\n\n=== No `any`\n\n`any` is eliminated from core application code. Use `unknown` with `instanceof` narrowing for catch blocks:\n\n[source,typescript]\n----\ntry { ... } catch (e: unknown) {\n    if (e instanceof Error) {\n        globals.terminal?.println(`Error: ${e.message}`);\n    }\n}\n----\n\n=== Module Exports\n\n- Functions intended for cross-module use are explicitly `export`ed.\n- Module-level state (e.g., `let isWorkspaceExpanded`) is private by default.\n- Types are exported via `export type` or `export interface`.\n\n== Testing Strategy\n\n=== Current Coverage\n\n[cols=\"2,1,2\"]\n|===\n| Suite | Tests | Focus\n\n| VirtualFileSystem | 64 | Path resolution, CWD, CRUD, mount/unmount, lazy content, events\n| Shell | 57 | Env vars, prompt, builtins, stage transitions, external handlers\n| ContentRegistry | 16 | Registration, resolution, VFS integration, template generators\n| Costs | 3 | Cost estimation engine\n| **Total** | **140** |\n|===\n\n=== Gap: UI Layer\n\nThe UI layer (overlays, stage transitions, DOM manipulation) has zero test coverage. All regressions to date have occurred in this layer. The primary barrier is the absence of a DOM environment in the test runner (Vitest with no jsdom/happy-dom configured).\n\n=== Mitigation\n\nThe slot pattern and the populate/teardown lifecycle are architectural mitigations for UI bugs. By reducing shared mutable DOM state, the slot pattern eliminates the class of bug where one consumer corrupts another's DOM. The teardown convention ensures workspace state is cleaned up before stage transitions.\n\nFuture improvement: add integration tests with a DOM environment to verify overlay lifecycle sequences.\n\n== Known Patterns to Extract\n\nThe following patterns currently live inline in stage modules but are candidates for extraction into `src/lcars-framework/` or `src/ui/`:\n\n1. **`workspace_teardown()`**: Currently in `search.ts`, imported by `process.ts`. If more stage transitions need workspace cleanup, this should move to a lifecycle module.\n\n== Extracted Patterns (Completed)\n\n1. **`overlaySlots_clear()`**: Moved to `src/core/logic/OverlayUtils.ts`.\n2. **Resize handle logic**: Moved to `src/ui/interactions/ResizeHandle.ts`.\n\n---\n_Last updated: 2026-01-30 (v4.5.1)_",
    "lcars.adoc": "= ARGUS LCARS Interface Design\n:toc:\n:icons: font\n\nThis document captures the specific interaction and visual metaphors used in the ARGUS (ATLAS Resource Guided User System) LCARS interface.\n\n== The Intelligence Console (Terminal)\n\nThe terminal is the primary command and control hub for ARGUS. It functions as a \"Unified Intelligence Console\" where standard system commands (bash-like), natural language queries (LCARSLM), and agentic UI manipulations are integrated into a single stream.\n\n=== Visual Metaphor: The Tactical Drawer\n\nThe terminal is conceptually positioned **between** the Status Header (top panel) and the Operational Workspace (bottom panel). It is designed as a \"retractable drawer\" that unfurls from behind the main workspace.\n\n.Key Design Principles:\n* **Framework Integration**: The terminal is powered by the `LCARSTerminal` component from the `lcars-framework`. It is decoupled from application logic, using a command-registration API.\n* **Frameless Integration**: To avoid visual clutter, the terminal does not have its own left-side LCARS framing. Instead, it sits flush against the primary `left-frame` (sidebar), which acts as a \"rail\" for the drawer.\n* **The Workspace Lid**: The horizontal `bar-panel` (containing bars 6-10) functions as the physical \"lid\" of the bottom panel.\n* **Retraction Logic**:\n  - **Closed**: The lid sits at the top of the right-frame; the terminal is hidden (height: 0).\n  - **Open**: The lid slides downward, revealing the terminal screen above it.\n* **Dynamic Elbows**: The LCARS corner elbows are attached to the sliding \"lid\" rather than the frame, ensuring a flush join at any deployment height. These elbows have a high z-index (300) to sit above overlays like the Marketplace.\n\n=== Interaction Metaphor: The Pullable Access Strip\n\nThe primary method for adjusting the terminal's height is the **Access Strip**.\n\n* **The Handle**: A horizontal orange bar (`october-sunset`) floating 5px above the workspace lid.\n* **Draggable Workspace**: By \"grabbing\" this handle, the user physically pulls the entire workspace down, increasing the terminal's visibility. The height limit has been removed to allow full-screen console expansion.\n* **Visual Feedback**: The handle glows when active, providing tactile confirmation.\n* **Integrated Toggles**:\n  - **Tactical Close**: A glowing `mars` red pill at the top-right of the terminal header for quick retraction. Pulses with `lcars-beckon-mars` to signal interactivity.\n  - **Primary Toggle**: The rightmost bar segment (`bar-10`) of the workstation lid acts as the toggle switch. Pulses with `lcars-beckon-orange` when the terminal is closed; stops pulsing when open.\n  - **Resize Handle**: The Access Strip pulses with `lcars-beckon-orange` when the terminal is open, indicating drag-to-resize capability.\n\n== The Workspace Split-Pane\n\nWhen a project is OPENed from the Search stage, the right-frame transforms into a **workspace layout** — a vertical stack of two independently-sized panels separated by resize handles.\n\n=== Layout Structure\n\nThe workspace activates by adding `workspace-active` to `.right-frame`, switching it to a flex column. The DOM order becomes:\n\n----\n.right-frame.workspace-active\n├── #intelligence-console .terminal-drawer     (terminal panel)\n├── .workspace-resize-handle[data-target=terminal]  (terminal resize grip)\n├── #asset-detail-overlay.workspace-expanded   (file browser panel)\n├── .workspace-resize-handle[data-target=browser]   (browser resize grip)\n├── .bar-panel.main-bar-panel                  (hidden in workspace)\n└── #main-content                              (hidden in workspace)\n----\n\n=== Independent Panel Sizing\n\nThe two panels are **fully decoupled** — resizing one does not affect the other. This is achieved by giving each panel its own bottom-edge resize handle, rather than using a traditional split-pane divider that redistributes a fixed pool of height.\n\n* **Terminal panel**: Height set explicitly by drag (default: 30% of frame). `flex: none`. Min-height: 80px. No upper bound — making the terminal taller makes the page taller.\n* **File browser panel**: `flex: none; height: 70vh; min-height: 400px`. Independently resizable via its own handle.\n* **Page scrolling**: `.right-frame.workspace-active` has `min-height: 100vh` and `overflow: visible`, so the page scrolls to accommodate the total height of both panels. Users can scroll the top LCARS header off-screen for maximum workspace area.\n\n=== Resize Handles\n\nBoth handles share the `.workspace-resize-handle` CSS class:\n\n* **Visual**: 6px horizontal bar in `october-sunset` (orange). On hover/active: `canary` (yellow) with a subtle box-shadow glow.\n* **Interaction**: `cursor: row-resize`. Standard mousedown → mousemove → mouseup drag pattern.\n* **Cleanup**: Both handles and their event listeners are created by `workspace_expand()` and torn down by `workspace_collapse()`.\n\n=== Bidirectional Tab ↔ Terminal Sync\n\nThe file browser sidebar (SOURCE/DATA tabs) and the terminal working directory stay in sync:\n\n* **Tab → Terminal**: Clicking a sidebar tab calls `shell.cd()` to change the terminal's working directory to the corresponding project subdirectory (`/src` or `/data`).\n* **Terminal → Tab**: The Shell's `onCwdChange_set()` callback fires whenever `cd` succeeds. The workspace handler resolves the new cwd to a tab ID via `cwdToTab_resolve()` and switches the visual tab accordingly.\n\n== The Dataset Detail Overlay (Gather Mode)\n\nWhen a dataset tile is clicked from the search results, the asset detail overlay opens in **gather mode** — a selectable FileBrowser showing the dataset's data tree.\n\n=== Visual Identity\n\nThe dataset detail uses LCARS hue 200 (sky blue) to distinguish it from project detail (hue 30, orange/honey). The sidebar shows a single \"DATA\" tab and a \"GATHER\" label at the bottom corner.\n\n=== Selectable FileBrowser\n\nThe FileBrowser component operates in `selectable: true` mode. Short clicks still preview files. Long-pressing (500ms+) toggles selection:\n\n* **File long-press**: Toggles the individual file. Selected files show `.selected-for-gather` — a canary left-border, background tint, and checkmark prefix.\n* **Folder long-press**: Toggles all descendant files. If all are selected, deselects all; otherwise selects all.\n\n=== Command Column\n\nThe standard INSTALL/CLOSE pills are replaced with:\n\n* **DONE** (canary/gold): Commits gathered selection, closes overlay, marks dataset tile as `.gathered`.\n* **ADDITIONAL DATA** (october-sunset/orange): Commits selection, closes overlay, returns to grid for more dataset browsing.\n* **CANCEL** (mars/red): Closes without committing.\n\n=== Cost Strip\n\nA real-time cost summary bar at the bottom of the content area:\n\n----\nSELECTED: 45 / 293 FILES  |  ESTIMATED COST: $6.92\n----\n\nPer-file cost = dataset total cost / total file count. Updates live via `onSelectionChange` callback.\n\n== The Persistent Project Strip\n\nA horizontal strip of compact project chips persists at the top of the Search stage across all search operations. Projects never disappear when dataset results are displayed.\n\n* **Default chip**: honey border on dark background.\n* **Active chip** (gather target): solid honey background, black text, glow. Gathered data merges into this project.\n* **\"+ NEW\" chip**: dashed harvestgold border. Clears the active target for new project creation.\n\nFirst click on a chip sets it as the gather target. Second click (already active) opens the project detail overlay.\n\n== The Multi-Mode Overlay Architecture\n\nThe `#asset-detail-overlay` is shared by three consumers — marketplace assets, project detail, and dataset detail — each requiring different sidebar panels, content areas, and command pills. Rather than rewriting the overlay's innerHTML on each open and restoring it on close (a fragile pattern that caused regressions), the overlay uses a **slot-based multi-mode** approach.\n\n=== DOM Structure\n\nThe overlay contains both the marketplace's original static DOM and three empty **slot containers**:\n\n----\n#asset-detail-overlay[data-mode=\"marketplace|project|dataset\"]\n├── .detail-layout\n│   ├── .detail-panel\n│   │   ├── .lcars-frame\n│   │   │   ├── .lcars-sidebar            ← marketplace original (never mutated)\n│   │   │   ├── #overlay-sidebar-slot     ← project/dataset sidebar\n│   │   │   ├── .lcars-content            ← marketplace original (never mutated)\n│   │   │   ├── #overlay-content-slot     ← project/dataset content\n│   ├── .detail-command-column            ← marketplace original (CLOSE/INSTALL)\n│   ├── #overlay-command-slot             ← project/dataset commands (DONE/ADD/CANCEL or CLOSE/OPEN)\n----\n\n=== Mode Switching\n\nThe `data-mode` attribute on the overlay root controls visibility via CSS attribute selectors:\n\n* **`marketplace`** (default): Original sidebar, content, and command column are visible. All `.overlay-slot` containers are `display: none`.\n* **`project`** / **`dataset`**: Original elements are hidden via `:not(.overlay-slot)` selectors. Slot containers are visible and populated by `projectDetail_populate()` or `datasetDetail_populate()`.\n\nWhen a project or dataset detail is closed, the close handler:\n\n1. Clears slot innerHTML (via `overlaySlots_clear()`)\n2. Sets `data-mode=\"marketplace\"`\n\nThe marketplace's original DOM is **never touched**. No restore logic is needed.\n\n=== Workspace Teardown\n\nWhen the user triggers FEDERALIZE AND LAUNCH from within an expanded workspace, the system must fully tear down the workspace before transitioning to the Monitor stage. The `workspace_teardown()` function handles this:\n\n1. Calls `workspace_collapse()` — removes resize handles, restores `rightFrame` layout, shows stage content\n2. Hides the `asset-detail-overlay` and resets `data-mode` to `marketplace`\n3. Clears all slot contents\n4. Closes the terminal (monitor has its own telemetry)\n\nThis ensures the Monitor stage content renders unobstructed.\n\n== Operational Modes\n\nThe terminal dynamically adapts its persona and capabilities based on the active SeaGaP stage.\n\n=== Search Mode (AI Core)\nDuring the Search stage, the terminal acts as an AI-driven discovery engine.\n* **Prompt**: `ARGUS: SEARCH >`\n* **Agentic Logic**: The AI can automatically select datasets in the visual grid using the `[SELECT: ID]` intent parser.\n* **Telematic Readout**: The visual grid below the terminal serves as a secondary evidence display, updating in real-time as the AI identifies relevant cohorts.\n\n=== Developer Mode (Technical Shell)\nUpon entering the Process stage, the console transitions into a technical coding environment.\n* **Prompt**: `dev@argus:~/src/project $`\n* **Styling**: The UI automatically switches to a monospaced font (**Inconsolata**), clears history, and enables mixed-case input/output for technical accuracy.\n* **Commands**: Supports standard linux-style commands (`ls`, `cd`, `pwd`, `mkdir`, `rm`, `python`).\n\n== Typography: The Dual-Voice System\n\nARGUS uses the **Antonio** font family with a selective casing strategy:\n\n* **The System Voice (Uppercase)**: All structural elements, headers, prompts, and button labels are strictly uppercase.\n* **The Data Voice (Mixed Case)**: Terminal output (AI responses, file contents) and user input allow mixed case to preserve technical precision and improve readability.\n* **Visual Polish**: Terminal readouts feature a soft text-shadow glow, simulating a high-density CRT display.\n\n== LCARS Component System\n\nARGUS is built on a reusable **LCARS Framework** (`src/lcars-framework/`) that decouples data simulation from UI rendering.\n\n=== Telemetry Service\nThe telemetry system uses a provider-renderer pattern:\n* **Generators**: Pure logic classes (e.g., `ProcessGenerator`, `NetworkGenerator`) that produce data objects.\n* **Renderers**: Visual components (e.g., `ListRenderer`, `LogRenderer`) that take data and update the DOM.\n* **Service**: A central orchestrator that manages registration and the 800ms \"flicker\" update loop.\n\n=== Workflow Tracker\nThe `WorkflowTracker` procedurally generates linear pipelines (like SeaGaP) with:\n* **Stations**: Circular \"stops\" with associated labels and status classes (`active`, `visited`).\n* **Connectors**: Dynamic line segments between stops.\n* **Integrated Telemetry**: Each station includes a \"hanging\" telemetry window that populates via the `TelemetryService`.\n\n=== Asset Card Component\nThe `AssetCard` (`src/ui/components/AssetCard.ts`) is a shared UI primitive used to represent both Marketplace assets and User Projects. It unifies the visual language between external resources and internal workspaces.\n\n.Features:\n* **Polymorphic Rendering**: Adapts metadata display (stars/version for assets vs. dataset counts/modification date for projects).\n* **Integrated Actions**: Supports an optional primary action pill (INSTALL, SELECT, OPEN).\n* **Identity States**: Visually flags \"Installed\" or \"Active\" items via CSS class toggles.\n\n=== Architecture\n\nThe system consists of two parts:\n\n1. **TypeScript Generator** (`src/ui/components/LCARSFrame.ts`)\n   - Creates DOM structures for LCARS frames\n   - Handles panel configuration and layout\n   - Exposes utility functions to window for HTML event handlers\n\n2. **CSS Design System** (`dist/css/lcars-components.css`)\n   - Defines base styles using CSS custom properties\n   - Computes color shades via HSL\n   - Handles responsive breakpoints\n\n=== The Hue-Based Color System\n\nAll LCARS component colors derive from a single `--lcars-hue` value (0-360). The CSS automatically computes four shade variants:\n\n[source,css]\n----\n.lcars-frame {\n    --lcars-hue: 200;           /* Blue family */\n    --lcars-sat: 70%;\n    --lcars-light-1: 75%;       /* Lightest */\n    --lcars-light-2: 65%;\n    --lcars-light-3: 55%;\n    --lcars-light-4: 45%;       /* Darkest */\n\n    /* Computed shades */\n    --lcars-shade-1: hsl(var(--lcars-hue), var(--lcars-sat), var(--lcars-light-1));\n    --lcars-shade-2: hsl(var(--lcars-hue), var(--lcars-sat), var(--lcars-light-2));\n    /* ... */\n}\n----\n\n.Predefined Hue Values\n[cols=\"1,1,2\"]\n|===\n|Name |Hue |Usage\n\n|BLUE/SKY |200 |Default marketplace assets\n|ORANGE |30 |Main application frame\n|GREEN/FDA |140 |FDA regulatory tools\n|PURPLE/NEBULA |270 |Special categories\n|RED/MARS |0 |Alerts, warnings\n|GOLD |45 |Highlights\n|===\n\n=== LCARS Frame Structure\n\nA complete LCARS frame consists of four grid areas:\n\n----\n╭━━━━━━━━━━╮━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n┃  ELBOW   ┃  TOP BAR (title + actions)\n┣━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n┃ PANEL 1  ┃\n┃──────────┃  CONTENT AREA\n┃ PANEL 2  ┃  (scrollable)\n┃──────────┃\n┃ PANEL 3  ┃\n┃ [spacer] ┃\n┃ PANEL N  ┃  ← corner radius\n╰━━━━━━━━━━╯─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─\n----\n\n* **Elbow**: Curved corner piece connecting top bar to sidebar\n* **Top Bar**: Horizontal header with title, metadata, and action buttons\n* **Sidebar**: Vertical stack of navigation panels (same width, varying heights/shades)\n* **Content**: Main scrollable content area\n\n=== Panel Design Principles\n\nLCARS panels follow strict design rules:\n\n1. **Uniform Width**: All sidebar panels are the same width. Visual variety comes from color and height, not width.\n2. **Shade Cycling**: Panels alternate through shade variants (1-4) for visual rhythm\n3. **Height Variants**: Panels can have different heights (`tall`, `medium`, `short`)\n4. **Corner Radii**: Only the elbow (top-left) and bottom panel (bottom-left) have rounded corners\n5. **Text Alignment**: Panel labels align right (LCARS convention for left sidebars)\n6. **Spacer Element**: A colored spacer fills remaining height between panels and the bottom corner\n\n=== Usage Example\n\n**HTML Structure:**\n[source,html]\n----\n<div class=\"lcars-frame\" style=\"--lcars-hue: 200;\">\n    <div class=\"lcars-elbow\"></div>\n    <div class=\"lcars-top-bar\">\n        <h1>Title</h1>\n        <button class=\"close-btn\">CLOSE</button>\n    </div>\n    <div class=\"lcars-sidebar\">\n        <a class=\"lcars-panel\" data-shade=\"1\" data-height=\"tall\">SECTION 1</a>\n        <a class=\"lcars-panel\" data-shade=\"2\">SECTION 2</a>\n        <a class=\"lcars-panel\" data-shade=\"3\">SECTION 3</a>\n        <div class=\"lcars-sidebar-spacer\" data-shade=\"4\"></div>\n        <a class=\"lcars-panel lcars-corner-bl\" data-shade=\"1\">SECTION N</a>\n    </div>\n    <div class=\"lcars-content\">\n        <!-- Scrollable content -->\n    </div>\n</div>\n----\n\n**Dynamic Theming (TypeScript):**\n[source,typescript]\n----\n// Change color scheme at runtime\nconst frame = document.getElementById('my-lcars-frame');\nframe.style.setProperty('--lcars-hue', '140');  // Switch to green\n----\n\n=== Marketplace Integration\n\nThe Asset Detail Overlay demonstrates the \"Floating Command Module\" pattern, where critical actions are decoupled from the information display to maximize screen real estate and mimic hardware controls.\n\n==== Visual Style: PADD Aesthetic\nThe asset tiles and detail frames use an asymmetrical \"PADD\" (Personal Access Display Device) geometry:\n* **Thick Top Bar:** 10px solid accent bar (Sky Blue or FDA Green).\n* **Rounded Corner:** Bottom-right corner has a 24px radius (`border-radius: 0 0 24px 0`), creating a distinct physical shape.\n* **No Borders:** Replaced thin outlines with deep contrast backgrounds and shadow glows.\n\n==== Floating Command Pills\nAction buttons are removed from the internal content area and placed in a dedicated **Command Column** to the right of the main panel.\n\n* **Structure:**\n  [source,html]\n  ----\n  <div class=\"detail-layout\">\n      <!-- Main Information Display -->\n      <div class=\"detail-panel\">...</div>\n\n      <!-- Floating Command Column -->\n      <div class=\"detail-command-column\">\n          <button class=\"pill-btn close-pill\">CLOSE</button>\n          <button class=\"pill-btn install-pill\">INSTALL</button>\n      </div>\n  </div>\n  ----\n* **Dynamic Coloring:** The INSTALL pill automatically inherits the asset's hue (Blue vs. FDA Green) via CSS variables.\n* **Status Feedback:** The INSTALL pill contains a progress bar overlay and status text (`READY` -> `INSTALLING` -> `INSTALLED`).\n\n==== Color Coding\n* **Standard Assets:** `--lcars-hue: 200` (Sky Blue)\n* **FDA Regulatory Tools:** `--lcars-hue: 140` (Green)\n* **Close Actions:** `var(--mars)` (Red)\n\n[source,typescript]\n----\n// In marketplace/view.ts\nconst hue = asset.type === 'fda' ? 140 : 200;\nlcarsFrame.style.setProperty('--lcars-hue', String(hue));\n----\n\n== Interactive Affordances: The Beckon Pulse\n\nIn Michael Okuda's original LCARS designs for The Next Generation, instrument panels were never entirely static. Panels flickered, shifted, and cycled through subtle brightness changes to suggest ongoing background system activity. This visual \"life\" served a dual purpose: it made the interface feel like a living system, and it drew attention to active controls without explicit labels or iconography.\n\nARGUS adopts this principle as a formal visual language pattern called the **Beckon Pulse**. Any interactive element that lacks an obvious affordance (no label, no icon, no conventional button shape) uses a slow brightness oscillation to signal \"interact with me.\"\n\n=== The Pattern\n\nThe Beckon Pulse is a `3-3.5s` CSS animation that oscillates `filter: brightness()` between `1.0` and `1.15-1.25`, with an optional `box-shadow` glow. The effect is subtle enough to register in peripheral vision without demanding attention. On hover, the animation stops and the element shows a static highlight, confirming interactivity.\n\n=== Variants\n\n[cols=\"1,2,2\"]\n|===\n| Variant | Animation | Usage\n\n| `lcars-beckon-orange`\n| brightness 1.0 → 1.15, soft orange glow\n| Open/activate controls (e.g., `bar-6` terminal opener)\n\n| `lcars-beckon-mars`\n| brightness 1.0 → 1.25, red glow intensifies\n| Close/dismiss controls (e.g., terminal close pill)\n\n| `.lcars-beckon` (utility class)\n| Applies `lcars-beckon-orange` by default\n| Any generic interactive element\n|===\n\n=== Contextual Activation\n\nBeckon animations are **context-sensitive**: they only pulse when the affordance is relevant. For example, `bar-6` (the terminal opener) beckons only when the terminal is closed. Once the terminal is open, bar-6 stops pulsing — the user's attention should shift to the terminal content and its close control, which now takes over the beckon duty.\n\nThis prevents **pulse fatigue**: the visual rhythm of the interface changes as the user navigates, with different elements beckoning at different moments rather than everything pulsing simultaneously.\n\n=== CSS Usage\n\n[source,css]\n----\n/* Apply via utility class */\n.my-interactive-element {\n    /* ... */\n}\n.my-interactive-element.lcars-beckon {\n    animation: lcars-beckon-orange 3.5s ease-in-out infinite;\n}\n.my-interactive-element.lcars-beckon:hover {\n    animation: none;\n}\n\n/* Or apply a specific variant directly */\n.my-close-button {\n    animation: lcars-beckon-mars 3s ease-in-out infinite;\n}\n----\n\n=== Toggling via JavaScript\n\n[source,typescript]\n----\n// Start beckoning\nelement.classList.add('lcars-beckon');\n\n// Stop beckoning (e.g., when the associated panel is open)\nelement.classList.remove('lcars-beckon');\n----\n\n== Implementation Details\n\n* **Global Component**: The `LCARSTerminal` is a global singleton.\n* **Intent Parsing**: The `terminalCommand_handle()` dispatcher in `argus.ts` routes commands to `workflowCommand_handle()` (search/add/review/mount/simulate) and `aiQuery_handle()` (LLM queries). AI responses are parsed by `aiResponse_process()` to trigger system actions (selecting data, transitioning stages).\n* **Contextual Awareness**: The AI engine receives the full dataset catalog and the user's current \"Selection Buffer\" with every query, ensuring high-fidelity RAG (Retrieval Augmented Generation) reasoning.\n* **LCARS Frame Generator**: The `lcarsFrame_create()` function and related utilities are exposed on the `window` object for use in HTML event handlers.",
    "marketplace.adoc": "= ATLAS Marketplace Specification (v3.5.0)\n:toc:\n:toclevels: 3\n\n== 1. Overview\nThe ATLAS Marketplace is a global asset registry providing ChRIS plugins (MERIDIAN apps), reference datasets, pre-trained models, annotation tools, and FDA regulatory tools. It serves as the primary distribution channel for extending the capabilities of an ARGUS instance.\n\n== 2. Asset Types\n\n[cols=\"1,2,2\"]\n|===\n| Type | Description | VCS Impact\n\n| `plugin`\n| Containerized MERIDIAN/ChRIS applications.\n| Installed to `/bin/<plugin-name>` with executable stub content.\n\n| `dataset`\n| Standalone reference cohorts for local validation.\n| Installed to `/data/sets/<dataset-name>/manifest.json`.\n\n| `model`\n| Pre-trained neural network weights (e.g., ResNet, UNet).\n| Installed to `~/models/<model-name>/README.md` with model card.\n\n| `annotation`\n| Annotation tools and label schemas.\n| Installed to `/data/annotations/<tool-name>/manifest.json`.\n\n| `fda`\n| FDA regulatory compliance tools.\n| Dual install: `/bin/<tool-name>` + `/data/annotations/<tool-name>/`.\n\n| `workflow`\n| Federated learning workflow templates.\n| Installed to `~/workflows/<workflow-name>/manifest.json`.\n|===\n\n== 3. Installation Lifecycle\n\nThe Marketplace is a **Public Service** (accessible without authentication) but requires an active session for VCS integration.\n\n1.  **Browse:** Users explore the high-density grid. Filter by type, search by name/description/author, sort by stars/name/size.\n2.  **Install:** Clicking \"INSTALL\" triggers a progress animation (1.5s).\n3.  **Store Action:** The button calls `store.asset_install(id)`, which adds the asset ID to `state.installedAssets`.\n4.  **Provider Dispatch:** The `MarketplaceProvider.asset_install()` translates the asset into VCS filesystem entries at the appropriate paths (see table above). Each entry includes content generators for manifest files, executable stubs, and model cards.\n5.  **Terminal Notification:** The Intelligence Console confirms availability and provides usage hints.\n\n== 4. Architectural Integration\nThe Marketplace is decoupled from the SeaGaP workflow. It operates as a modal overlay driven by the central `Store` and `EventBus`. The overlay slides in from the right (Slide-In Overlay animation pattern, see `docs/visual_language.adoc`).\n\n=== Key Files\n\n[cols=\"1,2\"]\n|===\n| File | Purpose\n\n| `src/marketplace/view.ts`\n| Marketplace UI: grid rendering, filtering, sorting, search, detail overlay, install handlers.\n\n| `src/core/data/marketplace.ts`\n| `MARKETPLACE_ASSETS` registry of 400+ assets with metadata.\n\n| `src/vfs/providers/MarketplaceProvider.ts`\n| Translates assets into VCS filesystem trees with content generators.\n|===\n\n=== Detail Overlay\nClicking an asset card opens a full detail overlay with:\n\n* LCARS frame with hue-based color coding (blue for standard, green for FDA)\n* Floating Command Column with INSTALL and CLOSE pills\n* Specifications, usage commands, dependencies, changelog, related assets\n\nSee `docs/lcars.adoc` for the Floating Command Module visual pattern.",
    "onboarding.adoc": "= ARGUS Developer Onboarding Guide\n:author: ATLAS Project Team\n:revdate: 2026-01-30\n:toc:\n:sectnums:\n\n== Welcome to ARGUS\n\nARGUS (ATLAS Resource Guided User System) is the UI layer for the ATLAS federated medical imaging platform. It is a **Vanilla TypeScript** application that implements the SeaGaP-MP workflow (Search, Gather, Process, Monitor, Post).\n\n**The Golden Rule:** There is no framework (React, Vue, Svelte). We use raw DOM manipulation, orchestrated by a custom Pub/Sub Store and strict architectural patterns.\n\n== The Mental Model\n\nTo work on ARGUS, you need to understand three core concepts:\n\n=== The Store is Truth\n\nEverything that changes (current stage, selected datasets, training status) lives in `src/core/state/store.ts`.\n\n*   **Don't** mutate state directly.\n*   **Do** call Store actions (e.g., `store.dataset_select(id)`).\n*   **Do** listen for events (e.g., `events.on(Events.STATE_CHANGED, ...)`).\n\n=== The Virtual Computer (VCS)\n\nARGUS isn't just a website; it simulates a computer.\n\n*   It has a filesystem (`src/vfs/`).\n*   It has a shell (`src/vfs/Shell.ts`) with environment variables (`$HOME`, `$PWD`).\n*   It has a terminal.\n\n**Key Concept:** \"Providers\" bridge the gap. When you select a dataset in the UI, the `DatasetProvider` effectively \"mounts\" that data into the virtual filesystem at `~/data/cohort/`.\n\n=== The Stage Lifecycle\n\nThe app moves through stages (Search -> Process -> Monitor).\n\n*   **Entry Point:** `src/argus.ts` is the orchestrator.\n*   **Lifecycle:** Each stage module (e.g., `src/core/stages/process.ts`) exports `stage_enter()` and `stage_exit()` hooks.\n*   **Control Flow:** The orchestrator calls `currentStage.stage_exit()` -> `nextStage.stage_enter()`.\n\n== Codebase Tour\n\n[cols=\"1,3\"]\n|===\n| Path | What's Inside\n\n| `src/argus.ts`\n| **The Orchestrator.** Initializes the app, sets up the VCS, and handles high-level events. Keep this file clean.\n\n| `src/lcars-framework/`\n| **The UI Library.** Reusable LCARS components (Terminal, WorkflowTracker) that know *nothing* about ARGUS business logic.\n\n| `src/core/state/`\n| **The Brain.** `store.ts` (state) and `events.ts` (pub/sub bus).\n\n| `src/core/logic/`\n| **The Logic Layer.** Specialized services like `commands.ts` (routing), `WindowBindings.ts` (DOM glue), and `Lifecycle.ts`.\n\n| `src/core/stages/`\n| **The Scenes.** One file per stage (search, gather, process...). Logic for that specific screen lives here.\n\n| `src/vfs/`\n| **The Computer.** The virtual filesystem, shell, and content generators.\n\n| `src/lcarslm/`\n| **The AI.** Service for communicating with Gemini/OpenAI (RAG logic).\n|===\n\n== Rules of the Road\n\n=== Naming: RPN (Reverse Polish Notation)\n\nWe use `object_method` naming to group related functionality.\n\n*   ✅ `project_load()`, `dataset_select()`, `terminal_toggle()`\n*   ❌ `loadProject()`, `selectDataset()`, `toggleTerminal()`\n\n=== The Slot Pattern\n\nWe avoid rewriting `innerHTML` for complex overlays.\n\n*   The `#asset-detail-overlay` has empty \"slots\" (`#overlay-content-slot`).\n*   When you open a Project Detail, you simply **show** the slot and **render** into it.\n*   When you close it, you **clear** the slot.\n*   *Never* touch the original Marketplace DOM that shares the overlay.\n\n=== Window Bindings\n\nHTML `onclick=\"myFunc()\"` requires `myFunc` to be on `window`.\n\n*   **Don't** just say `(window as any).myFunc = ...`\n*   **Do** register it in `src/core/logic/WindowBindings.ts`.\n\n== \"Hello World\": Adding a Command\n\nWant to add a new command called `hello` to the terminal?\n\n1.  **Edit `src/core/logic/commands.ts`**:\n    Route commands through `CalypsoCore.command_execute(...)` (already wired by default).\n    New deterministic workflow behavior should be added in `src/lcarslm/CalypsoCore.ts`.\n\n[source,typescript]\n----\n// CalypsoCore.ts\nif (primaryCommand === 'hello') {\n    return {\n        success: true,\n        message: 'Hello, World!',\n        actions: []\n    };\n}\n----\n\nThe terminal router delegates to CalypsoCore first, then falls back to the LLM when no first-class intent matches.\n\n== \"Hello World\": Adding a Stage\n\n1.  **Create `src/core/stages/mystage.ts`**:\n    Implement `stage_enter()` and `stage_exit()`.\n\n2.  **Register in `src/argus.ts`**:\n    Import it and add it to `STAGE_HANDLERS`.\n\n3.  **Update Navigation**:\n    Add it to `STAGE_ORDER` in `src/core/logic/navigation.ts`.\n\n== Further Reading\n\n*   **`docs/framework.adoc`**: Detailed guide to the patterns mentioned above.\n*   **`docs/vcs.adoc`**: Deep dive into how the Virtual Filesystem works.\n*   **`docs/architecture.adoc`**: High-level system design.",
    "oracle.adoc": "= ORACLE: Reflexive Verification Through Agentic Self-Testing\n:author: ATLAS Project Team\n:revdate: 2026-02-07\n:revnumber: 1.2.0\n:toc: macro\n:toclevels: 3\n:sectnums:\n:icons: font\n\n[.lead]\n_A methodology for integration testing of AI-driven systems using the system's own conversational interface as both test driver and verification oracle._\n\ntoc::[]\n\n== Abstract\n\nModern web applications increasingly incorporate AI-driven interfaces that mediate between user intent and system functionality. Traditional testing approaches — unit tests, end-to-end browser automation, snapshot testing — struggle to verify these systems because the integration seams between AI interpretation, state management, and UI rendering are numerous, asynchronous, and often non-deterministic at the surface level.\n\nThis document introduces **ORACLE** (Observational Reflexive Agentic Confirmation of Logical Execution), a testing methodology in which the system's own AI interface serves as the test driver, and internal system state serves as the verification oracle. Rather than testing _around_ the AI layer or mocking it away, ORACLE tests _through_ the AI layer, verifying that natural language commands produce correct deterministic state transformations.\n\nWe describe the theoretical foundations, architectural requirements, implementation specifics for the ARGUS system, and a formal test script specification.\n\n== Introduction\n\n=== The Problem: Integration Testing of AI-Mediated Systems\n\nContemporary applications increasingly feature conversational or agentic interfaces where an AI layer interprets user intent and dispatches to underlying system functions. This architecture introduces a testing challenge:\n\n[cols=\"1,2,2\"]\n|===\n| Testing Approach | Limitation | Consequence\n\n| **Unit Tests**\n| Test functions in isolation\n| Cannot verify that AI correctly routes intent to function\n\n| **E2E Browser Automation**\n| Brittle selectors, visual assertions\n| Breaks on CSS changes; cannot assert semantic state\n\n| **Snapshot Testing**\n| Compares rendered output\n| High false-positive rate; conflates presentation with logic\n\n| **Mocking the AI Layer**\n| Removes non-determinism\n| Does not test the actual user-facing behavior\n|===\n\nThe core issue: the **integration seams** — where AI interpretation meets state mutation meets UI rendering — are precisely where bugs occur, yet they are the hardest to test.\n\n=== Observation: Bounded Non-Determinism\n\nIn systems like ARGUS, the AI layer (Calypso) does not perform arbitrary computation. It serves as a **natural language router** to deterministic functions:\n\n[source]\n----\nUser Input (fuzzy)          AI Interpretation           Deterministic Execution\n─────────────────────────────────────────────────────────────────────────────────\n\"add the BCH histology\"  →  INTENT: gather_dataset   →  dataset_gather('BCH-HISTO')\n\"include BCH set\"        →  INTENT: gather_dataset   →  dataset_gather('BCH-HISTO')\n\"gather BCH-HISTO-2024\"  →  INTENT: gather_dataset   →  dataset_gather('BCH-HISTO')\n----\n\nThe non-determinism is **bounded to intent classification**. Once intent is resolved, execution is pure. This means:\n\n1. Multiple surface forms map to the same intent\n2. The same intent always produces the same state transformation\n3. State is verifiable regardless of which surface form was used\n\n=== The ORACLE Insight\n\nIf the AI interface can successfully drive a workflow to completion, and the resulting system state is correct, then:\n\n- Intent classification worked\n- State management worked\n- All intermediate integrations worked\n\n**The system can test itself through its own user-facing interface.**\n\n== Background and Related Work\n\n=== Agentic AI Testing\n\nThe field of AI-driven test automation has evolved rapidly. Contemporary approaches include:\n\n**External Agent Testing**: Tools like Magnitude, TestZeus Hercules, and SmolAgents use external LLMs to interpret test specifications and drive applications through browser automation <<magnitude>> <<testzeus>>. The AI is a _test tool_, separate from the system under test.\n\n**Agent Simulation**: Platforms like LangWatch simulate multi-agent interactions to verify agent behavior under various scenarios <<langwatch>>. Focus is on testing the AI itself, not the system it controls.\n\n**Visual AI Testing**: Tools like Applitools use computer vision to detect UI regressions <<applitools>>. Assertions are visual, not semantic.\n\n=== Self-Testing Systems\n\nThe concept of systems that verify their own behavior has roots in:\n\n**Design by Contract** (Meyer, 1986): Preconditions, postconditions, and invariants embedded in code <<meyer>>.\n\n**Metamorphic Testing** (Chen et al., 1998): Verifying that related inputs produce related outputs according to known relations <<metamorphic>>.\n\n**Autonomous Self-Healing Systems**: Systems that detect and correct their own failures at runtime <<selfhealing>>.\n\n=== Gap in Existing Approaches\n\nNo existing methodology addresses the specific case where:\n\n1. An AI interface is the _primary_ user interaction mode\n2. The AI routes to deterministic backend functions\n3. System state (not UI appearance) is the source of truth\n4. The same interface used for production is used for testing\n\nORACLE fills this gap.\n\n== The ORACLE Methodology\n\n=== Core Principles\n\n[horizontal]\nReflexivity:: The test driver is the system's own AI interface, not an external tool.\nState Verification:: Assertions target internal state (VFS, Store), not rendered output.\nSemantic Equivalence:: Multiple natural language forms that resolve to the same intent are interchangeable in tests.\nProduction Parity:: Tests execute through the exact code path users traverse.\n\n=== Architectural Requirements\n\nFor ORACLE to apply, a system must exhibit:\n\n1. **Conversational Interface**: An AI layer that accepts natural language and dispatches to functions.\n2. **Deterministic Core**: Backend functions that produce predictable state given the same inputs.\n3. **Inspectable State**: Internal state that can be serialized and compared (e.g., filesystem tree, store snapshot).\n4. **Programmatic Access**: An API to send commands and retrieve state without browser automation.\n\n=== The Testing Model\n\n[source]\n----\n                    ┌─────────────────────────────────────────────┐\n                    │              TEST HARNESS                   │\n                    │  ┌─────────────────────────────────────┐    │\n                    │  │  Test Script (.oracle.json)         │    │\n                    │  │  - Natural language commands        │    │\n                    │  │  - State assertions                 │    │\n                    │  └──────────────┬──────────────────────┘    │\n                    │                 │                           │\n                    │                 ▼                           │\n                    │  ┌─────────────────────────────────────┐    │\n                    │  │  Oracle Test Runner                 │    │\n                    │  │  - Parses script                    │    │\n                    │  │  - Executes command_execute()       │    │\n                    │  │  - Retrieves state snapshots        │    │\n                    │  │  - Evaluates assertions             │    │\n                    │  └──────────────┬──────────────────────┘    │\n                    └─────────────────┼───────────────────────────┘\n                                      │ In-process CalypsoCore\n                                      ▼\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                           SYSTEM UNDER TEST                                 │\n│  ┌─────────────────────────────────────────────────────────────────────┐   │\n│  │                         AI Layer (Calypso)                          │   │\n│  │   Natural Language Input → Intent Classification → Function Call    │   │\n│  └──────────────────────────────────┬──────────────────────────────────┘   │\n│                                     │                                       │\n│                    NON-DETERMINISTIC BOUNDARY                               │\n│  ═══════════════════════════════════╪═══════════════════════════════════   │\n│                    DETERMINISTIC EXECUTION                                  │\n│                                     │                                       │\n│                                     ▼                                       │\n│  ┌─────────────────────────────────────────────────────────────────────┐   │\n│  │                    Core Functions                                   │   │\n│  │   dataset_gather() → store.dataset_select() → cohortTree_build()   │   │\n│  └──────────────────────────────────┬──────────────────────────────────┘   │\n│                                     │                                       │\n│                                     ▼                                       │\n│  ┌─────────────────────────────────────────────────────────────────────┐   │\n│  │                    System State                                     │   │\n│  │   VirtualFileSystem    Store    EventBus                           │   │\n│  │   (inspectable)        (inspectable)                               │   │\n│  └─────────────────────────────────────────────────────────────────────┘   │\n└─────────────────────────────────────────────────────────────────────────────┘\n----\n\n=== Assertion Types\n\nORACLE supports three categories of assertions:\n\n[cols=\"1,2,2\"]\n|===\n| Category | Example | Verification Method\n\n| **State Existence**\n| `vfs_exists: \"~/projects/DRAFT/data/BCH-HISTO/\"`\n| Check node exists in VFS tree\n\n| **State Content**\n| `vfs_contains: { path: \"~/config.yaml\", content: \"model: unet\" }`\n| Read node content, substring/regex match\n\n| **State Snapshot**\n| `vfs_snapshot_matches: \"snapshots/gather-complete.json\"`\n| Serialize VFS subtree, deep compare to saved snapshot\n\n| **Store State**\n| `store.currentStage: \"process\"`\n| Read Store property, compare value\n\n| **Output Contains**\n| `output_contains: \"Dataset gathered\"`\n| Check Calypso's response text (weak assertion, use sparingly)\n|===\n\n== ARGUS Implementation\n\n=== System Context\n\nARGUS is a Vanilla TypeScript application implementing the SeaGaP-MP workflow (Search, Gather, Process, Monitor, Post) for federated medical imaging. Its AI layer, **Calypso**, interprets natural language commands and dispatches to deterministic functions that manipulate:\n\n- **VirtualFileSystem (VFS)**: In-memory POSIX-like filesystem\n- **Store**: Centralized application state with EventBus\n- **Providers**: Domain-to-filesystem translators (DatasetProvider, ProjectProvider, MarketplaceProvider)\n\nSee `docs/vcs.adoc`, `docs/architecture.adoc`, and `docs/calypso.adoc` for detailed specifications.\n\n=== Architectural Fit\n\nARGUS satisfies all ORACLE requirements:\n\n[cols=\"1,2\"]\n|===\n| Requirement | ARGUS Implementation\n\n| Conversational Interface\n| CalypsoCore accepts natural language, classifies intent, dispatches to functions\n\n| Deterministic Core\n| RPN-named functions (`dataset_gather()`, `project_scaffold()`) with typed inputs/outputs\n\n| Inspectable State\n| VFS exposes `tree_snapshot()`, Store exposes `state_snapshot()`\n\n| Programmatic Access\n| In-process `CalypsoCore` execution for ORACLE, plus Calypso HTTP API for external clients\n|===\n\n=== Systematic Path and Stress Testing\n\nAs of v9.0.5, ORACLE has been extended to systematically verify the **Manifest-Driven DAG Engine**. This ensures that Calypso correctly enforces workflow constraints across different persona paths.\n\n==== Systematic Path Testing\nScenarios like `fedml-comprehensive.oracle.json` verify multiple valid paths through a single workflow. By using the `/reset` command, a test script can:\n1. Walk a **Linear Path** (e.g., skip optional `rename` step).\n2. Reset the system state and re-initialize the session.\n3. Walk a **Branched Path** (e.g., execute `rename` before `harmonize`).\n4. Verify that downstream artifacts (e.g., `harmonize.json`) are correctly materialized regardless of the path taken.\n\n==== Stress Testing\nThe `fedml-stress.oracle.json` scenario intentionally executes steps out of order to verify the **Soft Enforcement Model**:\n- **Dependency Blocking**: Attempting a downstream stage (e.g., `harmonize`) before an upstream stage (e.g., `search`) correctly triggers a warning.\n- **Soft-Block Progression**:\n    * **Attempt 1**: Triggers a short warning (e.g., \"Cohort not harmonized\").\n    * **Attempt 2**: Triggers a detailed reason (e.g., \"Federated learning requires consistent formats\").\n    * **Attempt 3**: Allows the action to proceed (Expert override).\n- **Materialization Verification**: Ensures that artifacts (e.g., `code.json`) are only created when the action is actually executed, not when a warning is shown.\n\n=== The CalypsoCore Abstraction\n\nThe key architectural decision enabling ORACLE is the **CalypsoCore** — a DOM-free orchestrator that can run in Node.js without a browser. See `docs/calypso.adoc` for the full specification.\n\n[source]\n----\n┌─────────────────────────────────────────────────────────────────────────────┐\n│                         CALYPSO CORE (DOM-FREE)                             │\n│                                                                             │\n│   ┌─────────────────────────────────────────────────────────────────────┐   │\n│   │  CalypsoCore.command_execute(input: string): CalypsoResponse        │   │\n│   │                                                                     │   │\n│   │  1. Shell builtins    → shell.command_execute()                     │   │\n│   │  2. First-class workflow intents (workflow_* handlers)             │   │\n│   │  3. LLM fallback      → engine.query() → intent_dispatch()          │   │\n│   └─────────────────────────────────────────────────────────────────────┘   │\n│                                    │                                        │\n│                                    ▼                                        │\n│   ┌─────────────────────────────────────────────────────────────────────┐   │\n│   │  CalypsoResponse                                                    │   │\n│   │  {                                                                  │   │\n│   │    message: \"● DATASET GATHERED.\",                                  │   │\n│   │    actions: [{ type: 'dataset_select', id: 'ds-012' }],             │   │\n│   │    state: { vfs: <snapshot>, store: <snapshot> }                    │   │\n│   │  }                                                                  │   │\n│   └─────────────────────────────────────────────────────────────────────┘   │\n│                                                                             │\n│   Depends on (all DOM-free):                                                │\n│   ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐   │\n│   │     VFS      │  │    Store     │  │    Shell     │  │ LCARSEngine  │   │\n│   └──────────────┘  └──────────────┘  └──────────────┘  └──────────────┘   │\n└─────────────────────────────────────────────────────────────────────────────┘\n----\n\nThis design means:\n- **State mutations happen in CalypsoCore** (deterministic)\n- **UI rendering is delegated to adapters** (environment-specific)\n- **Tests can bypass UI entirely** and assert directly on state\n\n=== Component Architecture\n\n[source]\n----\nsrc/\n├── lcarslm/\n│   ├── CalypsoCore.ts           # DOM-free orchestrator\n│   ├── engine.ts                # LLM client (already DOM-free)\n│   ├── types.ts                 # CalypsoResponse, CalypsoAction, Intent\n│   └── adapters/\n│       ├── BrowserAdapter.ts    # DOM rendering for web app\n│       ├── CLIAdapter.ts        # stdout/stdin for CLI\n│       └── NodeAdapter.ts       # Test harness integration\n│\n├── cli/\n│   ├── calypso-server.ts        # Headless server entry point\n│   └── calypso-cli.ts           # Interactive REPL client\n│\n├── scripts/\n│   └── oracle-runner.mjs        # In-process ORACLE runner\n│\n├── tests/\n│   └── oracle/\n│       └── *.oracle.json        # Scenario files\n│\n├── vfs/\n│   └── VirtualFileSystem.ts     # tree_snapshot() method\n│\n└── core/\n    └── state/\n        └── store.ts             # state_snapshot() method\n----\n\n=== Calypso Server API\n\nThe Calypso Server (`make calypso`) exposes a REST API for programmatic interaction:\n\n[cols=\"1,2,2\"]\n|===\n| Endpoint | Method | Description\n\n| `/calypso/command`\n| POST\n| Send a command to CalypsoCore. Body: `{ \"command\": \"search histology\" }`. Returns: `CalypsoResponse`\n\n| `/calypso/vfs/snapshot`\n| GET\n| Returns serialized VFS tree. Query params: `path` (optional subtree root)\n\n| `/calypso/vfs/exists`\n| GET\n| Check if path exists. Query params: `path`. Returns: `{ \"exists\": true/false }`\n\n| `/calypso/vfs/read`\n| GET\n| Read file content. Query params: `path`. Returns: `{ \"content\": \"...\" }`\n\n| `/calypso/store/state`\n| GET\n| Returns serialized Store state\n\n| `/calypso/store/get`\n| GET\n| Get specific store property. Query params: `property`. Returns: `{ \"value\": ... }`\n\n| `/calypso/reset`\n| POST\n| Reset VFS and Store to clean state for next test\n\n| `/calypso/login`\n| POST\n| Login with username. Body: `{ \"username\": \"rudolph\" }`. Reinitializes VFS with user home.\n\n| `/calypso/prompt`\n| GET\n| Returns current shell prompt string (e.g., `rudolph@CALYPSO:[~/projects]> `)\n\n| `/calypso/version`\n| GET\n| Returns Calypso version string\n|===\n\n=== Calypso CLI\n\nThe `calypso-cli` tool provides interactive access to a running Calypso instance (headless or browser).\n\n[source,bash]\n----\n# Start headless server\n$ make calypso &\n\n# Connect CLI\n$ make calypso-cli\n----\n\n**CLI Commands:**\n\n[cols=\"1,3\"]\n|===\n| Command | Description\n\n| `<natural language>`\n| Sent to CalypsoCore for processing\n\n| `/run <script>`\n| Run an external `.clpso` script (fail-fast, one command per line)\n\n| `/help`\n| Show available commands and quick usage\n\n| `quit` / `exit`\n| Disconnect and exit\n|===\n\n**Example Session:**\n\n[source]\n----\nuser@CALYPSO:[~]> search histology datasets\n● AFFIRMATIVE. SCAN COMPLETE.\n○ IDENTIFIED 3 DATASET(S) MATCHING QUERY PARAMETERS.\n  [ds-012] BCH-HISTO-2024 (Histology/Classification)\n  [ds-045] MGH-PATH-SLIDES (Histology/Segmentation)\n  [ds-078] BIDMC-TISSUE-BANK (Histology/Detection)\n\nuser@CALYPSO:[~]> add ds-012\n● DATASET GATHERED. MOUNTED TO ~/data/cohort/BCH-HISTO-2024/\n\nuser@CALYPSO:[~]> tree ~/data/cohort/\n~/data/cohort/\n└── BCH-HISTO-2024/\n    ├── images/\n    │   ├── slide_0001.svs\n    │   ├── slide_0002.svs\n    │   └── slide_0003.svs\n    └── manifest.json\n\nuser@CALYPSO:[~]> /run harmonize\n● COHORT HARMONIZATION COMPLETE. DATA STANDARDIZED FOR FEDERATION.\n\nuser@CALYPSO:[~]> quit\nGoodbye.\n----\n\nThis CLI is useful for:\n- Interactive debugging during development\n- Manual verification of workflows\n- Scripted automation (pipe commands via stdin)\n- Connecting to a running browser session for inspection\n\n=== VFS Snapshot Method\n\nAdd to `src/vfs/VirtualFileSystem.ts`:\n\n[source,typescript]\n----\n/**\n * Serialize a subtree of the VFS for snapshot comparison.\n *\n * Returns a deterministic JSON-serializable representation of the tree\n * structure and file metadata. Content is optionally included.\n *\n * @param rootPath - The subtree root (default: '/')\n * @param includeContent - Whether to include file content (default: false)\n * @returns Serializable tree snapshot\n */\npublic tree_snapshot(\n    rootPath: string = '/',\n    includeContent: boolean = false\n): VfsSnapshot {\n    const node: FileNode | null = this.node_get(rootPath);\n    if (!node) {\n        throw new Error(`Snapshot root not found: ${rootPath}`);\n    }\n    return this.node_serialize(node, includeContent);\n}\n\nprivate node_serialize(node: FileNode, includeContent: boolean): VfsSnapshotNode {\n    const serialized: VfsSnapshotNode = {\n        name: node.name,\n        type: node.type,\n        path: node.path,\n    };\n\n    if (node.type === 'file') {\n        serialized.size = node.size;\n        if (includeContent && node.content !== null) {\n            serialized.content = node.content;\n        }\n        if (node.contentGenerator) {\n            serialized.hasGenerator = true;\n        }\n    }\n\n    if (node.type === 'folder' && node.children) {\n        serialized.children = node.children\n            .map((child: FileNode): VfsSnapshotNode => this.node_serialize(child, includeContent))\n            .sort((a: VfsSnapshotNode, b: VfsSnapshotNode): number => a.name.localeCompare(b.name));\n    }\n\n    return serialized;\n}\n----\n\n=== Store Snapshot Method\n\nAdd to `src/core/state/store.ts`:\n\n[source,typescript]\n----\n/**\n * Serialize current store state for snapshot comparison.\n *\n * Excludes non-serializable globals (terminal, vcs, shell instances).\n * Returns only the serializable ExtendedState.\n *\n * @returns JSON-serializable state object\n */\npublic state_snapshot(): ExtendedState {\n    return JSON.parse(JSON.stringify(this._state));\n}\n----\n\n== Test Script Specification\n\n=== File Format\n\nORACLE scenarios use JSON files with the `.oracle.json` extension in `tests/oracle/`.\n\n=== Schema\n\n[source,json]\n----\n{\n  \"name\": \"FedML Smoke\",\n  \"username\": \"oracle\",\n  \"steps\": [\n    {\n      \"send\": \"search histology\",\n      \"success\": true,\n      \"output_contains\": [\"FOUND\", \"DATASET\"]\n    },\n    {\n      \"send\": \"add ds-006\",\n      \"success\": true,\n      \"capture_project\": true\n    },\n    {\n      \"vfs_exists\": \"/home/${user}/projects/${project}/src/train.py\"\n    }\n  ]\n}\n----\n\nSupported step keys:\n\n1. `send` - execute one Calypso command string. Supports `${user}`, `${project}`, and `${session}` interpolation.\n2. `success` - expected boolean for the previous `send`.\n3. `output_contains` - string or string[] that must appear in the response message (case-insensitive).\n4. `capture_project` - when `true`, stores the active project name into the `${project}` variable.\n5. `vfs_exists` - asserts path existence after interpolation.\n\n=== Advanced Runner Features\n\nThe `oracle-runner.mjs` provides the following capabilities:\n- **Session Continuity**: Re-fetches the `${session}` path after every command, allowing scripts to handle session-reinitializing commands like `/reset`.\n- **Case-Insensitive Matching**: Ensures that presentation-layer casing changes do not break logic tests.\n- **Diagnostic Logging**: In verbose mode (`--verbose`), the runner logs response messages and VFS confirmations for every step.\n\n== Test Execution\n\n=== Makefile Targets\n\n[source,makefile]\n----\n# Start headless Calypso server (port 8081)\ncalypso:\n\tnpx tsx src/cli/calypso-server.ts\n\n# Start interactive CLI client\ncalypso-cli:\n\tnpx tsx src/cli/calypso-cli.ts\n\n# Run ORACLE scenarios (in-process runner)\ntest-oracle:\n\t@npm run build > /dev/null\n\tnode scripts/oracle-runner.mjs\n\n# Run ORACLE tests with verbose output\ntest-oracle-verbose:\n\t@npm run build > /dev/null\n\tnode scripts/oracle-runner.mjs --verbose\n----\n\n=== Running Tests\n\n[source,bash]\n----\n# Run all ORACLE tests\nmake test-oracle\n\n# Run with verbose output\nmake test-oracle-verbose\n\n# Direct runner invocation\nnode scripts/oracle-runner.mjs\n----\n\n=== Manual Testing with CLI\n\nFor interactive debugging, use the CLI alongside the test:\n\n[source,bash]\n----\n# Terminal 1: Start Calypso server\n$ make calypso\n\n# Terminal 2: Run CLI for manual exploration\n$ make calypso-cli\nuser@CALYPSO:[~]> search histology\nuser@CALYPSO:[~]> add ds-012\nuser@CALYPSO:[~]> harmonize\n\n# Terminal 3: Run ORACLE scenarios (uses in-process runtime)\n$ make test-oracle\n----\n\n=== CI Integration\n\nOracle tests integrate with existing CI pipelines:\n\n[source,yaml]\n----\n# .github/workflows/test.yml\njobs:\n  oracle-tests:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Build\n        run: npm run build\n\n      - name: Run Oracle tests\n        run: make test-oracle\n----\n\n== Limitations and Considerations\n\n=== When ORACLE Is Appropriate\n\n- Systems with AI/conversational interfaces as primary interaction mode\n- Applications where internal state is the source of truth\n- Workflows that span multiple stages/components\n- **Regression testing of manifest constraints and DAG logic**\n- **Stress testing of out-of-order interaction flows**\n\n=== When ORACLE Is Not Appropriate\n\n- Pure unit testing of isolated functions (use standard unit tests)\n- Visual regression testing (use screenshot comparison tools)\n- Performance/load testing (use dedicated profiling tools)\n- Testing the AI model itself (use LLM evaluation frameworks)\n\n=== AI Reliability\n\nORACLE assumes the AI layer has sufficient reliability to consistently classify intents. If the AI frequently misclassifies:\n\n1. Tests will fail on assertions (correct behavior — the system is broken)\n2. High test flakiness may indicate AI training issues\n3. Consider adding retry logic with backoff for known-flaky classifications\n\n=== Snapshot Maintenance\n\nThe current runner focuses on deterministic command/output/path assertions.\nIf snapshot-style assertions are reintroduced later, maintain them as follows:\n\n- regenerate snapshots only for intentional behavior changes\n- review snapshot diffs in code review\n- keep snapshot scope narrow (subtree over full tree where possible)\n\n== Future Work\n\n=== Planned Enhancements\n\n1. **Parallel Test Execution**: Run independent tests concurrently with isolated VFS instances\n2. **Fuzzing Mode**: Generate random valid command sequences to discover edge cases\n3. **Coverage Mapping**: Track which deterministic functions are exercised by which tests\n4. **Visual Assertions**: Optional DOM state assertions for UI-critical tests\n5. **Time Travel Debugging**: Record full state history for failed tests\n\n=== Research Directions\n\n1. **Adversarial Testing**: Intentionally ambiguous commands to verify graceful degradation\n2. **Multi-User Simulation**: Test concurrent sessions and state isolation\n3. **LLM-Generated Tests**: Use a second LLM to generate test scenarios from documentation\n\n== Conclusion\n\nORACLE represents a paradigm shift in testing AI-mediated systems. By embracing the AI interface as the test driver rather than testing around it, we achieve:\n\n- **Production parity**: Tests traverse the exact code path users do\n- **Integration coverage**: The most bug-prone seams are directly exercised\n- **Self-documentation**: Test scripts serve as executable workflow documentation\n- **Regression detection**: State-based assertions catch integration failures that unit tests miss\n\nThe reflexive nature of ORACLE — using the system to test itself — is not a limitation but a feature. If Calypso cannot successfully drive a workflow, neither can a user. The test failure surface equals the user failure surface.\n\n[bibliography]\n== References\n\n- [[[magnitude]]] Sharma, S. \"A Review of Open-Source AI-Driven UI Test Automation Frameworks (2025).\" Medium, 2025. https://medium.com/@ss-tech/a-review-of-open-source-ai-driven-ui-test-automation-frameworks-2025-4b957cdf822d\n\n- [[[testzeus]]] TestZeus. \"Hercules: AI-Driven Test Automation.\" 2025. https://github.com/test-zeus-ai/testzeus-hercules\n\n- [[[langwatch]]] LangWatch. \"Agent Testing with Simulations.\" 2025. https://langwatch.ai/blog/the-4-best-llm-evaluation-platforms-in-2025-why-langwatch-eedefines-the-category-with-agent-testing-(with-simulations)\n\n- [[[applitools]]] Applitools. \"Visual AI Testing Platform.\" https://applitools.com\n\n- [[[meyer]]] Meyer, B. \"Design by Contract.\" IEEE Computer, 1992. https://doi.org/10.1109/2.161279\n\n- [[[metamorphic]]] Chen, T.Y., Cheung, S.C., Yiu, S.M. \"Metamorphic Testing: A New Approach for Generating Next Test Cases.\" Technical Report HKUST-CS98-01, 1998.\n\n- [[[selfhealing]]] Kephart, J.O., Chess, D., M. \"The Vision of Autonomic Computing.\" IEEE Computer, 2003. https://doi.org/10.1109/MC.2003.1160055\n\n- [[[qualizeal]]] QualiZeal. \"The Rise of Agentic AI: Transforming Software Testing in 2025 and Beyond.\" 2025. https://qualizeal.com/the-rise-of-agentic-ai-transforming-software-testing-in-2025-and-beyond/\n\n- [[[testgrid]]] TestGrid. \"Agentic AI Testing: The Future of Autonomous Software QA.\" 2025. https://testgrid.io/blog/agentic-ai-testing/\n\n---\n_Last updated: {revdate} (v{revnumber})_",
    "philosophy.adoc": "= ARGUS: Design Philosophy and Conceptual Framework\n:author: ATLAS Project Team\n:revdate: 2026-01-23\n:toc:\n:sectnums:\n\n== Introduction\n\nARGUS (ATLAS Resource Guided User System) serves as the primary interface through which users interact with the ATLAS federated medical imaging platform. The name draws from Greek mythology, where Argus Panoptes was the hundred-eyed giant whose vigilance made him the perfect guardian. In the context of ATLAS, ARGUS provides comprehensive visibility into distributed resources across federated Trusted Domains, enabling users to search, curate, process, and monitor medical imaging workflows while maintaining the security and governance guarantees that ATLAS provides.\n\nThis document establishes the conceptual foundations that guide ARGUS development, ensuring that implementation decisions remain aligned with user needs and platform capabilities.\n\n== The SeaGaP-MP Workflow Framework\n\nAt the core of ARGUS lies a unifying interaction pattern called SeaGaP-MP, an acronym representing the five stages through which users accomplish their goals: Search, Gather, Process, Monitor, and Post. This framework emerged from analysis of how different user personas interact with federated medical imaging resources, revealing that despite significant differences in ultimate objectives, the underlying workflow structure remains remarkably consistent.\n\n=== Search\n\nThe Search stage represents the user's initial engagement with the ATLAS catalog. Users query metadata to discover resources relevant to their task, whether those resources are annotated training datasets, raw images requiring labels, pre-trained models, or processing applications. The search interface must accommodate both structured queries with specific filter criteria and exploratory browsing for users who may not yet know precisely what they need.\n\nCritical to the Search stage is transparency regarding resource characteristics that affect downstream decisions. Access costs, expected processing times, cohort sizes, data provenance, and quality metrics must be surfaced during search so that users can make informed selections before committing resources.\n\n=== Gather\n\nOnce users have identified relevant resources through search, the Gather stage assembles those resources into a working context. ARGUS presents gathered resources using a virtual filesystem metaphor, consistent with the MERIDIAN architecture's foundational principle that applications interact with data through standard filesystem interfaces rather than custom APIs.\n\nThis virtual filesystem abstraction serves multiple purposes. It provides a familiar mental model for users accustomed to working with files and directories. It aligns with the ChRIS platform's feed-based provenance model, where workflow state is represented as materialized filesystem trees. And it enables seamless transition to the Process stage, where development environments and applications expect filesystem-based data access.\n\nThe Gather stage also presents cost estimates for the assembled cohort, giving users an opportunity to refine their selection before committing to processing. Users should understand what they will pay before they proceed, and the platform must provide mechanisms to adjust the gathered set to meet budget constraints.\n\n=== Process\n\nThe Process stage encompasses the actual work users perform on gathered resources. The nature of this work varies significantly by persona. Developers write training code in integrated development environments, which ATLAS then transcodes into federated machine learning workflows distributed across contributing Trusted Domains. Annotators apply labels to images through specialized annotation interfaces. Users execute inference by running pre-trained models against their gathered image sets.\n\nDespite this variation, the Process stage shares common characteristics across personas. Work occurs within the security boundary of appropriate Trusted Domains, ensuring that raw data never leaves institutional control. The MERIDIAN architecture guarantees that processing applications conform to defined security levels, with most applications operating at Level 0 where no external network access is permitted.\n\nFor the Developer persona specifically, the Process stage contains significant complexity that the interface must make tractable. Users write standard training code as if working with local data, and ATLAS handles the transformation into federated learning workflows. This transcoding represents substantial value but also substantial machinery.\n\nTo bridge the gap between this \"local mental model\" and the \"global execution reality,\" ARGUS imposes a **Simulation Loop**. Before code can be deployed to partners, it must pass a local \"Phantom Federation\" check. This ensures that the developer's code can withstand the serialization, aggregation, and privacy noise injection inherent to federation, all within a safe local sandbox. The interface should provide appropriate visibility into this transformation, building user trust without overwhelming them with implementation details.\n\n=== Monitor\n\nAfter processing begins, users require visibility into execution progress. The Monitor stage provides this visibility through interfaces appropriate to the work being performed. Developers training models see epoch progression, loss curves, and per-node status across participating Trusted Domains. Users running inference see job completion percentages and estimated time remaining. Annotators see progress through their assigned image sets.\n\nThe Monitor stage must also surface cost accumulation during execution. Users who authorized a maximum expenditure need confidence that the platform respects that limit, with clear indication of current spend against budget. When costs approach limits, users must have the ability to abort execution. The platform guarantees that aborted jobs incur no charges for incomplete work, though partial results may be available depending on the nature of the processing.\n\n=== Post\n\nThe Post stage addresses what happens after processing completes. Results must be retrieved, reviewed, and potentially persisted back into the ATLAS ecosystem for others to discover and use.\n\nFor Developers, the Post stage involves publishing trained models to the marketplace. The training process produces weight files in the aggregator's output directory, with full provenance captured as nested filesystem directories showing the complete lineage from input data through processing steps to final output. Publishing makes these models available as MERIDIAN-compliant applications that other users can discover and execute.\n\nFor Annotators, the Post stage involves persisting annotations. These may either enrich the original data's metadata in the catalog, making the annotations discoverable alongside the source images, or they may be published as separate annotation products that reference the source data. The choice depends on licensing arrangements, institutional policies, and annotator preferences.\n\nFor Users running inference, the Post stage is typically simpler, involving export or download of results to external systems or persistence within the user's ATLAS workspace for future reference.\n\n== User Personas\n\nARGUS serves multiple distinct user personas, each with different goals, expertise levels, and interaction patterns. While all personas navigate the SeaGaP-MP workflow, the specific content and complexity at each stage varies significantly.\n\n=== Federated ML Developer\n\nThe Federated ML Developer persona represents researchers and engineers building new machine learning models using ATLAS resources. They possess technical sophistication and expect powerful tools, including integrated development environments comparable to VSCode or JupyterLab. Their workflow emphasizes iteration and experimentation, with frequent cycles through the SeaGaP-MP stages as they refine their approaches.\n\nThe defining characteristic of the Federated ML Developer experience in ATLAS is the platform's ability to transform standard training code into federated learning workflows automatically. They write code as if working with local data, and ATLAS handles distribution across Trusted Domains, aggregation of gradients, and production of final models. This capability represents the platform's core value proposition for this persona.\n\n=== Annotator\n\nThe Annotator persona represents individuals who apply labels to medical images, creating the annotated datasets that Developers require for training. Annotators may be clinical experts such as radiologists or pathologists whose domain knowledge gives their annotations particular authority, or they may be trained technicians working under clinical supervision.\n\nThe Annotator workflow emphasizes efficiency and ergonomics for repetitive tasks. The interface must minimize friction in moving through images while providing powerful annotation tools appropriate to the imaging modality. Progress tracking and quality metrics help annotators and their supervisors understand throughput and consistency.\n\n=== User\n\nThe User persona represents consumers of trained models who wish to run inference on their own images. Users may have limited technical sophistication and expect straightforward interfaces that hide platform complexity. Their primary concern is obtaining results, not understanding the machinery that produces them.\n\nThe User workflow is typically the simplest instantiation of SeaGaP-MP. Search focuses on finding appropriate models and uploading or selecting images for processing. Gather is often implicit in the search stage. Process involves execution with minimal configuration. Monitor shows progress toward completion. Post delivers results in usable formats.\n\n=== Data Provider\n\nThe Data Provider persona represents institutions contributing data to the ATLAS ecosystem. Unlike other personas who use ATLAS to accomplish external goals, Data Providers are primarily concerned with visibility into how their contributed resources are being used, what revenue those contributions generate, and what governance policies apply.\n\nThe Data Provider workflow inverts the typical consumption pattern. Search focuses on their own contributed data and its usage patterns. Gather assembles reports and analytics. Process involves policy management and pricing decisions. Monitor tracks access patterns and revenue accumulation. Post updates catalog listings and governance configurations.\n\n=== App Developer\n\nThe App Developer persona represents engineers building MERIDIAN-compliant applications beyond machine learning models. These may include image processing pipelines, quality control tools, format converters, or visualization applications. App Developers require access to platform APIs, testing infrastructure, and publication workflows.\n\n=== Administrator\n\nThe Administrator persona represents individuals responsible for platform governance, user management, and compliance. Administrators require visibility into system health, audit logs, access patterns, and policy enforcement. Their workflow centers on oversight and control rather than resource consumption.\n\n== Cost Model Principles\n\nARGUS implements a cost model designed to give users confidence and control over their expenditures. Three principles guide this implementation.\n\nFirst, users see cost estimates before committing to processing. The Gather stage presents projected costs based on the assembled resource set and intended processing. Users can adjust their selections to meet budget constraints before any charges accrue.\n\nSecond, users see cost accumulation during processing. The Monitor stage displays running totals against authorized budgets, ensuring that users always understand their current expenditure.\n\nThird, users can abort processing without penalty for incomplete work. If a user cancels a job before completion, they receive no results but incur no charges. This guarantee gives users confidence to experiment without fear of runaway costs.\n\n== Provenance and Output Model\n\nATLAS captures complete provenance for all processing through its filesystem-based workflow model. Each processing step materializes its inputs and outputs as filesystem directories, creating an explicit record of data flow through the workflow graph. This approach, inherited from the ChRIS platform's feed architecture, ensures that users can trace any result back through its complete derivation history.\n\nFor machine learning workflows specifically, the aggregator process running on the central hub produces final outputs in its designated output directory. Weight files, training logs, and associated metadata persist with full provenance linking them to the training data, code, and configuration that produced them.\n\nThis filesystem-centric approach aligns with the MERIDIAN architecture's core principle: by standardizing on filesystem interfaces rather than custom APIs, the platform achieves integration scalability while maintaining the auditability and reproducibility that regulated medical applications require.\n\n== Data-State Computation: Alignment with ChRIS\n\nARGUS is the interface to a platform whose compute model is fundamentally **data-state-centric**. ChRIS represents computation as a DAG where each node is a mortal container that consumes `/input`, produces `/output`, and exits. Progress through the graph is determined by the existence of materialized data artifacts, not by controller-internal state. There is no hidden scheduler logic deciding what runs next -- the filesystem is the single source of truth.\n\nThis architectural principle, described fully in _ChRIS DAGs and Workflow Semantics: Data-State vs Control-Flow_, has a direct implication for the UI layer: **ARGUS should reason about workflow progress the same way ChRIS reasons about compute progress** -- by inspecting data state, not maintaining control-flow counters.\n\n=== Why This Matters at the UI Layer\n\nThe temptation in a UI application is to track workflow progress using in-memory state: arrays of completed stage IDs, boolean flags, counters. This is the control-flow approach. It fails when:\n\n* The tracking state drifts from the actual state of the system (missed increments, resets, race conditions)\n* An AI layer consumes the tracking state and reasons confidently from incorrect premises\n* Fixing one counter's logic creates regressions in another, producing a whack-a-mole cycle\n\nARGUS experienced all three failure modes. The resolution was to align the UI layer with the compute layer: the Virtual Computer System's filesystem serves as the medium for materialized workflow artifacts, and the `WorkflowEngine` queries these artifacts in real time rather than maintaining a separate record of what has been done.\n\n=== The Provenance Connection\n\nThis data-state approach connects directly to the provenance principles described earlier. ChRIS captures complete provenance through its filesystem-based workflow model -- each processing step materializes its inputs and outputs as directories. ARGUS mirrors this at the workflow level: each completed stage is evidenced by a concrete artifact in the VFS (a `.harmonized` marker, a `train.py` file, a `.local_pass` certification). The workflow history is readable from the filesystem, not from controller logs or ephemeral memory.\n\nFor AI-mediated interfaces specifically, this grounding is essential. An LLM consuming workflow context derived from filesystem queries is reading ground truth. An LLM consuming counter-derived context is reading assertions that may be stale or wrong. The difference between these two modes of context injection is the difference between a system that drifts and one that stays aligned.\n\n== Conclusion\n\nARGUS provides the window through which users see and interact with the ATLAS platform. The SeaGaP-MP framework ensures consistent workflow structure across diverse personas, while persona-specific adaptations address the varying needs of Developers, Annotators, Users, Data Providers, App Developers, and Administrators. Cost transparency, abort guarantees, and comprehensive provenance build the trust necessary for users to commit valuable resources to federated processing. These philosophical foundations guide implementation decisions as ARGUS development proceeds.",
    "vcs.adoc": "= ARGUS Virtual Computer System (VCS) Specification\n:author: ATLAS Project Team\n:revdate: 2026-01-29\n:toc:\n:toclevels: 3\n:sectnums:\n\n== Overview\n\nThe Virtual Computer System (VCS) is the stateful runtime environment underlying the ARGUS Intelligence Terminal. It provides a POSIX-like in-memory filesystem with file content, a shell interpreter with environment variables, and a provider system that populates the filesystem from application context (datasets, projects, marketplace installs).\n\n=== Purpose\n\nThe VCS replaces the current `VirtualFileSystem` class (`src/core/logic/vfs.ts`), which provides directory navigation but no file content, no shell abstraction, and no integration with the application lifecycle. The current implementation has the following deficiencies:\n\n[cols=\"1,2\"]\n|===\n| Deficiency | Impact\n\n| `FileNode` has no `content` field\n| `cat` cannot work. IDE content is hardcoded HTML in `process.ts`.\n\n| Prompt is set by string literals\n| Terminal prompt and VFS CWD are out of sync after stage transitions.\n\n| No `cat`, `rm`, `cp`, `mv`\n| Users cannot read, delete, copy, or move files.\n\n| Stage transitions don't call `cd`\n| Process stage claims `~/src/project` but CWD remains `/home/user`.\n\n| Marketplace installs create name-only nodes\n| `vfs.touch('/home/user/bin/x')` creates an entry with no content or metadata.\n\n| Filesystem rebuilt from scratch each Gather\n| No persistence across the session. No accumulation of artifacts.\n|===\n\nThe VCS resolves all of these by providing a complete, stateful mini-computer that the terminal interacts with as a real shell environment.\n\n=== Design Principles\n\n1. **Single Source of Truth.** The VCS owns the current working directory, the filesystem tree, and all file content. The terminal prompt reads from the VCS. Stage transitions issue real `cd` commands through the Shell. The IDE reads file content from the VCS.\n\n2. **POSIX Familiarity.** Users who know Unix will feel at home. `ls`, `cd`, `cat`, `pwd`, `mkdir`, `touch`, `rm`, `cp`, `mv`, `echo`, `env` work as expected. Paths are `/`-separated. `~` expands to `$HOME`.\n\n3. **Content-Aware Files.** Every file in the VCS can have content — a string (for text files) or a metadata descriptor (for binary stubs like images). The content is generated on demand by Providers and cached in the filesystem.\n\n4. **Provider Architecture.** The VCS does not know about datasets, projects, or marketplace assets. Providers are responsible for translating application domain objects into filesystem trees with content. This keeps the VCS pure and the domain logic encapsulated.\n\n5. **Event-Driven Integration.** The VCS emits events on mutation (`VFS_CHANGED`, `CWD_CHANGED`). The Store, terminal, and UI components subscribe to these events. The VCS never reaches into the DOM.\n\n== Architecture\n\n=== Component Diagram\n\n----\n┌──────────────────────────────────────────────────────────┐\n│                     Terminal (UI)                        │\n│              Sends keystrokes, renders output            │\n└──────────────────────┬───────────────────────────────────┘\n                       │\n                       ▼\n┌──────────────────────────────────────────────────────────┐\n│                      Shell                               │\n│  Command parsing, builtin dispatch, env vars, prompt     │\n│  $HOME, $USER, $PWD, $PATH, exit codes, history          │\n└──────────────────────┬───────────────────────────────────┘\n                       │\n                       ▼\n┌──────────────────────────────────────────────────────────┐\n│                 VirtualFileSystem                        │\n│  Tree storage, content storage, path resolution          │\n│  read(), write(), rm(), cp(), mv(), stat(), ls(), cd()   │\n│  mount(), unmount(), event emission                      │\n└───────────┬──────────────────────────┬───────────────────┘\n            │                          │\n            ▼                          ▼\n┌───────────────────┐     ┌────────────────────────────────┐\n│  ContentRegistry  │     │          Providers             │\n│  Templates &      │     │  DatasetProvider               │\n│  generators for   │◄────│  ProjectProvider               │\n│  file bodies      │     │  MarketplaceProvider           │\n└───────────────────┘     └────────────────────────────────┘\n----\n\n=== Data Flow\n\n1. **User types `cat train.py`** in the terminal.\n2. **Terminal** sends the raw input string to the **Shell**.\n3. **Shell** parses the command (`cat`) and argument (`train.py`), resolves the path relative to `$PWD`.\n4. **Shell** calls `vfs.read('/home/user/src/project/train.py')`.\n5. **VirtualFileSystem** looks up the node. If `content` is `null`, it calls the **ContentRegistry** to generate content on demand.\n6. **ContentRegistry** finds the registered template for `train.py`, invokes it with the current project context, and returns the content string.\n7. **VirtualFileSystem** caches the content on the node and returns it.\n8. **Shell** wraps the content in a `ShellResult` (`{ stdout, stderr, exitCode }`).\n9. **Terminal** renders `stdout` to the screen.\n\n== Filesystem Layout\n\n=== Root Structure\n\n----\n/\n├── home/\n│   └── <username>/          # $HOME — one per authenticated user (default: 'user')\n│       ├── data/\n│       │   ├── cohort/      # Current gathered datasets (populated by DatasetProvider)\n│       │   └── cache/       # Intermediate processing artifacts\n│       ├── src/\n│       │   └── project/     # Active project workspace (populated by ProjectProvider)\n│       ├── models/          # Training outputs + installed models\n│       ├── results/         # Post-stage published artifacts\n│       ├── bin/             # User-local scripts and tools\n│       └── .config/\n│           └── argus.yaml   # User preferences, API keys\n│\n├── bin/                     # System-wide executables (marketplace plugin installs)\n├── data/\n│   ├── catalog/             # Read-only ATLAS catalog mirror\n│   │   ├── datasets.json\n│   │   └── models.json\n│   ├── sets/                # Marketplace dataset installs\n│   └── annotations/         # Marketplace annotation tool installs\n│\n└── etc/\n    └── atlas/\n        ├── nodes.json       # Trusted Domain registry\n        └── federation.yaml  # Default federation parameters\n----\n\n=== Well-Known Paths Under `$HOME`\n\nThese paths are scaffolded at login by the `ProjectProvider`. They are conventions, not enforced — the user can remove or rename them. Stage transitions `cd` to the relevant path but do not require it to exist.\n\n[cols=\"1,2\"]\n|===\n| Path | Purpose\n\n| `~/data/cohort/`\n| Gathered datasets for the current session. Populated by `DatasetProvider` during the Gather stage. Contains one subdirectory per contributing institution (e.g., `BCH/`, `MGH/`), each with `images/`, `masks/`, and annotation files.\n\n| `~/data/cache/`\n| Intermediate artifacts from processing. Cleared between sessions.\n\n| `~/src/project/`\n| Active project workspace. Contains `train.py`, `config.yaml`, `requirements.txt`, `README.md`, and a `.meridian/` directory for federation manifests.\n\n| `~/models/`\n| Training outputs (weights, metrics) and marketplace model installs.\n\n| `~/results/`\n| Post-stage published artifacts. Populated after `model_publish()`.\n\n| `~/bin/`\n| User-local scripts and tools. Distinct from `/bin/` (system-wide).\n\n| `~/.config/argus.yaml`\n| User preferences, stored API keys, shell configuration.\n\n| `~/.history`\n| Shell command history. Persisted across sessions (localStorage-backed).\n|===\n\n=== System Paths\n\nThese paths are managed by the VCS and Providers. They are writable only through Provider APIs, not directly by the user.\n\n[cols=\"1,2\"]\n|===\n| Path | Purpose\n\n| `/bin/`\n| Marketplace plugin installs. Each plugin is an executable stub with metadata content (name, version, description, usage).\n\n| `/data/catalog/`\n| Read-only mirror of the ATLAS catalog. Contains `datasets.json` and `models.json` generated from `core/data/datasets.ts` and `core/data/marketplace.ts`.\n\n| `/data/sets/`\n| Marketplace dataset installs. Each dataset is a directory with a `manifest.json`.\n\n| `/data/annotations/`\n| Marketplace annotation tool installs. Each tool is a directory with a `manifest.json`.\n\n| `/etc/atlas/nodes.json`\n| Trusted Domain registry. Generated from `core/data/nodes.ts`.\n\n| `/etc/atlas/federation.yaml`\n| Default federation parameters.\n|===\n\n== Persona System\n\n=== `$HOME` Per User\n\n`$HOME` is always `/home/<username>`. The username is determined at login. In the current prototype, the username matches the persona name (`developer`, `annotator`, etc.). In a production system, this would be the authenticated user's ID.\n\n=== Landing Directory Per Persona\n\nAfter login, the Shell `cd`s to the persona's landing directory. This is where the user's session begins — analogous to a desktop environment opening a specific folder.\n\n[cols=\"1,1,2\"]\n|===\n| Persona | Landing Directory | Rationale\n\n| Developer\n| `~/src/project`\n| Ready to code. Project files immediately visible.\n\n| Annotator\n| `~/workspace`\n| Ready to label. Annotation queue visible.\n\n| Clinician\n| `~/cases`\n| Ready to review. Patient cases visible.\n\n| Scientist\n| `~/experiments`\n| Ready to analyze. Experiment notebooks visible.\n\n| Provider\n| `~/data`\n| Ready to manage contributed data.\n\n| Admin\n| `~/system`\n| Ready to manage users and nodes.\n\n| FDA / Regulatory\n| `~/audits`\n| Ready to review compliance artifacts.\n|===\n\n=== Home Directory Scaffolding\n\nAt login, the `ProjectProvider` scaffolds the well-known subdirectory structure under `$HOME`. The scaffolding is additive — it creates directories that don't exist but never overwrites existing content. This preserves any user modifications from a previous session (if session persistence is implemented).\n\n== VirtualFileSystem API\n\n=== FileNode Interface\n\n[source,typescript]\n----\ninterface FileNode {\n    name: string;\n    type: 'file' | 'folder';\n    path: string;                          // Absolute path\n    size: string;                          // Human-readable (e.g., '4.2 KB')\n    content: string | null;                // Text content, null if not yet generated\n    contentGenerator: string | null;       // ContentRegistry key for lazy generation\n    permissions: 'rw' | 'ro';             // Read-write or read-only\n    modified: Date;                        // Last modification timestamp\n    children: FileNode[] | null;           // null for files, array for folders\n    metadata: Record<string, string>;      // Arbitrary key-value pairs (DICOM headers, etc.)\n}\n----\n\n=== Core Methods\n\nAll methods follow the project RPN naming convention: `<subject>_<verb>`.\n\n[cols=\"2,2,3\"]\n|===\n| Method | Signature | Behavior\n\n| `node_read`\n| `(path: string): string \\| null`\n| Returns file content. If `content` is null and `contentGenerator` is set, invokes the ContentRegistry to generate content on demand. Returns null for folders. Throws if path does not exist.\n\n| `node_write`\n| `(path: string, content: string): void`\n| Writes content to a file. Creates the file if it does not exist (parent must exist). Updates `modified` timestamp and `size`. Emits `VFS_CHANGED`.\n\n| `node_remove`\n| `(path: string): void`\n| Removes a file or empty folder. Throws if folder is not empty (unless `recursive: true`). Emits `VFS_CHANGED`.\n\n| `node_copy`\n| `(src: string, dest: string): void`\n| Copies a file or folder tree. Deep copy — new nodes, same content. Emits `VFS_CHANGED`.\n\n| `node_move`\n| `(src: string, dest: string): void`\n| Moves a file or folder. Reparents the node in the tree. Updates `path` recursively. Emits `VFS_CHANGED`.\n\n| `node_stat`\n| `(path: string): FileNode \\| null`\n| Returns the FileNode at the given path without reading content. Returns null if not found.\n\n| `dir_list`\n| `(path: string): FileNode[]`\n| Returns the children of a directory. Throws if path is not a folder.\n\n| `dir_create`\n| `(path: string): void`\n| Creates a directory. Creates intermediate directories if needed (like `mkdir -p`). Emits `VFS_CHANGED`.\n\n| `file_create`\n| `(path: string, content?: string): void`\n| Creates an empty file (like `touch`). Optionally with initial content. Emits `VFS_CHANGED`.\n\n| `path_resolve`\n| `(input: string): string`\n| Resolves a relative path against `$PWD`. Expands `~` to `$HOME`. Normalizes `.` and `..`.\n\n| `cwd_get`\n| `(): string`\n| Returns the current working directory as an absolute path.\n\n| `cwd_set`\n| `(path: string): void`\n| Changes the current working directory. Throws if path does not exist or is not a folder. Emits `CWD_CHANGED`.\n\n| `tree_mount`\n| `(path: string, root: FileNode): void`\n| Mounts a subtree at the given path. Used by Providers to attach generated trees. Emits `VFS_CHANGED`.\n\n| `tree_unmount`\n| `(path: string): void`\n| Removes a previously mounted subtree. Emits `VFS_CHANGED`.\n|===\n\n=== Events\n\n[cols=\"1,2,2\"]\n|===\n| Event | Payload | Emitted By\n\n| `VFS_CHANGED`\n| `{ path: string, operation: string }`\n| Any mutation method (`node_write`, `node_remove`, `dir_create`, etc.)\n\n| `CWD_CHANGED`\n| `{ oldPath: string, newPath: string }`\n| `cwd_set()`\n|===\n\n== Shell\n\nThe Shell is the command interpreter layer between the Terminal UI and the VirtualFileSystem. It is the \"computer\" the user talks to. The Terminal becomes a dumb I/O surface: it sends keystrokes to the Shell and renders whatever the Shell returns.\n\n=== ShellResult Interface\n\n[source,typescript]\n----\ninterface ShellResult {\n    stdout: string;      // Standard output (rendered by terminal)\n    stderr: string;      // Standard error (rendered in red by terminal)\n    exitCode: number;    // 0 = success, non-zero = error\n}\n----\n\n=== Environment Variables\n\n[cols=\"1,1,2\"]\n|===\n| Variable | Default | Description\n\n| `$HOME`\n| `/home/user`\n| User's home directory. Set at login.\n\n| `$USER`\n| `user`\n| Current username. Set at login.\n\n| `$PWD`\n| `$HOME`\n| Current working directory. Updated by `cd`. Synonym for `vfs.cwd_get()`.\n\n| `$PATH`\n| `/bin:~/bin`\n| Executable search path. Used by Shell to resolve commands.\n\n| `$PERSONA`\n| `fedml`\n| Current persona context.\n\n| `$STAGE`\n| `search`\n| Current SeaGaP stage. Updated on stage transitions.\n\n| `$PS1`\n| `$USER@argus:$PWD $`\n| Prompt format string. Evaluated by Shell for each prompt render.\n|===\n\n=== Builtin Commands\n\n[cols=\"1,2,2\"]\n|===\n| Command | Usage | Behavior\n\n| `cd`\n| `cd [path]`\n| Change directory. No args = `cd $HOME`. Calls `vfs.cwd_set()`.\n\n| `pwd`\n| `pwd`\n| Print working directory. Reads `$PWD`.\n\n| `ls`\n| `ls [path]`\n| List directory contents. Defaults to `$PWD`. Colorized output (folders in blue, executables in green).\n\n| `cat`\n| `cat <file>`\n| Print file content. Calls `vfs.node_read()`.\n\n| `mkdir`\n| `mkdir [-p] <path>`\n| Create directory. `-p` creates intermediate directories.\n\n| `touch`\n| `touch <file>`\n| Create empty file or update timestamp.\n\n| `rm`\n| `rm [-r] <path>`\n| Remove file or directory. `-r` for recursive.\n\n| `cp`\n| `cp <src> <dest>`\n| Copy file or directory.\n\n| `mv`\n| `mv <src> <dest>`\n| Move or rename file or directory.\n\n| `echo`\n| `echo [text...]`\n| Print text to stdout. Supports `$VARIABLE` expansion.\n\n| `env`\n| `env`\n| Print all environment variables.\n\n| `export`\n| `export KEY=VALUE`\n| Set an environment variable.\n\n| `whoami`\n| `whoami`\n| Print `$USER`.\n\n| `date`\n| `date`\n| Print current date and time.\n\n| `clear`\n| `clear`\n| Clear terminal output buffer.\n\n| `help`\n| `help`\n| List available commands with descriptions.\n\n| `history`\n| `history`\n| Show command history.\n|===\n\n=== Prompt Generation\n\nThe Shell owns prompt generation. The prompt is computed by evaluating the `$PS1` format string against the current environment. This replaces all hardcoded `terminal.setPrompt()` calls throughout the codebase.\n\n[source,typescript]\n----\n// $PS1 = '$USER@argus:$PWD $ '\n// After cd /home/user/src/project:\n// Rendered: 'user@argus:~/src/project $ '\n----\n\nThe `~` substitution is cosmetic: if `$PWD` starts with `$HOME`, the Shell replaces that prefix with `~` in the rendered prompt.\n\n=== Stage Transitions\n\nWhen the application transitions between SeaGaP stages, the Shell receives a `stage_enter` call:\n\n[source,typescript]\n----\nshell.stage_enter('process');\n// 1. Sets $STAGE = 'process'\n// 2. cd to the persona's landing directory for that stage\n// 3. Prompt auto-updates via $PS1 evaluation\n----\n\nThis replaces the current pattern of hardcoded `terminal.setPrompt()` and `consoleEl.classList.add('open')` in the stage-change listener.\n\n== Content System\n\n=== ContentRegistry\n\nThe ContentRegistry maps file paths (or path patterns) to content generators. When the VFS needs to read a file whose `content` is null, it consults the ContentRegistry.\n\n[source,typescript]\n----\ninterface ContentGenerator {\n    pattern: string | RegExp;        // Path match (e.g., '~/src/project/train.py')\n    generate: (context: ContentContext) => string;\n}\n\ninterface ContentContext {\n    filePath: string;\n    persona: string;\n    selectedDatasets: Dataset[];\n    activeProject: Project | null;\n    installedAssets: string[];\n}\n----\n\n=== Templates\n\nTemplates are pure functions that generate file content strings. They live in `src/vfs/content/templates/`.\n\n[cols=\"1,2\"]\n|===\n| Template | Generates\n\n| `train.ts`\n| `train.py` — Python federated training script. Adapts to selected datasets (imports, data paths, model architecture).\n\n| `readme.ts`\n| `README.md` — Project documentation. Lists datasets, topology, privacy settings.\n\n| `config.ts`\n| `config.yaml` — Training configuration. Epochs, learning rate, aggregation strategy.\n\n| `requirements.ts`\n| `requirements.txt` — Python dependencies.\n\n| `manifest.ts`\n| `.meridian/manifest.json` — MERIDIAN federation manifest with node assignments.\n\n| `catalog.ts`\n| `/data/catalog/datasets.json` and `models.json` — Serialized catalog from `core/data/`.\n\n| `nodeRegistry.ts`\n| `/etc/atlas/nodes.json` — Serialized Trusted Domain registry from `core/data/nodes.ts`.\n|===\n\n=== Lazy Content Generation\n\nContent is generated lazily on first `node_read()`. This avoids generating content for files the user never opens. Once generated, content is cached on the `FileNode.content` field and served directly on subsequent reads.\n\nIf the application state changes (e.g., a new dataset is selected), Providers can call `node_invalidate(path)` to clear cached content, forcing regeneration on the next read.\n\n== Providers\n\nProviders are responsible for translating application domain objects into filesystem trees. They are the bridge between the ARGUS application state and the VCS filesystem.\n\n=== DatasetProvider\n\nPopulates `~/data/cohort/` from the selected datasets.\n\n**Triggered by:** `DATASET_SELECTION_CHANGED` event (during Gather stage).\n\n**Behavior:**\n\n1. Unmounts the existing `~/data/cohort/` tree (if any).\n2. For each selected dataset, creates:\n+\n----\n~/data/cohort/\n└── <institution>/           # e.g., BCH, MGH, BIDMC\n    ├── images/\n    │   ├── img_0001.dcm\n    │   ├── img_0002.dcm\n    │   └── ...\n    ├── masks/\n    │   ├── mask_0001.png\n    │   └── ...\n    ├── annotations.json\n    └── manifest.json        # Dataset metadata (id, modality, cost, provenance)\n----\n3. Each file has a `contentGenerator` registered for on-demand content (e.g., DICOM header summaries for `.dcm` files, annotation schema for `.json` files).\n4. Mounts the tree at `~/data/cohort/`.\n5. Creates `~/data/cohort/manifest.json` with aggregated cohort metadata (total cost, dataset IDs, provenance chain).\n\n=== ProjectProvider\n\nPopulates `~/src/project/` and scaffolds the home directory structure.\n\n**Triggered by:** Login (scaffolding) and stage transitions (project population).\n\n**Behavior at login:**\n\n1. Creates `$HOME` and all well-known subdirectories.\n2. Creates `~/.config/argus.yaml` with default preferences.\n3. Calls `shell.cwd_set()` to the persona's landing directory.\n\n**Behavior at Process stage entry:**\n\n1. Populates `~/src/project/` with:\n+\n----\n~/src/project/\n├── train.py              # contentGenerator: train template\n├── config.yaml           # contentGenerator: config template\n├── requirements.txt      # contentGenerator: requirements template\n├── README.md             # contentGenerator: readme template\n└── .meridian/\n    └── manifest.json     # contentGenerator: meridian manifest template\n----\n2. All files use lazy content generation via the ContentRegistry.\n\n=== MarketplaceProvider\n\nInstalls marketplace assets into the appropriate system paths.\n\n**Triggered by:** `store.asset_install(assetId)`.\n\n**Behavior by asset type:**\n\n[cols=\"1,2,2\"]\n|===\n| Asset Type | Install Path | Content\n\n| Plugin\n| `/bin/<plugin-name>`\n| Executable stub with name, version, description, usage instructions, dependencies.\n\n| Dataset\n| `/data/sets/<dataset-name>/manifest.json`\n| Dataset metadata, sample count, modality, license.\n\n| Model\n| `~/models/<model-name>/README.md`\n| Model card with architecture, training data, metrics, usage.\n\n| Annotation Tool\n| `/data/annotations/<tool-name>/manifest.json`\n| Tool metadata, supported formats, label schema.\n\n| FDA Tool\n| `/bin/<tool-name>` + `/data/annotations/<tool-name>/`\n| Both executable and data components.\n|===\n\n== Integration Points\n\n=== VCS ↔ Store\n\nThe VCS is stored as a global singleton on `store.globals.vcs` (replacing the current `store.globals.vfs`). The Store does not reach into the VCS; it emits events that Providers listen to.\n\n[cols=\"1,2\"]\n|===\n| Store Event | VCS Response\n\n| `STAGE_CHANGED`\n| Shell calls `stage_enter()` — updates `$STAGE`, `cd`s to landing directory.\n\n| `DATASET_SELECTION_CHANGED`\n| DatasetProvider rebuilds `~/data/cohort/`.\n\n| `PROJECT_LOADED`\n| ProjectProvider scaffolds `~/src/project/`.\n\n| `STATE_CHANGED` (marketplace install)\n| MarketplaceProvider installs asset to appropriate path.\n|===\n\n=== VCS ↔ Terminal\n\nThe Terminal sends raw input strings to `shell.command_execute(line)` and receives `ShellResult` objects. The Terminal is responsible only for:\n\n- Rendering `stdout` (default color) and `stderr` (error color)\n- Displaying the prompt (from `shell.prompt_render()`)\n- Managing input focus, history navigation (arrow keys), and tab completion\n\nThe Terminal no longer registers individual commands. All command registration moves to the Shell.\n\n=== VCS ↔ IDE (Process Stage)\n\nThe IDE code viewer calls `vfs.node_read(path)` to display file content. When the user selects a file in the project explorer, the IDE reads its content from the VFS — not from a hardcoded template.\n\nThe project explorer tree is built by calling `vfs.dir_list('~/src/project/')` recursively.\n\n=== VCS ↔ Marketplace\n\n`assetDetail_install()` in `marketplace/view.ts` calls `store.asset_install(id)`. The Store emits `STATE_CHANGED`. The `MarketplaceProvider` listens and writes the asset into the VFS at the appropriate system path.\n\n== Source Structure\n\n----\nsrc/\n└── vfs/\n    ├── VirtualFileSystem.ts      # Core: tree + content + CWD + events\n    ├── Shell.ts                  # Command interpreter + env vars + prompt\n    ├── types.ts                  # FileNode, ShellResult, ContentContext, etc.\n    │\n    ├── content/\n    │   ├── ContentRegistry.ts    # Path → generator mapping + lazy evaluation\n    │   └── templates/\n    │       ├── train.ts          # train.py generator\n    │       ├── readme.ts         # README.md generator\n    │       ├── config.ts         # config.yaml generator\n    │       ├── requirements.ts   # requirements.txt generator\n    │       ├── manifest.ts       # .meridian/manifest.json generator\n    │       ├── catalog.ts        # /data/catalog/*.json generators\n    │       └── nodeRegistry.ts   # /etc/atlas/nodes.json generator\n    │\n    └── providers/\n        ├── DatasetProvider.ts    # Builds ~/data/cohort/ from selected datasets\n        ├── ProjectProvider.ts    # Scaffolds $HOME + populates ~/src/project/\n        └── MarketplaceProvider.ts # Installs assets to /bin, /data/sets, etc.\n----\n\n== Migration Path\n\n=== Files to Retire\n\n[cols=\"1,2\"]\n|===\n| Current File | Replaced By\n\n| `src/core/logic/vfs.ts`\n| `src/vfs/VirtualFileSystem.ts` — complete rewrite with content support.\n\n| `src/core/logic/filesystem.ts`\n| `src/vfs/providers/DatasetProvider.ts` — the `filesystem_create()` function moves into the provider.\n\n| Hardcoded `train.py` HTML in `src/core/stages/process.ts:117-141`\n| `src/vfs/content/templates/train.ts` — generates plain text, not HTML.\n\n| Hardcoded `README.md` HTML in `src/core/stages/process.ts:143-155`\n| `src/vfs/content/templates/readme.ts`.\n\n| `terminal.setPrompt()` calls in `src/argus.ts:497-514`\n| `shell.stage_enter()` + `$PS1` evaluation.\n\n| Command registration in `src/ui/components/Terminal.ts:36-117`\n| `src/vfs/Shell.ts` — all builtins move to the Shell.\n\n| `store.globals.vfs`\n| `store.globals.vcs` — rename to reflect the expanded scope.\n|===\n\n=== Files to Modify\n\n[cols=\"1,2\"]\n|===\n| File | Changes\n\n| `src/core/state/store.ts`\n| Replace `globals.vfs` with `globals.vcs`. Add `VFS_CHANGED` and `CWD_CHANGED` events.\n\n| `src/core/state/events.ts`\n| Add new event types for VFS and CWD changes.\n\n| `src/argus.ts`\n| Initialize VCS instead of VFS. Wire Shell to Terminal. Remove hardcoded prompt/stage logic.\n\n| `src/ui/components/Terminal.ts`\n| Simplify to I/O surface. Remove command registration. Delegate to Shell.\n\n| `src/lcars-framework/ui/Terminal.ts`\n| Remove command map. Add `shell` integration point.\n\n| `src/core/stages/gather.ts`\n| Replace `filesystem_build()` with DatasetProvider call.\n\n| `src/core/stages/process.ts`\n| Replace `populate_ide()` with VFS reads. Remove hardcoded file content.\n\n| `src/marketplace/view.ts`\n| Replace `store.asset_install()` inline VFS touch with MarketplaceProvider call.\n|===\n\n== Implementation Status\n\nThis section is a living checklist. Update it with each implementation iteration.\n\n=== Phase 1: Core VFS (Complete)\n\n[cols=\"1,1,2\"]\n|===\n| Item | Status | Notes\n\n| `src/vfs/types.ts`\n| [x] Done\n| FileNode with content, ShellResult, ContentContext, VfsChangeEvent, CwdChangeEvent.\n\n| `src/vfs/VirtualFileSystem.ts`\n| [x] Done\n| Full rewrite. Tree, content, CWD, path resolution (~, .., relative), lazy content generation, events via EventBus. `legacyNode_normalize()` bridge removed in Phase 4.\n\n| VCS events in EventBus\n| [x] Done\n| Added `VFS_CHANGED` and `CWD_CHANGED` to `src/core/state/events.ts`.\n\n| Unit tests for VFS\n| [x] Done\n| 64 tests covering path resolution, CWD, dir/file CRUD, node read/write/copy/move/remove, mount/unmount, lazy content generation, invalidation, and event emission.\n\n| Retire `src/core/logic/vfs.ts`\n| [x] Done\n| Old VFS class deleted. All consumers migrated to new API: `store.ts`, `Terminal.ts`, `search.ts`, `gather.ts`, `process.ts`, `argus.ts`. Legacy FileNode trees bridge via `legacyNode_normalize()`.\n|===\n\n=== Phase 2: Shell (Complete)\n\n[cols=\"1,1,2\"]\n|===\n| Item | Status | Notes\n\n| `src/vfs/Shell.ts`\n| [x] Done\n| Environment variables ($HOME, $USER, $PWD, $PATH, $PERSONA, $STAGE, $PS1), prompt generation with ~ substitution, stage transitions with landing directories, and external handler delegation.\n\n| `src/vfs/ShellBuiltins.ts`\n| [x] Done\n| 20+ POSIX-like builtins (cd, pwd, ls, cat, mkdir, touch, rm, cp, mv, echo, env, export, whoami, date, history, help, python, upload, analyze, simulate, harmonize). Decoupled from Shell environment logic.\n\n| Wire Shell to Terminal\n| [x] Done\n| Terminal delegates all input to Shell via `onUnhandledCommand`. Shell exit code 127 falls through to async fallback handler (AI/workflow commands). `shell_connect()` + `fallback_set()` APIs. Shell created in `argus.ts`, stored in `globals.shell`.\n\n| Remove command registration from Terminal.ts\n| [x] Done\n| All filesystem commands moved to Shell builtins. Terminal only registers `clear` (DOM access) and overrides base `help` to delegate to Shell. AI/workflow commands (search, add, review, mount, simulate, LLM fallback) handled via fallback handler.\n\n| Unit tests for Shell\n| [x] Done\n| Shell coverage includes env vars, prompt generation, command parsing, all builtins, stage transitions, and external handler delegation. Refer to CI for current totals.\n\n| Stage-change listener updated\n| [x] Done\n| `argus.ts` stage listener calls `shell.stage_enter()` for CWD/env updates. Process/default stages use Shell $PS1 via `prompt_sync()`. Search/gather retain command-console prompts.\n|===\n\n=== Phase 3: Content System (Complete)\n\n[cols=\"1,1,2\"]\n|===\n| Item | Status | Notes\n\n| `src/vfs/content/ContentRegistry.ts`\n| [x] Done\n| Path-to-generator mapping with lazy evaluation. `generator_register()`, `generators_registerAll()`, `vfs_connect()`, `content_resolve()`. Builds `ContentContext` from live application state.\n\n| `src/vfs/content/templates/*.ts`\n| [x] Done\n| 8 generators: train (Python script adapts to datasets/modality), readme (Markdown with topology), config (YAML training config), requirements (pip deps), manifest (MERIDIAN JSON), catalog-datasets (serialized DATASETS), catalog-models (model architectures), node-registry (Trusted Domain nodes).\n\n| IDE integration\n| [x] Done\n| `ide_openFile()` in process.ts now reads from VFS via `node_read()`, triggering lazy content generation. Added `syntax_highlight()` for .py, .yaml, .json, .md, .txt with semantic CSS classes. Removed all hardcoded HTML templates.\n\n| Unit tests\n| [x] Done\n| ContentRegistry coverage includes registration, resolution, VFS integration (lazy gen + caching), and template generation. Refer to CI for current totals.\n\n| Wiring\n| [x] Done\n| `ContentRegistry` created in `argus.ts`, all generators registered via `ALL_GENERATORS`, connected to VFS before Shell init.\n|===\n\n=== Phase 4: Providers (Complete)\n\n[cols=\"1,1,2\"]\n|===\n| Item | Status | Notes\n\n| `src/vfs/providers/ProjectProvider.ts`\n| [x] Done\n| `homeDir_scaffold()` creates ~/bin, ~/data, ~/src, /etc/atlas, /bin, /tmp, config files with content generators. `projectDir_populate()` creates ~/src/project/ with train, config, requirements, readme, manifest generators.\n\n| `src/vfs/providers/DatasetProvider.ts`\n| [x] Done\n| `cohortTree_build()` replaces `filesystem_create()`. Builds VCS FileNode trees directly with proper provider codes, image/mask nodes, validation dirs. Helper functions: `datasetDir_build()`, `imageNodes_build()`, `maskNodes_build()`, `validationDir_build()`, `node_file()`.\n\n| `src/vfs/providers/MarketplaceProvider.ts`\n| [x] Done\n| `asset_install()` dispatches to type-specific installers (plugin, dataset, model, annotation, fda, workflow). Each creates dirs, files, metadata, and content generator keys. 6 new asset manifest generators added.\n\n| Retire `src/core/logic/filesystem.ts`\n| [x] Done\n| Deleted `filesystem.ts` and `filesystem.test.ts`. Removed `legacyNode_normalize()` from `VirtualFileSystem.ts`. All consumers migrated to providers.\n\n| Template expansion\n| [x] Done\n| 6 new generators: `argus-config`, `plugin-executable`, `dataset-manifest`, `model-readme`, `annotation-manifest`, `workflow-manifest`, `cohort-manifest`. Total: 14 generators registered.\n\n| Store + Stage wiring\n| [x] Done\n| `store.asset_install()` calls `asset_install()` via MarketplaceProvider. `gather.ts` and `search.ts` use `cohortTree_build()`. `argus.ts` calls `homeDir_scaffold()` at init and `projectDir_populate()` on process stage entry.\n|===\n\n=== Phase 5: Integration (Complete)\n\n[cols=\"1,1,2\"]\n|===\n| Item | Status | Notes\n\n| Store migration (`vfs` → `vcs`)\n| [x] Done\n| Renamed `globals.vfs` → `globals.vcs` in store definition and all 7 consumer files. Property key in Store.globals renamed.\n\n| Stage transition integration\n| [x] Done\n| `shell.stage_enter()` already wired in Phase 2. Unified all stages to use `prompt_sync()` after stage_enter. Removed redundant `updatePrompt()` call from navigation.ts (method didn't exist on Terminal).\n\n| Marketplace integration\n| [x] Done\n| `store.asset_install()` delegates to `asset_install()` via MarketplaceProvider (wired in Phase 4). Marketplace view (`view.ts`) has no inline VFS calls — clean separation.\n\n| Remove all hardcoded `setPrompt()` calls\n| [x] Done\n| Removed `terminal.setPrompt('ARGUS: SEARCH >')` and `terminal.setPrompt('ARGUS: COHORT >')` from argus.ts stage-change listener. All stages now use `terminal.prompt_sync()` which reads Shell's `$PS1`. Shell is sole prompt authority.\n|===\n\n== Changelog\n\n[cols=\"1,1,3\"]\n|===\n| Date | Version | Changes\n\n| 2026-01-28\n| 0.1.0\n| Initial specification. Defines architecture, filesystem layout, APIs, providers, migration path, and implementation phases.\n\n| 2026-01-28\n| 0.2.0\n| Phase 1 complete: `types.ts`, `VirtualFileSystem.ts`, VCS events in EventBus, 64 unit tests, old VFS retired. All consumers migrated. Legacy bridge `legacyNode_normalize()` added for filesystem.ts compatibility.\n\n| 2026-01-28\n| 0.3.0\n| Phase 2 complete: `Shell.ts` with builtins, env vars, $PS1 prompt generation, stage transitions, and external handler delegation. Terminal rewritten as dumb I/O surface with Shell → fallback handler chain. Shell wired into `argus.ts` via `globals.shell`. Stage listener updated to use `shell.stage_enter()`.\n\n| 2026-01-28\n| 0.4.0\n| Phase 3 complete: `ContentRegistry.ts` with lazy evaluation and VFS integration. 8 template generators (train, readme, config, requirements, manifest, catalog-datasets, catalog-models, node-registry). IDE reads from VFS with `syntax_highlight()` for .py/.yaml/.json/.md/.txt. Hardcoded HTML templates removed from process.ts.\n\n| 2026-01-29\n| 0.5.0\n| Phase 4 complete: Three providers created — `DatasetProvider.ts` (`cohortTree_build()`), `ProjectProvider.ts` (`homeDir_scaffold()`, `projectDir_populate()`), `MarketplaceProvider.ts` (`asset_install()` with 6 type-specific installers). 6 new asset manifest generators + `argusConfig` generator (14 total). Store, gather, search, argus.ts migrated to providers. Legacy `filesystem.ts` and `filesystem.test.ts` deleted. `legacyNode_normalize()` removed from VirtualFileSystem.ts.\n\n| 2026-01-29\n| 0.6.0\n| Phase 5 complete: `globals.vfs` renamed to `globals.vcs` across store and all 7 consumers. Hardcoded `setPrompt()` calls removed from search/gather stages — Shell `$PS1` via `prompt_sync()` is sole prompt authority. Dead `updatePrompt()` call removed from navigation.ts. Marketplace integration verified clean (no inline VFS calls). All 5 phases complete.\n\n| 2026-01-29\n| 0.7.0\n| Style guide compliance sweep. All VCS/Provider/Store code now uses RPN naming (e.g., `store.asset_install()`, `detailHeader_populate()`), explicit type annotations on all consts/lambdas, JSDoc on all public/private functions, `catch (e: unknown)` with `instanceof Error` narrowing, and typed `declare global { interface Window }` extensions replacing `(window as any)` casts. Typed filter lambda parameters throughout VirtualFileSystem.ts and Shell.ts.\n|===",
    "visual_language.adoc": "= ARGUS: Visual Language Specification\n:author: ATLAS Project Team\n:revdate: 2026-01-30\n:toc:\n:sectnums:\n\n== Introduction\n\nARGUS draws its visual identity from Star Trek's LCARS (Library Computer Access/Retrieval System), designed by Michael Okuda for The Next Generation. Where LCARS was created for television cameras, ARGUS adapts its design language for responsive, interactive web use. This document codifies the motion and layout patterns that give ARGUS its cinematic, mechanical feel.\n\nThe visual language is built on a central metaphor: ARGUS is a physical console. Frames are structural members that separate and rejoin. Content panels are equipment trays that slide into exposed bays. Nothing simply appears or disappears -- everything moves with deliberate, mechanical purpose.\n\n== Core Structural Elements\n\n=== The LCARS Frame\n\nBar panels form the structural skeleton of the interface. The primary frame consists of two horizontal bar rows (bars 1-5 at top, bars 6-10 at bottom) connected by a vertical left sidebar. These bars are not decorative chrome -- they are load-bearing members that define content regions and, critically, can separate to expose functional surfaces beneath them.\n\nThe frame uses rounded \"elbows\" at connection points between horizontal and vertical members, achieved through a combination of `border-radius` and pseudo-element geometry. These curves are the most recognizable LCARS signature and must be preserved at all viewport sizes.\n\n=== The Content Region\n\nThe area enclosed by bars and sidebar is the active workspace. Content within this region changes based on the current SeaGaP-MP stage. The region scrolls vertically but never horizontally.\n\n=== The Slot\n\nWhen bars separate, the space between them becomes a slot -- a bay into which content panels can be inserted. The Intelligence Console occupies the primary slot between the lower bar panel and the main content area. The slot concept is generalizable: any region where frame members can part to accept a content panel is a slot.\n\n== Animation Patterns\n\nARGUS uses three distinct animation patterns, each appropriate to different interaction contexts. All animations use the same easing curve (`cubic-bezier(0.4, 0, 0.2, 1)`) for visual consistency.\n\n=== Pattern 1: Frame Separation\n\nFrame members move apart to create space. This is a vertical height transition where a collapsed region expands to a target height.\n\n[cols=\"1,3\"]\n|===\n| Duration | 600ms (`--frame-transition-duration`)\n| Easing | `cubic-bezier(0.4, 0, 0.2, 1)` (`--lcars-easing`)\n| CSS mechanism | `transition: height` on the slot container\n| Trigger | Class toggle (`.open`)\n| Used by | Intelligence Console frame, terminal drawer\n|===\n\nFrame Separation alone does not introduce content. It exposes empty space -- a bay waiting to receive a panel. When used in isolation, the frame region would contain static content already present in the DOM that is revealed by the expansion.\n\n=== Pattern 2: Slide-In Overlay\n\nA full-surface overlay enters from the right edge of the viewport and covers the content region entirely. This is used for modal or near-modal experiences that temporarily replace the active workspace.\n\n[cols=\"1,3\"]\n|===\n| Duration | 400ms (`--slide-transition-duration`)\n| Easing | `cubic-bezier(0.4, 0, 0.2, 1)` (`--lcars-easing`)\n| CSS mechanism | `@keyframes` with `translateX(100%)` to `translateX(0)`\n| Trigger | State change via Store (`marketplaceOpen`)\n| Close | Reverse animation via `.closing` class, then `display: none` on `animationend`\n| Used by | Marketplace overlay, Asset detail overlay\n|===\n\nThe slide-in overlay implies a separate system or context. The marketplace is not part of the SeaGaP workflow -- it is an adjacent resource. The rightward origin reinforces this: it arrives from outside the console's workspace.\n\n=== Pattern 3: Frame-then-Slide (The Double Whammy)\n\nThis is the signature ARGUS interaction pattern, combining Frame Separation with a content slide-in to create a two-phase mechanical animation:\n\n==== Opening Sequence\n\n. **Phase 1 -- Frame Separation** (600ms): The slot container expands vertically. Bar panels move apart. The bay is now exposed but empty.\n. **Phase 2 -- Content Slide-In** (400ms): After the frame finishes expanding, the content panel slides in from the right edge of the slot, filling the bay.\n\nTotal opening time: ~1000ms. The sequential phasing is intentional for the opening -- the user should perceive two distinct mechanical actions: \"bay opens\" then \"equipment slides in.\"\n\n==== Closing Sequence\n\n. **Simultaneous**: The content panel begins sliding out to the right AND the frame begins collapsing at the same time. Both animations run in parallel.\n\nTotal closing time: ~600ms. The overlapped closing is intentional -- closing should feel snappier than opening. The visual effect is the content being retracted as the bay shuts, like a drawer closing with its tray still retracting.\n\n==== Timing Constants\n\n[cols=\"2,1,1\"]\n|===\n| Constant | Value | CSS Variable\n| Frame transition duration | 600ms | `--frame-transition-duration`\n| Slide transition duration | 400ms | `--slide-transition-duration`\n| Easing curve | cubic-bezier(0.4, 0, 0.2, 1) | `--lcars-easing`\n|===\n\n==== Used By\n\n* Intelligence Console (terminal)\n* Future: any panel that occupies a frame slot (diagnostics, settings, inline help)\n\n== The Frame Slot System\n\nThe Frame-then-Slide pattern is implemented as a composable system with two components:\n\n=== SlidePanel\n\nA reusable primitive that manages the slide-in and slide-out animation of a single DOM element. The SlidePanel knows nothing about frames or slots -- it only knows how to move its content element horizontally using CSS transitions.\n\nThe SlidePanel applies the `.frame-slot-panel` CSS class to its managed element. This class sets the initial state (`translateX(100%)`, `opacity: 0`) and defines the transition properties. The `.active` class triggers the slide-in; the `.exiting` class triggers the slide-out.\n\nCSS transitions are used rather than `@keyframes` animations because transitions can be interrupted and reversed mid-animation. This is essential for the draggable access strip, which allows users to manually resize the terminal bay.\n\n=== FrameSlot\n\nAn orchestrator that coordinates the two-phase sequence by combining a frame element (the expandable container) with a SlidePanel (the sliding content). The FrameSlot manages the timing between phases and provides guards against rapid-fire toggling that could leave the animation in a broken state.\n\nThe FrameSlot is the integration point. To add a new pluggable panel to a frame slot in the future, one creates a new SlidePanel instance and registers it with the FrameSlot. The frame expansion logic remains unchanged -- only the content that slides in differs.\n\n== Design Rationale\n\n=== Why Two Phases on Open?\n\nA single combined animation (frame expands while content slides) would be faster but would read as a single event. Two distinct phases create a narrative: something mechanical happened (the bay opened), and then something was delivered (the panel arrived). This maps to the physical console metaphor and gives the user's attention two anchor points rather than one.\n\n=== Why Overlap on Close?\n\nOpening is a reveal -- it deserves ceremony. Closing is a dismissal -- it should be efficient. Users who close a panel want it gone; making them wait through a sequential reverse animation creates frustration. The overlapped close respects the user's intent to dismiss while still maintaining visual coherence.\n\n=== Why Slide from the Right?\n\nThe left edge of the ARGUS interface is occupied by the LCARS sidebar -- a fixed structural member. Content entering from the right implies arrival from outside the current context, which is semantically correct for both the marketplace (an external registry) and the terminal (a system-level tool that exists below the application surface). The rightward origin also follows natural left-to-right reading flow: the workspace is read first, then the arriving panel draws attention as it enters the visual field.\n\n== Pattern Selection Guide\n\n[cols=\"2,3,2\"]\n|===\n| Scenario | Pattern | Rationale\n\n\n| System tool appearing within the console frame\n| Frame-then-Slide\n| Mechanical feel; tool is \"inserted\" into the console\n\n| External resource browser or modal overlay\n| Slide-In Overlay\n| Full takeover; content is from outside the workflow\n\n| Revealing static content within the layout\n| Frame Separation only\n| No new content arrives; existing content is exposed\n\n| Future: swapping one tool for another in an open bay\n| Slide-out then Slide-in (no frame animation)\n| Bay is already open; only the content changes\n|===\n\n== Visual Convergence: Asset Tiles and Project Tiles\n\nTo maintain a consistent visual language across the platform, ARGUS uses a unified tile-based metaphor for all addressable resources, whether they are external (Marketplace Assets) or internal (User Projects).\n\n=== The Asset Card Pattern\n\nThe `AssetCard` component codifies the established LCARS \"tile\" aesthetic. It features:\n* **The Header Badge**: Top-left identification of the resource type (e.g., \"PLUGIN\", \"PROJECT\").\n* **The Semantic Color Code**: Orange for algorithms/scripts, Honey for data/projects, Sky for core systems.\n* **Metadata Alignment**: Primary stats (stars, dataset counts) on the right, authorship/origin on the bottom-left.\n* **The Mechanical Action**: A primary action button (INSTALL, SELECT) integrated into the card's baseline.\n\n=== Interaction Parity: Preview Before Commitment\n\nConsistent with the Marketplace interaction model, User Projects now feature a **Detail Preview** phase. Clicking a project tile no longer triggers an immediate workspace load (commitment); instead, it opens a detail overlay providing a read-only preview of the project's source code and data cohort.\n\n=== The Workspace Layout\n\nAs of v4.3.0, opening a project from the detail preview activates a **workspace layout** that transforms the right-frame into a vertical stack of two independently-sized panels: the Intelligence Console (terminal) on top and a FileBrowser below.\n\nEach panel owns its own bottom-edge **resize handle** — an LCARS-styled 6px orange grip bar. Dragging a handle resizes only its associated panel. The panels are fully decoupled; the page scrolls to accommodate their combined height. This \"independent sizing\" model replaces the traditional split-pane approach (where resizing one panel shrinks the other) and aligns with the LCARS philosophy of modular, self-contained instrument panels.\n\nThe file browser tabs (SOURCE/DATA) and the terminal working directory maintain bidirectional sync: clicking a tab changes the terminal's cwd, and typing `cd` in the terminal switches the active tab.",
    "why-not-agentic.adoc": "= Why ARGUS Doesn't Let the AI Drive\n:author: ATLAS Project Team\n:revdate: 2026-02-14\n:toc: macro\n:sectnums:\n\ntoc::[]\n\n== The One-Sentence Version\n\nAI models are structurally incapable of assembling clinical workflows with guaranteed correctness, so ARGUS uses them only to understand what you want — never to decide what to do.\n\n== The Problem with \"Agentic AI\"\n\nThe current trend in AI is to give language models more autonomy: let them pick tools, assemble multi-step procedures, and execute complex workflows. This is called \"agentic AI.\" It works impressively in demos. It is dangerous in clinical settings.\n\nHere is why, without equations.\n\n=== Generation Is Guessing\n\nWhen you ask an AI to generate text, code, or a plan, it is not looking up the answer. It is sampling from a cloud of possibilities — all the outputs that are roughly consistent with your prompt. Most of those possibilities are wrong. The model picks one that _seems_ right based on patterns it learned during training.\n\nThis is not a flaw to be fixed. It is how generation works. The same mechanism that lets the model produce creative, fluent, useful responses also means it will sometimes produce confident, fluent, _wrong_ responses. You cannot have one without the other.\n\n=== More Steps, More Risk\n\nNow consider what happens when you ask an AI to assemble a multi-step workflow: \"search for brain scans, build a cohort, harmonize the data, train a model, containerize it, and deploy it across three hospitals.\"\n\nAt each step, the model must choose what to do next. Each choice has some small probability of being wrong — picking the wrong tool, skipping a required step, using the wrong parameters. The key insight is that these probabilities _compound_:\n\n- If each step has a 2% chance of error and there are 10 steps, the chance of at least one error is roughly 18%.\n- At 20 steps, it is 33%.\n- At 50 steps, it is 64%.\n\nThe longer the workflow, the more certain it becomes that something will go wrong. This is not pessimism. It is arithmetic.\n\n=== \"Show Your Work\" Doesn't Help\n\nA common response is to require the AI to explain its reasoning — show the chain of thought, output explicit code, make the steps visible. This feels safer because you can see what it is doing.\n\nBut each line of reasoning is itself another step sampled from a probability distribution. Requiring more explicit steps does not reduce the error probability; it increases the number of places where errors can occur. Transparency helps _humans detect_ errors after the fact, but it does not prevent the AI from _making_ them.\n\n=== Safety Checks Are Reactive, Not Preventive\n\nAnother response is to add guardrails — filters that catch dangerous outputs, safety interlocks that block invalid actions, self-consistency checks. These help, but they are reactive: they respond to errors after the model has already decided to make them. They reduce the _impact_ of mistakes but not the _probability_ of attempting them.\n\nA self-driving car with excellent brakes still crashes if the steering system points it at a wall. You want a steering system that cannot point at walls in the first place.\n\n== What ARGUS Does Instead\n\nARGUS takes the AI out of the steering seat. The design principle is simple: **the AI interprets what you want; deterministic code decides what to do.**\n\n=== The Routing Chain\n\nWhen you type something into CALYPSO, your input passes through five levels:\n\n[cols=\"1,3\"]\n|===\n| Level | What Happens\n\n| 1. Shell commands\n| Exact matches like `ls`, `cd`, `tree` execute immediately. No AI involved.\n\n| 2. Workflow commands\n| Known commands like `search`, `gather`, `harmonize` map directly to specific operations. No AI involved.\n\n| 3. Pattern matching\n| Questions like \"what stage am I on?\" are intercepted and answered from system state. No AI involved.\n\n| 4. Intent resolution\n| Natural language like \"ok do the harmonization\" is stripped down to the keyword `harmonize` and routed to level 2. No AI involved.\n\n| 5. LLM fallback\n| Only if none of the above match does the AI get consulted — and even then, it provides _guidance and explanation_, not action execution.\n|===\n\nLevels 1 through 4 are deterministic. They produce the same output every time for the same input. The AI at level 5 is a communicator, not a decision-maker.\n\n=== Proof by Artifact, Not Assertion\n\nMost AI systems tell you what happened: \"I've completed the task.\" You have to trust the assertion. ARGUS does not work this way.\n\nIn ARGUS, progress is proven by _materialized artifacts_ — files that exist (or don't) in the system:\n\n- Your cohort is assembled when `.cohort` exists\n- Your data is harmonized when `.harmonized` exists\n- Your training passed when `.local_pass` exists\n- Your model is federated when `.federated` exists\n\nEvery time the system checks your workflow state, it looks at what actually exists — not at what it remembers or what it told you last time. This is the same model used by ChRIS, the compute platform ARGUS serves: the filesystem _is_ the truth.\n\n=== Manifests: Pinning \"What Comes Next\"\n\nEven with deterministic routing and artifact-based state, one gap remained: the AI was still responsible for telling you _what to do next_. And it drifted — skipping steps, forgetting options, jumping ahead.\n\nThe solution is **persona manifests**: explicit YAML documents that define every stage of a workflow, what it produces, what commands are available, and what the user should be told. The AI reads the manifest instead of guessing. \"What comes next\" becomes a lookup, not an inference.\n\n== The Analogy\n\nThink of a GPS navigation system:\n\n- **Agentic AI** is like giving the GPS the steering wheel. It usually picks good routes, but sometimes it drives into a lake because its map has a confident-looking road where the lake is. More detailed turn-by-turn instructions don't help if the route itself is wrong.\n\n- **ARGUS** is like a GPS that shows you the route and tells you when to turn, but _you_ drive. The routes are pre-mapped and validated. The GPS interprets your destination (\"take me to the hospital\") but does not invent new roads.\n\n== When This Matters\n\nFor a chatbot that writes marketing copy, agentic AI is fine. A wrong output is mildly annoying.\n\nFor a system that assembles medical imaging workflows — choosing which algorithms process patient data, in what order, with what parameters, across multiple hospitals — a wrong output is a patient safety issue. The cost of an incorrect workflow is not a bad paragraph; it is a wrong diagnosis, a missed finding, or a compromised federated learning model trained on improperly harmonized data.\n\nARGUS is built for the second case. The architecture is not conservative for philosophical reasons. It is conservative because the mathematics of probabilistic systems demands it.\n\n== Further Reading\n\n- `docs/agentic-safety.adoc` — The formal mathematical argument with proofs\n- `docs/agentic.adoc` — How ARGUS compares to other agentic design patterns\n- `docs/CURRENT.md` — Active design work on manifest-driven workflow sequencing\n- `docs/persona-workflows.adoc` — Data-state grounding and workflow definitions\n\n---\n_Last updated: {revdate}_"
};
