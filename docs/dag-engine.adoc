= Manifest-Driven DAG Engine: The Core of Workflow Orchestration
:author: ATLAS Project Team
:revdate: 2026-02-17
:revnumber: 10.0.0
:toc: macro
:toclevels: 4
:sectnums:

toc::[]

== Abstract

The ARGUS DAG Engine is the declarative heart of the system's workflow orchestration. It models scientific processes as Directed Acyclic Graphs (DAGs) defined in YAML manifests, ensuring that every user interaction is governed by strict procedural rules and cryptographically anchored by Merkle fingerprints. This document serves as the formal specification for the DAG engine, detailing the mechanics of topological position resolution, the branch-aware Merkle provenance model, and the engineering rationale for grounding graph transitions in physical filesystem artifacts.

== Introduction: The Case for a Graph-Based Model

=== The Failure of Linear State Machines
In early iterations of ARGUS (v1.0 through v8.0), workflow progress was managed through hardcoded linear state machines. This approach was structurally incapable of supporting the complex realities of federated research. A scientific workflow is rarely a straight line; it involves branching (e.g., renaming a project), re-execution (e.g., changing search parameters), and parallel dependencies (e.g., merging cohorts from multiple sites). Linear models inevitably suffer from "State Drift," where the system's belief about its position diverges from the actual project data.

=== The Resolution: Topological Grounding
We learned that a scientific workflow must be modeled as a graph, not a list. The resolution was the implementation of a **Manifest-Driven DAG Engine**. In the v10.0 architecture, this engine has been enhanced with **Merkle-Proven Fingerprinting**. Every node in the graph is now grounded in a physical VFS artifact, and every transition is verified against a cryptographic chain of parentage. This ensures that the system's logical position is always a direct reflection of the physical evidence on the virtual disk.

== DAG Topology Figure

[source,text]
----
manifest DAG (example):

┌────────┐     ┌────────┐     ┌───────────┐     ┌─────────┐
│ search │────▶│ gather │────▶│ harmonize │────▶│ proceed │
└────────┘     └────────┘     └───────────┘     └─────────┘

re-execution branch:
┌────────┐
│ search │  (new fingerprint)
└────┬───┘
     │
     └──────────────▶ downstream lineage marked stale until re-materialized
                      ┌────────┐     ┌───────────┐     ┌─────────┐
                      │ gather │────▶│ harmonize │────▶│ proceed │
                      └────────┘     └───────────┘     └─────────┘
----

== The Workflow Manifest: Declarative Process Specification

Workflows in ARGUS are defined externally in YAML manifests (`src/dag/manifests/`). These files serve as the "Scientific Schema" for the system.

=== Node Identity and Topological Constraints
Each node in the DAG defines a discrete stage of the workflow.
*   **Previous (Prerequisites):** Defines the parent stages that must be completed before the current stage can execute. This creates the "Directed" and "Acyclic" properties of the graph.
*   **Commands:** Lists the canonical protocol commands (e.g., `harmonize`, `train`) that the stage handles.
*   **Produces (The Artifact Contract):** This is the most critical field. It defines the specific artifact file (e.g., `harmonize.json`) that must be materialized in the VFS for the stage to be considered complete.

=== Polymorphism and Persona Selection
The DAG Engine supports multiple active manifests. At system boot, the user (or the system persona) selects a manifest (e.g., `fedml.manifest.yaml` or `chris.manifest.yaml`). The DAG Engine then compiles this YAML into a runtime graph of `DAGNode` objects, providing a specialized execution environment tailored to that specific scientific persona.

== Topological Position Resolution: Determining "Where We Are"

In a non-linear graph, determining the "current stage" is a non-trivial operation. The `WorkflowAdapter` class implements a "Check-Then-Crawl" algorithm to resolve the system's topological position.

=== The Check-Then-Crawl Algorithm
1.  **VFS Inventory:** The engine first performs a deep walk of the VFS session tree, identifying all existing artifact envelopes.
2.  **Readiness Mapping:** For each node in the DAG, the engine evaluates its "Readiness" based on the inventory. A node is considered "Ready" if and only if:
    - All of its parent nodes have materialized valid artifacts.
    - Its own artifact is either missing or marked as stale.
3.  **Kahn's Leaf Identification:** The engine uses a modified version of Kahn's algorithm to perform a topological sort of the ready nodes. The first node in this order that lacks a completed artifact is identified as the authoritative `currentStage`.

This process ensures that Calypso's guidance and command routing are always grounded in the physical reality of the project tree, making the system immune to "context drift."

== Merkle Fingerprinting: The Chain of Evidence

To ensure the integrity of the scientific process over time, the DAG Engine utilizes a Merkle Provenance Chain. This mechanism cryptographically anchors every stage's data to its specific lineage.

=== The SHA-256 Recursive Fingerprint
When a stage completes, the `MerkleEngine` calculates a SHA-256 fingerprint for the resulting artifact.
$$H_{current} = \text{SHA-256}(Content_{current} + \text{ParentFingerprints})$$
This calculation ensures that an artifact's identity is inextricably linked to the specific versions of the data that preceded it.

=== Branch-Aware Staleness Detection
If a user re-executes an upstream stage (e.g., changing the search query), the `MerkleEngine` creates a new timestamped branch in the session tree.
*   **Fingerprint Invalidation:** The new upstream artifact receives a new fingerprint.
*   **Topological Ripple:** The DAG Engine immediately detects that all downstream artifacts (e.g., the gathered cohort) now point to an outdated parent hash.
*   **State Flagging:** These downstream stages are flagged as `[STALE]`. This informs the user—and the AI Kernel—that the scientific validity of the downstream data has been compromised and requires re-verification.

== Conclusion

The ARGUS DAG Engine transforms scientific processes from abstract ideas into verifiable, graph-based protocols. By grounding all workflow transitions in Merkle-proven materialization and topological resolution, the engine provides the "Scientific Conscience" of the system. It ensures that every step taken by a researcher is documented, auditable, and cryptographically anchored to its provenance, providing the rigorous foundation required for high-stakes federated medical research.

---
_Last updated: 2026-02-17 (v10.0.0)_
