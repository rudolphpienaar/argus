= DAG Engine Specification
:author: ATLAS Project Team
:revdate: 2026-02-14
:toc: macro
:toclevels: 3
:sectnums:

toc::[]

== Overview

The DAG engine (`src/dag/`) is a foundational layer of ARGUS responsible for
defining, materializing, and verifying workflow execution as a directed acyclic
graph.

=== What It Is

A directed acyclic graph (DAG) is a graph where edges have direction and no
path leads back to its starting node — there are no cycles. In ARGUS, each
node is a workflow stage (search, gather, harmonize, etc.) and each edge
represents a dependency: "this stage comes after that one." The DAG captures
the full topology of a workflow — which stages exist, how they relate, where
they branch and rejoin.

The DAG engine is the machinery that reads these graphs from YAML definitions,
materializes them as directory trees with artifacts, and verifies their
integrity over time. It sits alongside the VFS and WorkflowEngine as core
infrastructure — not a utility or helper, but a first-class subsystem.

=== Why It Exists

ARGUS follows ChRIS data-state DAG semantics: progress is proven by
materialized artifacts, not asserted by controllers or counters. Before the
DAG engine, workflow state was tracked by VFS markers (`.cohort`, `.harmonized`,
`.local_pass`) scattered in the project directory, and sequencing — "what comes
next" — was delegated to LLM inference. The LLM drifted: skipping stages,
forgetting options, confabulating next steps.

The DAG engine solves this by making both state and sequencing explicit.
The workflow topology is declared in YAML manifests. Each stage materializes a
structured artifact when it executes. A Merkle fingerprint chain detects when
upstream changes invalidate downstream artifacts. The LLM reads the manifest
for guidance instead of guessing — sequencing becomes a lookup, not an
inference.

=== What It Does

The engine has three responsibilities:

1. **Parse** manifest and script YAML files into a common DAG representation
2. **Materialize** the DAG into a storage backend as a session tree with
   artifacts and fingerprints
3. **Verify** the integrity of the materialized tree using a Merkle
   fingerprint chain

These responsibilities map to three sub-modules (`graph/`, `store/`,
`fingerprint/`) with strict separation of concerns.

== Design Principles

=== Every Stage Produces an Artifact

In ChRIS, every plugin in a pipeline writes output data. The platform knows a
plugin is done because its output directory exists and contains files. There is
no separate "status" field to check — the data _is_ the status.

The DAG engine follows the same principle. Every stage — without exception —
materializes an artifact into its `data/` directory in the session tree. There
are no pass-through stages, no stages that "just" display information, no
stages that run but leave no trace.

This design eliminates special-casing in the runtime. The readiness check for
any stage is identical: "do all my parents have artifacts?" The fingerprint
chain is unbroken across every node. The runtime never needs to ask "is this
a real stage or a pass-through?" — they are all real.

Three categories of stages require specific artifact strategies:

- **Repeatable stages** (search, code/test) use an **accumulation model**.
  Each iteration appends to the artifact rather than replacing it. The
  artifact grows over time, capturing the full history. The final state at
  the time the user moves on is what gets fingerprinted into the downstream
  chain.

- **Optional stages** that are skipped still materialize a **skip sentinel**
  — a small artifact recording `{skipped: true}` along with any default
  values. The sentinel gets fingerprinted exactly like a real artifact.
  If the user later comes back and performs the stage for real, the sentinel
  is replaced, the fingerprint changes, and downstream stages are detected
  as stale.

- **Informational stages** (like a federation briefing) materialize a record
  of what was presented — the briefing content, timestamp, and any
  acknowledgment. Even "just showing something" produces an artifact.

=== Backward Pointers, Not Forward

The manifest DAG follows the ChRIS pipeline YAML convention. In a ChRIS
pipeline, each plugin declares its `previous` — the plugin it comes after.
The platform reconstructs the full graph by reading these backward pointers.

This convention is used instead of forward pointers (`next`) because it
naturally supports three graph shapes:

- **Linear sequences** — the common case. Each stage has one `previous`.
- **Branching** — when two or more stages declare the same `previous`, the
  graph branches. The parent has multiple children without needing to
  enumerate them.
- **Joining** — when a stage declares multiple entries in `previous`, the
  graph joins. The stage waits for all parents to complete.

Forward pointers (`next`) would require every node to know all its children
in advance, making branching verbose and joining awkward. Backward pointers
keep each node self-contained: it knows only where it came from.

=== Two Trees: Session and Project

ARGUS maintains two separate directory structures that serve different purposes.

The **session tree** is a nested DAG materialization. It records _what
happened_: which stages executed, in what order, what artifacts they produced,
what fingerprints they carry. Users do not work in the session tree directly.
It exists for provenance, replay, auditing, and session persistence.

The **project tree** is a flat working directory. It is _where users work_:
editing code, examining datasets, running training. The project tree is
familiar — `input/`, `src/`, files at the top level. Users `cd` into it,
`ls` it, edit files in it.

The separation is deliberate. Mixing working files with provenance metadata
creates confusion — users see internal bookkeeping alongside their code, and
tooling must distinguish "user files" from "system files." Keeping them apart
means the session tree can be structured for machine consumption (nested DAG,
JSON artifacts, fingerprints) while the project tree stays clean for human
consumption.

=== Storage Backend Abstraction

The mental model for session materialization is a filesystem — nested
directories, files, symlinks. But the engine should not be locked to any
particular storage technology.

Today, ARGUS uses an in-memory VFS. Tomorrow, the CalypsoServer could use a
real filesystem sandbox. Eventually, sessions might persist in object storage
(S3-compatible) or distributed filesystems like ZeroFS.

The engine writes through a `StorageBackend` interface — five methods that
abstract the difference between a real filesystem, an in-memory tree, and a
key-value store. Swapping backends requires no changes to graph logic,
fingerprinting, or session management.

== Module Structure

[source]
----
src/dag/
  graph/
    types.ts               # DAGNode, DAGEdge, DAGDefinition (common output)
    validator.ts           # cycle detection, orphan check, join validation
    resolver.ts            # walk topology, compute readiness from store state
    parser/
      manifest.ts          # manifest YAML → DAGDefinition
      script.ts            # script YAML → DAGDefinition
      common.ts            # shared parsing utilities

  store/
    types.ts               # StorageBackend interface, SessionInfo
    SessionStore.ts        # session lifecycle against any backend
    backend/
      vfs.ts               # in-memory VFS backend
      fs.ts                # real filesystem backend (future)
      object.ts            # object storage backend (future)

  fingerprint/
    hasher.ts              # compute stage fingerprints from content + parent fps
    chain.ts               # Merkle chain validation, staleness detection
    types.ts               # FingerprintRecord, StalenessResult
----

=== Layer Separation

The three sub-modules have strict boundaries. Understanding what each does
and does _not_ do is essential for maintaining the architecture.

**`graph/`** is **pure topology**. It parses YAML files into a common
`DAGDefinition` structure. It validates that the graph is well-formed (no
cycles, no orphans, no dangling references). It resolves readiness by
querying which stages have materialized artifacts. It never performs I/O
directly — it asks the store layer whether an artifact exists, but it never
writes, reads, or creates files itself.

The parser sub-module (`graph/parser/`) has separate parsers for manifests
and scripts. Both produce the same `DAGDefinition` output type. The
distinction matters because manifests and scripts have different schemas and
different validation rules — a manifest defines full topology with
instructions and commands, while a script references a manifest and provides
parameter overrides. Keeping the parsers separate prevents schema leakage
between the two formats. The shared `common.ts` handles mechanics common to
both: YAML loading, `previous` field normalization (string → array), and
basic structural checks.

**`store/`** is **pure I/O**. It materializes the DAG into storage: creating
directories, writing artifact files, creating links for join edges. It manages
session lifecycle (create, resume, list, archive). It never interprets DAG
semantics — it does not know what "readiness" means or what a "join" is. The
graph layer tells it "create this directory, write this file, make this link"
and it does so through whichever backend is configured.

**`fingerprint/`** is **pure verification**. It computes hashes, validates
the Merkle chain, and reports staleness. It is read-only against the
materialized tree — it never writes or modifies artifacts. It reads what
the store layer wrote and reports whether the chain is intact.

== Manifest Format

A manifest is a YAML document that defines a complete persona workflow DAG.
It is the authoritative blueprint for a workflow — the single source of truth
for what stages exist, how they connect, what parameters they accept, and
what guidance the user receives at each step.

=== What a Manifest Is

Think of a manifest as the "pipeline definition" in ChRIS terminology, adapted
for interactive human-guided workflows. In ChRIS, a pipeline YAML defines
which plugins run in what order with what parameters. In ARGUS, a manifest
YAML defines which workflow stages exist in what order with what parameters,
instructions, and commands.

The key difference from ChRIS pipelines is the interactive element. ChRIS
pipelines run automatically — the platform executes each plugin when its
input is ready. ARGUS manifests are interactive — the user decides when to
proceed, what parameters to use, and whether to skip optional stages. The
manifest provides the structure and guidance; the user provides the decisions.

=== Why Manifests Exist

Before manifests, ARGUS had two representations of workflow structure: the
TypeScript workflow definitions (`fedml.ts`) that defined validation
conditions, and the LLM's implicit understanding of what stages exist and
what comes next. The TypeScript definitions answered "is this stage done?"
but not "what should the user do now?" The LLM filled that gap by inferring
next steps — and drifted.

Manifests eliminate the inference gap. Every stage declares its `instruction`
(what to tell the user) and `commands` (what actions are available). The LLM
reads these fields instead of guessing. Sequencing becomes deterministic.

=== Header

The manifest begins with a header containing metadata about the workflow:

[source,yaml]
----
# fedml.manifest.yaml

authors: ATLAS Team <atlas@childrens.harvard.edu>
name: "Federated ML — SeaGaP-MP Pipeline"
description: >
  Full lifecycle from dataset discovery through federation dispatch.
  Search, Gather, Harmonize, Code, Train, Federate.
category: Federated Learning
persona: fedml
version: 1.0.0
locked: false
----

Header fields:

[cols="1,3"]
|===
| Field | Description

| `authors`
| Contact information for the manifest author(s). Identifies who designed
  and maintains this workflow definition.

| `name`
| Human-readable name for the workflow. Displayed in session listings and
  persona selection.

| `description`
| Multi-line description of what the workflow does. Provides context for
  users and scripts that reference this manifest.

| `category`
| Classification for grouping and discovery. Multiple manifests can share
  a category.

| `persona`
| The ARGUS persona this manifest serves. When a user selects a persona
  during login, the runtime loads the manifest matching that persona.
  This field is also used by scripts as the anchor reference.

| `version`
| Semantic version of the manifest. Allows tracking changes to the
  workflow definition over time. When a manifest version changes, existing
  sessions created against an older version can be flagged.

| `locked`
| Governance control. When `true`, the DAG topology and parameter defaults
  are fixed — the workflow runs exactly as defined. Scripts can select stages
  and override parameters, but cannot add stages, skip non-optional stages,
  or rewire `previous` edges. When `false`, the workflow is modifiable at
  instantiation, allowing experimentation. In clinical contexts, validated
  workflows should be locked to prevent accidental modification.
|===

=== Stages

The `stages` list defines the DAG. Each entry is a stage node with its
topology, artifacts, parameters, and user guidance:

[source,yaml]
----
stages:
  - id: search
    name: Dataset Discovery
    phase: search-and-gather
    previous: ~
    optional: false
    produces:
      - search.json
    parameters:
      keywords: null
      modality: null
      anatomy: null
      catalog: atlas
    instruction: >
      Search the ATLAS catalog for datasets matching your research criteria.
      Use keywords, modality filters, or anatomical region.
    commands:
      - search <keywords>
    skip_warning: null
----

Stage fields:

[cols="1,1,3"]
|===
| Field | Required | Description

| `id`
| yes
| Unique identifier for the stage within this manifest. This string is used
  as the directory name in the session tree, as the key in fingerprint
  records, and as the reference target for `previous` fields in other
  stages. It must be a valid directory name (lowercase, hyphens allowed,
  no spaces).

| `name`
| yes
| Human-readable display name shown in progress indicators, session
  summaries, and user-facing messages.

| `phase`
| yes
| Grouping identifier for progress display and UI breadcrumbs. Multiple
  stages can share the same phase. For example, `search`, `gather`, and
  `rename` all belong to phase `search-and-gather`. Phases provide
  high-level progress indication ("You are in the Search & Gather phase")
  while stages provide granular tracking.

| `previous`
| yes
| Parent stage(s) in the DAG. This is the backward pointer that defines
  all topology. `~` (YAML null) for the root node — the workflow entry
  point. A single string for linear sequences (`previous: search`). A
  list for joins (`previous: [gather, rename]`). The stage declares who
  it comes after, not who comes next. See <<Reading the DAG>>.

| `optional`
| yes
| Whether the stage can be skipped without warning. When `true`, the user
  can bypass the stage freely; a skip sentinel is materialized so the
  Merkle chain remains intact. When `false`, skipping triggers the
  `skip_warning` sequence (if defined) and may be blocked entirely
  depending on governance policy.

| `produces`
| yes
| List of artifact filenames this stage materializes in its `data/`
  directory in the session tree. Always non-empty — every stage produces
  at least one artifact. The first entry is the primary artifact used for
  fingerprinting and readiness checks.

| `parameters`
| no
| Key-value map of configuration defaults for this stage. These are the
  knobs that control how the stage executes. Values of `null` mean "the
  user must provide this at runtime." Non-null values are defaults that
  can be overridden by scripts or runtime input. See <<Parameter
  Hierarchy>>.

| `instruction`
| yes
| The guidance text presented to the user when this stage is active. This
  is the critical field for LLM grounding — it is what the LLM reads
  instead of inferring. The instruction should tell the user what this
  stage does, why it matters, and what they should do next. It replaces
  the LLM's guess with a deterministic, manifest-defined answer.

| `commands`
| yes
| List of commands available to the user at this stage. Shown in guidance
  output and used for tab completion. These are the exact strings the user
  can type, with placeholder notation for arguments (e.g.,
  `search <keywords>`, `rename <new-name>`).

| `skip_warning`
| no
| Educational warning shown when the user attempts to skip a non-optional
  stage. Has three sub-fields: `short` (one-line summary displayed on first
  skip attempt), `reason` (detailed explanation displayed on second attempt),
  and `max_warnings` (number of warnings before allowing the skip — after
  this many warnings, the user may proceed and a skip sentinel is
  materialized). Null for optional stages or stages with no skip warning.
|===

=== Reading the DAG

The `previous` field defines all topology. A reader — human or machine — can
reconstruct the full graph from these backward pointers alone.

To build the graph from a manifest:

1. Each stage is a node, identified by `id`.
2. For each stage, draw a directed edge from every entry in `previous` to
   this stage.
3. The root node has `previous: ~` (null) — it is the entry point with no
   incoming edges.
4. A stage with `previous: [gather, rename]` is a **join** — it has two
   incoming edges and waits for both parents.
5. Two stages that both declare `previous: gather` form a **branch** —
   gather has two outgoing edges (two children).

This reconstruction is what `graph/parser/` does when loading a manifest.
The resulting `DAGDefinition` is a structured in-memory graph that the
validator and resolver operate on.

**Validation rules** (enforced by `graph/validator.ts`):

- **Acyclicity** — the graph must contain no cycles. A cycle would mean a
  stage depends on itself (directly or transitively), which is impossible
  to resolve. The validator performs a topological sort; if it fails, the
  graph has cycles.
- **Referential integrity** — every `previous` reference must point to an
  existing stage `id`. A dangling reference means the manifest is malformed.
- **Single root** — there must be exactly one node with `previous: ~`. This
  is the workflow entry point. Multiple roots would create ambiguity about
  where to start.
- **No orphans** — every non-root stage must be reachable from the root by
  following edges forward. An unreachable stage is dead code in the
  workflow.
- **Join reachability** — every parent listed in a join must itself be
  reachable from the root. A join that references an unreachable stage is
  malformed.

=== Example: Branch and Join

The simplest non-linear topology in the FedML workflow is the optional
`rename` stage:

[source]
----
search ──→ gather ──→ rename ──→ harmonize ──→ code ──→ ...
                │                    ↑
                └────────────────────┘
----

In YAML:

[source,yaml]
----
  - id: search
    previous: ~

  - id: gather
    previous: search

  - id: rename
    previous: gather
    optional: true

  - id: harmonize
    previous: [gather, rename]
----

`rename` is optional — it branches from `gather` and rejoins at `harmonize`.
The user can go from `gather` directly to `harmonize` (skipping rename) or
through `rename` first. Either way, harmonize has two parents and checks both
for artifacts. If rename was skipped, its skip sentinel satisfies the check.

== Script Format

=== What a Script Is

A script is a parameterized path through a manifest DAG. It does not define
its own topology — it inherits topology from the manifest it anchors to.
A script says: "run _these_ stages from the manifest, with _these_ parameter
values, skipping _these_ optional stages."

Scripts are to manifests what instantiated pipelines are to pipeline
definitions in ChRIS. The definition says what _can_ happen; the script says
what _will_ happen for this particular run.

=== Why Scripts Exist

Interactive workflows are flexible — users choose parameters, explore options,
and make decisions at each stage. But many workflows follow predictable
patterns: "search for histology, auto-gather everything, skip rename,
harmonize with default settings, scaffold code." Typing these commands
manually every time is tedious and error-prone.

Scripts capture these patterns as reusable automation. A power user creates a
script once, and anyone can replay it. Scripts also serve as documentation —
reading a script tells you exactly what a particular workflow run will do,
with what parameters, before you execute it.

The critical design constraint is that scripts cannot invent topology. They
select stages and configure them, but the stage definitions, validation rules,
instructions, and DAG structure all come from the manifest. This ensures that
scripts cannot create workflows that the manifest author did not anticipate,
which is especially important when the manifest is locked for governance.

=== Script Header

[source,yaml]
----
# histo-quickstart.script.yaml

authors: Rudolph Pienaar <rudolph.pienaar@childrens.harvard.edu>
name: "Histology Quick Start"
description: >
  Fast path: search histology, gather, harmonize, scaffold code.
category: Federated Learning
manifest: fedml
version: 1.0.0
----

Script header fields:

[cols="1,3"]
|===
| Field | Description

| `authors`
| Script author contact information. May differ from the manifest author —
  anyone can write scripts against a published manifest.

| `name`
| Human-readable script name. Displayed in script listings and execution
  logs.

| `description`
| What this script does. Should describe the specific use case, not
  repeat the manifest description.

| `category`
| Classification for grouping and discovery.

| `manifest`
| **Anchor.** The manifest this script operates on, referenced by the
  manifest's `persona` field. When the runtime loads a script, it first
  loads the corresponding manifest, then validates the script against it.
  This is the critical link that prevents scripts from operating outside
  a defined workflow structure.

| `version`
| Semantic version of the script. Independent from the manifest version.
|===

=== Script Stages

The script's `stages` list declares which manifest stages to execute and
how to configure them:

[source,yaml]
----
stages:
  - id: search
    parameters:
      keywords: "histology segmentation"
  - id: gather
    parameters:
      auto_select: true
  - id: rename
    skip: true
  - id: harmonize
  - id: code
----

Script stage fields:

[cols="1,1,3"]
|===
| Field | Required | Description

| `id`
| yes
| Must match a stage `id` in the anchored manifest. The runtime validates
  this during script loading.

| `parameters`
| no
| Parameter overrides for this stage. These values are merged on top of the
  manifest defaults. Keys must exist in the manifest stage's `parameters`
  map — a script cannot introduce parameters that the manifest did not
  define.

| `skip`
| no
| When `true`, the stage is explicitly skipped. A skip sentinel is
  materialized in the session tree. Only valid for stages marked
  `optional: true` in the manifest. If the manifest is locked, skipping
  a non-optional stage is a validation error.
|===

=== What Scripts Can and Cannot Do

**When the manifest is locked (`locked: true`):**

Scripts cannot:

- Add stages that don't exist in the manifest
- Remove or omit non-optional stages
- Change `previous` edges (rewire topology)
- Skip non-optional stages
- Introduce parameter keys not defined in the manifest

Scripts can:

- Select a subset of stages to run (must include all non-optional stages
  reachable in the selected path)
- Override parameter values for any stage
- Explicitly skip optional stages
- Set parameters to `null` to force interactive prompting even when the
  manifest provides a default

**When the manifest is unlocked (`locked: false`):**

The constraints on non-optional stages are relaxed. Scripts can skip any
stage, though the runtime may still issue warnings. This mode is for
experimentation and development, not clinical use.

=== Script Validation

When the runtime loads a script, it validates against the anchored manifest
before any execution begins:

1. **Stage existence** — every script stage `id` must exist in the manifest.
2. **Governance compliance** — if the manifest is locked, no non-optional
   stages may be omitted or explicitly skipped.
3. **Parameter validity** — parameter keys in overrides must exist in the
   corresponding manifest stage's `parameters` map.
4. **Sub-DAG integrity** — the selected stages must form a valid sub-DAG.
   No stage can have a `previous` reference pointing to a stage that was
   omitted from the script, unless that stage is optional and a skip
   sentinel will be materialized.

If any validation check fails, the script is rejected before execution with
a specific error identifying the violation.

== Parameter Hierarchy

=== What Parameters Are

Parameters are the configuration knobs for each stage. They control _how_
a stage executes: what keywords to search for, what resolution to harmonize
to, what app name to publish under. They are declared in the manifest with
default values (or `null` for required user input) and can be overridden at
multiple levels.

=== Why a Hierarchy

Different users of the same workflow need different configurations. A manifest
author sets sensible defaults for the general case. A script author tunes
parameters for a specific use case. A user at the keyboard makes final
adjustments for their particular run. The hierarchy allows each level to
build on the previous without duplicating the full configuration.

=== The Three Layers

Parameters flow through three layers, each overriding the previous:

[cols="1,2,2"]
|===
| Layer | Source | Example

| 1. Manifest defaults
| Set by the persona designer in the manifest YAML
| `resolution: [1.0, 1.0, 1.0]`

| 2. Script overrides
| Set by the script author in the script YAML
| `resolution: [0.5, 0.5, 0.5]`

| 3. Runtime overrides
| Typed interactively by the user or via command flags
| `harmonize --resolution 2.0,2.0,2.0`
|===

Resolution order: **runtime > script > manifest**. A value at a higher layer
replaces the value from a lower layer. A `null` value at any layer means
"defer to the next layer down" — or "prompt the user" if null at all layers.

The parameters actually used for a stage execution are captured in the
materialized artifact's `parameters_used` field. This provides a complete,
auditable record of exactly what configuration was applied, regardless of
which layer it came from.

== Session Tree

=== What the Session Tree Is

The session tree is a nested directory structure that materializes the DAG
as a filesystem hierarchy. Each stage becomes a directory nested inside its
primary parent. Each stage's artifacts live in a `data/` subdirectory.

The nesting literally encodes the DAG path. You can `ls` the tree and see
ancestry. The root stage's artifacts are at the top; the terminal stage's
artifacts are at the deepest nesting level.

=== Why Sessions Exist

Without sessions, workflow state is ephemeral. A user logs in, does some work,
logs out, and the state is gone. With sessions, the materialized tree persists.
A user can log out, come back hours or days later, select their session, and
continue exactly where they left off. The runtime reads the session tree,
walks the manifest, checks which stages have artifacts, and knows the current
position.

Sessions also enable comparison. A user can run the same workflow twice with
different parameters and compare the session trees side by side. The artifacts
record not just _what_ happened but _how_ — which parameters were used, what
the fingerprints were, where the chains diverge.

=== Structure

When a user logs in and selects a persona, a session is created under
`~/sessions/<persona>/`:

[source]
----
~/sessions/fedml/session-<id>/
  data/                                    ← search artifacts
  gather/
    data/                                  ← gather artifacts
    rename/
      data/                                ← rename artifacts (or skip sentinel)
      harmonize/
        data/                              ← harmonize artifacts
        code/
          data/                            ← code artifacts (accumulating)
          train/
            data/                          ← local validation artifacts
            federate-brief/
              data/
              federate-transcompile/
                data/
                federate-containerize/
                  data/
                  federate-publish-config/
                    data/
                    federate-publish-execute/
                      data/
                      federate-dispatch/
                        data/              ← terminal stage
----

The session ID is generated at creation time (timestamp + random suffix) and
is unique across all sessions for that persona.

=== Joins via Symlinks

The nested directory structure naturally captures linear paths and branches.
But joins — where a stage has multiple parents — break the nesting, because
a directory can only physically sit in one parent.

The solution is symlinks. A join stage nests physically under its **primary
parent** (the first entry in `previous`). Non-direct parents are represented
as symlinks within the stage's directory, pointing to the other parent's
location in the tree:

[source]
----
~/sessions/fedml/session-<id>/
  gather/
    data/
    rename/
      harmonize/
        data/                              ← harmonize artifacts
        gather -> ../../../gather          ← symlink: join to non-direct parent
----

The symlink makes the join edge traversable. The runtime can follow it to
read the parent's artifacts and verify its fingerprint. For a human exploring
the tree, `readlink` reveals the relationship.

**Why symlinks and not copies?** The parent's artifacts should exist in
exactly one place. Copying them would create divergence — if the parent is
re-executed, the copy becomes stale but isn't detected. Symlinks are
references, not duplicates. They point to the canonical location.

**Backend generalization:** The concept of "symlink" adapts to each storage
backend. On a POSIX filesystem, it is a literal symlink. On object storage,
it is a small reference object containing the target path. On ZeroFS, it is
whatever linking primitive that system provides. The `StorageBackend.link()`
method abstracts the mechanism while preserving the semantics.

=== Session Lifecycle

[cols="1,3"]
|===
| Operation | Description

| **Create**
| User logs in and selects a persona. The runtime creates
  `~/sessions/<persona>/session-<id>/` and materializes the root `data/`
  directory. The session is now active and positioned at the root stage.

| **Resume**
| User logs in and selects an existing session. The runtime reads the
  session tree, walks the manifest, and determines the current position by
  checking which stages have materialized artifacts. The user picks up
  exactly where they left off.

| **List**
| Returns all sessions for a persona with summary information: creation
  time, current stage (deepest materialized artifact), and staleness status
  (whether any artifacts have broken fingerprint chains).

| **Archive**
| Marks a completed or abandoned session as archived. The session is not
  deleted — the provenance record is preserved indefinitely. Archived
  sessions are hidden from the default listing but remain accessible.
|===

=== Relationship to Project Tree

The user works in `~/projects/<project>/`, not in the session tree:

[source]
----
~/projects/<project>/
  input/                   ← mounted datasets, .cohort, .harmonized
  src/                     ← train.py, user code
  .local_pass
----

The session tree records what happened. The project tree is where the user
works. These are separate concerns:

- The session tree is structured for machines — nested DAG, JSON artifacts,
  fingerprints.
- The project tree is structured for humans — flat, familiar, editable.

The linkage between them is established when `gather` creates the project.
The gather artifact in the session tree records the project path. The project
may carry a `.session` marker pointing back to the session, enabling
bidirectional navigation.

== Artifact Format

=== What an Artifact Is

An artifact is a JSON file that records what happened when a stage executed.
It is the materialized proof that the stage ran, with what inputs, producing
what outputs. In data-state terms, the artifact _is_ the state — its
existence means the stage is complete, its content records how.

=== Why the Envelope/Content Split

An artifact has two sections with different owners:

- The **envelope** is managed by the DAG engine. It contains structural
  metadata: which stage, when, what parameters, what fingerprints. The DAG
  engine writes this automatically.
- The **content** block is managed by the stage's executing code. It contains
  domain-specific data: which datasets were selected, what resolution was
  applied, what metrics resulted. Only the stage code knows this.

This separation keeps the DAG engine domain-agnostic. It wraps, fingerprints,
and materializes artifacts without knowing or caring what "harmonization" or
"federation" means. The stage code produces domain content without knowing
or caring about session trees or Merkle chains. Neither crosses the other's
boundary.

=== Structure

[source,json]
----
{
  "stage": "gather",
  "timestamp": "2026-02-14T10:30:00Z",
  "parameters_used": {
    "auto_select": false
  },

  "content": {
    "datasets": ["ds-001", "ds-006"],
    "project": "DRAFT-1234",
    "cohort_size": 2
  },

  "_fingerprint": "a3f8c2...",
  "_parent_fingerprints": {
    "search": "7b2e91..."
  }
}
----

=== Envelope Fields

[cols="1,3"]
|===
| Field | Description

| `stage`
| The stage `id` from the manifest. Identifies which stage produced this
  artifact.

| `timestamp`
| ISO 8601 timestamp of when the artifact was materialized. Used for
  display and ordering, not for fingerprinting (fingerprints are
  content-addressed, not time-addressed).

| `parameters_used`
| Snapshot of the fully resolved parameters (after manifest → script →
  runtime merge). This is the complete record of what configuration was
  applied. If a parameter came from the manifest default, the script
  override, or the user's keyboard, it appears here with the final value.

| `_fingerprint`
| SHA-256 hash of the entire artifact (envelope + content + parent
  fingerprints). This is the stage's identity in the Merkle chain.
  See <<Fingerprinting>>.

| `_parent_fingerprints`
| Map of parent stage `id` → fingerprint value at the time this stage
  executed. This records the exact state of every parent when this stage
  ran. Used for staleness detection: if a parent's current fingerprint
  differs from the value recorded here, this stage is stale.
|===

=== Content Block

The `content` field is opaque to the DAG engine. Its structure is determined
entirely by the stage's executing code. Examples of what different stages
record:

[cols="1,3"]
|===
| Stage | Content

| `search`
| `{ "queries": [{"query": "brain MRI", "results": ["ds-001"], "timestamp": "..."}] }`
  Accumulating — each search appends an entry.

| `gather`
| `{ "datasets": ["ds-001", "ds-006"], "project": "DRAFT-1234", "cohort_size": 2 }`

| `rename`
| `{ "old_name": "DRAFT-1234", "new_name": "brain-segmentation" }`
  Or skip sentinel: `{ "skipped": true, "default": "DRAFT-1234" }`

| `harmonize`
| `{ "resolution_applied": [1.0, 1.0, 1.0], "files_processed": 42 }`

| `code`
| `{ "cycles": [{"timestamp": "...", "files_modified": ["train.py"]}, ...] }`
  Accumulating — each code/test cycle appends.

| `train`
| `{ "exit_code": 0, "duration_s": 45, "metrics": {"loss": 0.23} }`
|===

The execution flow is: stage code returns a content object → DAG engine wraps
it in the envelope → DAG engine computes the fingerprint → DAG engine
materializes the complete artifact to storage.

=== Accumulating Artifacts

Some stages are iterative. The user searches multiple times, or writes code
and tests it repeatedly, before moving on. These stages use an
**accumulation model**: each iteration appends to the artifact rather than
replacing it.

The accumulating artifact captures the full iteration history. When the user
moves to the next stage, the fingerprint is computed from the final
accumulated state and locked into the downstream parent chain. If the user
later returns and adds more iterations, the content changes, the fingerprint
changes, and downstream stages are detected as stale.

This is important for provenance. A flat artifact that only records the last
search query loses the discovery trail. An accumulating artifact preserves
_how_ the user arrived at their final selection — which queries they tried,
what results they saw, what they kept and what they discarded.

=== Skip Sentinels

When an optional stage is skipped, the DAG engine materializes a sentinel:

[source,json]
----
{
  "stage": "rename",
  "timestamp": "2026-02-14T10:31:00Z",
  "parameters_used": {},

  "content": {
    "skipped": true,
    "default": "DRAFT-1234"
  },

  "_fingerprint": "c4d9f1...",
  "_parent_fingerprints": {
    "gather": "a3f8c2..."
  }
}
----

The sentinel is fingerprinted and treated identically to a real artifact.
The runtime has no special-case logic for skipped stages. The readiness check
for downstream stages works the same way: "does rename have an artifact?
Yes (the sentinel). What's its fingerprint? c4d9f1. Done."

If the user later decides to go back and actually perform the rename, the
sentinel is replaced with a real artifact. The fingerprint changes. Downstream
stages detect the change through the Merkle chain.

== Fingerprinting

=== What a Merkle Chain Is

A Merkle tree (named after Ralph Merkle, who patented the concept in 1979) is
a data structure where every node contains a hash that depends on the hashes
of its children. This means a change to any leaf propagates upward — the root
hash changes, and you can trace exactly which branch was modified by comparing
hashes at each level.

Git uses Merkle trees for commits: each commit hashes its content and its
parent commit's hash. If any commit in history changes, every subsequent
commit's hash changes too. This is how Git detects tampering and tracks
lineage.

The DAG engine uses the same principle, adapted from a tree to a DAG. Each
stage's artifact contains a fingerprint that depends on its own content _and_
the fingerprints of all its parent stages. A change to any upstream stage
cascades through the chain — every downstream fingerprint becomes stale.

=== Why Fingerprinting

The workflow is not a forced wizard. Users can jump back to earlier stages at
will. A researcher might reach harmonization, realize they forgot a dataset,
jump back to `gather`, add the dataset, and re-run gather. Now the cohort is
different — but harmonization was computed on the old cohort. How does the
system know?

Without fingerprinting, it doesn't. The harmonization artifact exists, so
the readiness check says "harmonize is complete." But it's complete _for the
wrong input_. This is the staleness problem, and it's invisible without
a mechanism to detect it.

Fingerprinting makes staleness visible. Harmonize's artifact recorded
gather's fingerprint at the time it ran. Gather's current fingerprint is
different (new dataset). The mismatch is detected automatically. No
controller, no event bus, no "dirty bit" — just data-state comparison.

=== Computing a Fingerprint

The fingerprint for a stage artifact is computed over the full artifact
content:

[source]
----
fingerprint(stage) = SHA-256(
  canonical_serialize(
    stage_id,
    parameters_used,
    content,
    sorted(parent_fingerprints)
  )
)
----

The input is canonically serialized — keys are sorted, whitespace is
normalized — to ensure deterministic hashing regardless of JSON key ordering
or formatting differences.

Note that `timestamp` is deliberately _excluded_ from the fingerprint
computation. Re-running a stage at a different time with the same parameters
and producing the same content should yield the same fingerprint. The
fingerprint is content-addressed, not time-addressed. This prevents false
staleness cascades when a stage is re-executed but nothing actually changed.

=== The Merkle Chain in Practice

Each artifact records `_parent_fingerprints` — the fingerprint of each parent
stage's artifact at the time this stage executed. This creates a chain:

[source]
----
search(fp: 7b2e91)
  └──→ gather(fp: a3f8c2, parents: {search: 7b2e91})
         └──→ rename(fp: c4d9f1, parents: {gather: a3f8c2})
                └──→ harmonize(fp: b7d1e4, parents: {gather: a3f8c2, rename: c4d9f1})
----

Every artifact is linked to its parents by fingerprint. The chain is
traversable in both directions: forward (follow edges to find what depends on
a stage) and backward (read `_parent_fingerprints` to find what a stage
depends on).

=== Staleness Detection

To check whether a stage is stale:

1. Read the stage's artifact and its `_parent_fingerprints`.
2. For each parent listed, read the parent's current artifact and its
   `_fingerprint`.
3. Compare: if `artifact._parent_fingerprints[parent_id] != parent._fingerprint`
   for any parent, the stage is **stale**.

This check is local — it only reads two artifacts per parent. But staleness
is **transitive**. If `gather` changes:

- `rename` is stale (its parent `gather` has a new fingerprint)
- `harmonize` is stale in _two ways_: directly via the gather join, and
  indirectly because rename (now stale) would produce a different fingerprint
  if re-executed

Walking forward from a changed node identifies all stale descendants. The
runtime can present this as a list: "These stages were computed against
outdated inputs and should be re-run."

=== Content-Addressed Invalidation

A critical property: fingerprints are computed over **content**, not
timestamps. If a user re-runs `gather` but selects the exact same datasets
in the same order, the content is byte-identical, the fingerprint is
byte-identical, and nothing downstream is invalidated. The user re-ran the
stage, but nothing actually changed, so no cascade occurs.

This is strictly better than timestamp-based invalidation (the `make`
approach). In `make`, touching a source file forces recompilation even if the
content didn't change. Content-addressed hashing avoids this waste.

=== Staleness Response

When staleness is detected, the system must decide how to respond. This is
configurable per stage in the manifest (future enhancement):

- **`warn`** (default) — the system informs the user: "Your harmonization was
  based on a different cohort. Re-run harmonize?" The user decides.
- **`block`** — the stage cannot be used until re-executed. Appropriate for
  critical stages in locked manifests where stale results are unacceptable.

The default is `warn` because ARGUS follows a soft-enforcement philosophy:
educate and inform rather than block. Expert users who understand the
implications can proceed with stale data if they choose.

== Readiness Resolution

=== What Readiness Means

A stage is **ready** when it can be executed — all prerequisites are met. A
stage is **complete** when it has executed and its artifact is materialized.
A stage is **blocked** when at least one prerequisite is not met.

The resolver (`graph/resolver.ts`) computes these states for every stage in
the manifest, producing a snapshot of the workflow's current position.

=== How Resolution Works

1. Load the manifest and build the in-memory DAG.
2. For each stage, query the storage backend: does an artifact exist in this
   stage's `data/` directory?
3. For each stage with an artifact, check the fingerprint chain: are any
   `_parent_fingerprints` mismatched against the current parent artifacts?
4. Classify each stage:
   - **Complete** — artifact exists and fingerprint chain is valid.
   - **Stale** — artifact exists but fingerprint chain is broken.
   - **Ready** — no artifact, but all `previous` stages are complete
     (not stale).
   - **Blocked** — no artifact, and at least one `previous` stage is
     incomplete or stale.

The resolver returns a `DAGPosition` structure containing these
classifications. This is what `workflowContext_forLLM()` uses to build the
LLM's context — deterministic, fresh, and based entirely on materialized
state.

=== The Next Stage

The resolver also identifies the **next stage** — the first ready stage in
topological order. This is the stage whose `instruction` and `commands` the
LLM should present to the user. The identification is deterministic: given
the same set of materialized artifacts, the resolver always returns the same
next stage.

== StorageBackend Interface

=== What It Is

The `StorageBackend` is the abstraction that decouples DAG materialization
from any specific storage technology. It defines five operations that every
storage system must support:

[source]
----
interface StorageBackend {
  write(path: string, data: any): Promise<void>
  read(path: string): Promise<any>
  exists(path: string): Promise<boolean>
  link(source: string, target: string): Promise<void>
  list(path: string): Promise<string[]>
}
----

=== Why an Interface

The DAG engine's logic — parsing, validation, fingerprinting, readiness
resolution — is independent of where artifacts are stored. An in-memory VFS,
a POSIX filesystem, and an S3 bucket all support the same operations: write
a blob, read it back, check if it exists, create a reference, list contents.

By coding against the interface rather than a specific backend, the entire
DAG engine can be tested against the fast in-memory VFS, deployed against a
real filesystem for persistence, and eventually migrated to object storage
for scalability — all without changing a line of graph logic or fingerprint
computation.

=== Method Reference

[cols="1,3"]
|===
| Method | Description

| `write(path, data)`
| Materialize an artifact at the given path. Creates parent directories
  as needed. Overwrites if the path already exists (for re-execution and
  accumulation updates).

| `read(path)`
| Retrieve a previously materialized artifact. Returns the deserialized
  content. Throws if the path does not exist.

| `exists(path)`
| Check whether an artifact has been materialized at the given path.
  Returns a boolean. This is the core readiness primitive — the resolver
  calls it for every stage.

| `link(source, target)`
| Create a join reference from source to target. On a POSIX filesystem,
  this is a symlink. On object storage, a small reference object
  containing the target path. The semantics are: "source points to target;
  reading source resolves to target's content."

| `list(path)`
| Enumerate children of a path. Returns an array of child names (not full
  paths). Used for session listing, tree walking, and discovering which
  stages have materialized in a session.
|===

=== Backend Implementations

[cols="1,2,2"]
|===
| Backend | Status | Description

| `backend/vfs.ts`
| Current
| In-memory VFS. Fast, ephemeral, used in development and testing. Sessions
  are lost when the process exits.

| `backend/fs.ts`
| Future
| Real filesystem on the CalypsoServer sandbox. Enables persistent sessions
  across server restarts. Uses real symlinks for joins.

| `backend/object.ts`
| Future
| Object storage (S3-compatible). Path nesting is flattened to key prefixes
  (`session-abc/gather/data/gather.json` becomes a single key). Links are
  small reference objects. Enables cloud-native session storage.
|===

== Integration with Existing Modules

=== CalypsoCore

CalypsoCore is the primary consumer of the DAG engine. It integrates at three
points:

- **Session management** — when a user logs in and selects a persona,
  CalypsoCore calls `SessionStore.create()`. When a user reconnects and
  selects an existing session, it calls `SessionStore.resume()`. The session
  provides the storage context for all subsequent stage operations.

- **Stage execution** — when a command like `gather` executes, the stage
  code (e.g., `project_gather()` in ProjectManager) performs the domain
  operation and returns a content object. CalypsoCore passes this content to
  the DAG engine, which wraps it in an envelope, computes the fingerprint,
  and materializes the artifact to the session tree.

- **Context building** — when the LLM needs context,
  `workflowContext_forLLM()` calls the resolver to get the current DAG
  position, then reads the manifest for the next ready stage's `instruction`
  and `commands`. The LLM receives deterministic guidance instead of
  inferring next steps.

=== WorkflowEngine

The existing `WorkflowEngine.stages_completed()` currently queries VFS
markers directly (e.g., checking whether `.cohort` exists). Over time, it
will delegate to the DAG engine's readiness resolver, unifying the two
approaches. The TypeScript workflow definitions in `fedml.ts` and `chris.ts`
may eventually be generated from or replaced by manifests.

=== ORACLE Testing

The DAG engine is fully testable through the VFS backend. ORACLE integration
tests can:

- Create a session, execute stages in sequence, and assert on the session
  tree structure.
- Verify fingerprint computation by executing a stage, reading the artifact,
  and confirming the hash matches manual computation.
- Simulate going back to an earlier stage (re-executing gather with different
  data), and verify that downstream stages are detected as stale.
- Load scripts, validate them against manifests, and verify that parameter
  merging produces expected results.
- Test edge cases: cyclic manifests (should be rejected), orphan stages
  (should be rejected), skip sentinels (should be fingerprinted normally).

== FedML Manifest Reference

The complete FedML manifest up to harmonization, showing all fields for each
stage:

[source,yaml]
----
# fedml.manifest.yaml

authors: ATLAS Team <atlas@childrens.harvard.edu>
name: "Federated ML — SeaGaP-MP Pipeline"
description: >
  Full lifecycle from dataset discovery through federation dispatch.
  Search, Gather, Harmonize, Code, Train, Federate.
category: Federated Learning
persona: fedml
version: 1.0.0
locked: false

stages:
  - id: search
    name: Dataset Discovery
    phase: search-and-gather
    previous: ~
    optional: false
    produces:
      - search.json
    parameters:
      keywords: null
      modality: null
      anatomy: null
      catalog: atlas
    instruction: >
      Search the ATLAS catalog for datasets matching your research criteria.
      Use keywords, modality filters, or anatomical region.
    commands:
      - search <keywords>

  - id: gather
    name: Cohort Assembly
    phase: search-and-gather
    previous: search
    optional: false
    produces:
      - gather.json
    parameters:
      auto_select: false
    instruction: >
      Add datasets to your cohort. When your selection is complete,
      run 'gather' to assemble the cohort and create your project.
    commands:
      - add <dataset>
      - remove <dataset>
      - show cohort
      - gather

  - id: rename
    name: Project Rename
    phase: search-and-gather
    previous: gather
    optional: true
    produces:
      - rename.json
    parameters:
      name: null
    instruction: >
      Your project was created with an auto-generated name.
      Rename it now if you'd like a meaningful identifier.
    commands:
      - rename <new-name>

  - id: harmonize
    name: Data Harmonization
    phase: harmonize
    previous: [gather, rename]
    optional: false
    produces:
      - harmonize.json
    parameters:
      resolution: [1.0, 1.0, 1.0]
      naming_convention: snake_case
      label_schema: default
    instruction: >
      Harmonize your cohort to ensure consistent data formats across sites.
      This applies image resampling, filename normalization, label schema
      alignment, and metadata standardization.
    commands:
      - harmonize
    skip_warning:
      short: Cohort not harmonized.
      reason: >
        Federated learning requires consistent data formats across sites.
        Without harmonization, your model may fail on heterogeneous inputs.
      max_warnings: 2

  # Remaining stages: code, train, federate-brief, federate-transcompile,
  # federate-containerize, federate-publish-config, federate-publish-execute,
  # federate-dispatch
----

== Example Script

A script that automates the first four stages with pre-filled parameters:

[source,yaml]
----
# histo-quickstart.script.yaml

authors: Rudolph Pienaar <rudolph.pienaar@childrens.harvard.edu>
name: "Histology Quick Start"
description: >
  Fast path: search histology, gather, harmonize, scaffold code.
  Skips rename, uses default harmonization settings.
category: Federated Learning
manifest: fedml
version: 1.0.0

stages:
  - id: search
    parameters:
      keywords: "histology segmentation"
  - id: gather
    parameters:
      auto_select: true
  - id: rename
    skip: true
  - id: harmonize
  - id: code
----

When this script is executed:

1. The runtime loads `fedml.manifest.yaml` (resolved via `manifest: fedml`
   matching the manifest's `persona: fedml` field).
2. It validates every script stage `id` against the manifest — all five
   exist, so validation passes.
3. For `search`: merges parameters (manifest default `keywords: null` →
   script override `keywords: "histology segmentation"`), executes the
   search, materializes `search.json` with the query and results.
4. For `gather`: merges parameters (manifest `auto_select: false` → script
   `auto_select: true`), auto-selects all search results, materializes
   `gather.json`.
5. For `rename`: marked `skip: true`, and rename is `optional: true` in the
   manifest, so a skip sentinel is materialized with the auto-generated
   project name.
6. For `harmonize`: no script parameter overrides, so manifest defaults
   apply (`resolution: [1.0, 1.0, 1.0]`). Executes harmonization,
   materializes `harmonize.json`.
7. For `code`: scaffolds the project structure, materializes `code.json`.
8. Execution stops — the user continues interactively from the `train` stage.

---
_Last updated: {revdate}_
